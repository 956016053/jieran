console.log("⏳ 开始加载题库数据...");
// 变量名改成 questions 以匹配你的程序逻辑
window.QuestionBank = [
	// 第一章
  {
    "id": "choice-1",
    "type": "choice",
    "question": "下列关于弱人工智能（Narrow AI）的描述，正确的是？",
    "options": [
      "具备跨领域泛化能力，能处理各种未见过的复杂问题",
      "专为特定任务设计，无法超出设定领域工作",
      "在所有领域都超越人类智能的假设性存在",
      "已实现商业化应用，如钢铁侠的贾维斯"
    ],
    "answer": 1,
    "hint": "弱AI=单项冠军，别和全能管家搞混啦！",
    "explanation": "弱人工智能的核心定义是专为特定任务设计，缺乏跨领域泛化能力（对应选项B）。选项A和D描述的是通用人工智能（General AI），目前尚未实现；选项C描述的是超人工智能（Super AI），属于遥远未来的假设。典型案例包括Siri、Alexa、垃圾邮件过滤器，它们仅能完成特定领域的任务。"
  },
  {
    "id": "choice-2",
    "type": "choice",
    "question": "图灵测试的核心机制是以下哪项？",
    "options": [
      "让机器通过视觉识别区分人类和其他机器",
      "通过文本对话让询问者无法分辨人类与机器",
      "测试机器解决复杂数学问题的速度",
      "验证机器是否能自我繁殖和进化"
    ],
    "answer": 2,
    "hint": "AI界的“蒙眼盲测”，靠聊天骗人～",
    "explanation": "图灵测试由艾伦·图灵在1950年《计算机器与智能》中提出，核心是“模仿游戏”：询问者通过文本与人类和机器对话，若无法分辨二者，则机器通过测试（对应选项B）。选项A混淆了视觉识别与文本交互；选项C是早期AI的性能测试，与图灵测试无关；选项D描述的是自我进化能力，并非图灵测试的核心。该测试启发了聊天机器人和自然语言处理（NLP）的发展。"
  },
  {
    "id": "choice-3",
    "type": "choice",
    "question": "1956年达特茅斯会议的关键历史贡献是？",
    "options": [
      "提出首个神经网络数学模型",
      "正式确立“人工智能”为独立学科",
      "开发出第一台自动驾驶车",
      "证明机器可以击败国际象棋冠军"
    ],
    "answer": 1,
    "hint": "AI的“出生证明”，大佬们给新领域起名啦！",
    "explanation": "达特茅斯会议由约翰·麦卡锡等人发起，核心贡献是正式提出“人工智能”（AI）一词，确立其为独立学科（对应选项B）。选项A是1943年麦卡洛克-皮茨神经元的贡献；选项C是2005年Stanley自动驾驶车的成就；选项D是1997年深蓝的突破。该会议标志着AI从跨学科探索正式成为专门的研究领域。"
  },
  {
    "id": "choice-4",
    "type": "choice",
    "question": "符号主义AI（GOFAI）的核心特征不包括以下哪项？",
    "options": [
      "自上而下的规则驱动",
      "依赖显式的知识表示",
      "从数据中自动学习模式",
      "基于逻辑推理进行决策"
    ],
    "answer": 2,
    "hint": "符号主义=法条主义者，靠手册办事，不是靠刷题～",
    "explanation": "符号主义AI的核心特征是：自上而下（Top-down）、显式知识表示、基于规则推理（对应选项A、B、D）。选项C“从数据中自动学习模式”是机器学习（尤其是深度学习）的特征，与符号主义的“手动编码规则”形成对比。符号主义认为智能可简化为符号操作，就像“背熟规则手册”办事，缺乏自主学习能力。"
  },
  {
    "id": "choice-5",
    "type": "choice",
    "question": "第一次AI寒冬（1974-1980）的导火索不包括以下哪份报告？",
    "options": [
      "ALPAC报告（1966年）",
      "Lighthill报告（1973年）",
      "Feynman报告（1981年）",
      "批评机器翻译和AI不切实际的报告"
    ],
    "answer": 2,
    "hint": "Feynman是物理学家，和AI寒冬没关系哦～",
    "explanation": "第一次AI寒冬的导火索是1966年ALPAC报告（批评机器翻译）和1973年Lighthill报告（批评AI不切实际），导致资金削减（对应选项A、B、D）。选项C的Feynman报告（1981年）主要讨论纳米技术和计算物理，与AI寒冬无关，且时间线也晚于第一次AI寒冬。AI寒冬的核心成因还包括算力限制和常识缺失。"
  },
  {
    "id": "choice-6",
    "type": "choice",
    "question": "下列哪种学习方式属于“有老师辅导的刷题”模式？",
    "options": [
      "监督学习",
      "无监督学习",
      "强化学习",
      "深度学习"
    ],
    "answer": 0,
    "hint": "有老师批改对错，就是监督学习呀～",
    "explanation": "监督学习的核心是从“带标签”数据中学习输入到输出的映射关系，就像“有老师辅导的刷题”：老师（标签）告知对错，模型修正思路（对应选项A）。选项B无监督学习是“无人指导的分类”，从无标签数据中发现模式；选项C强化学习是“驯兽模式”，通过奖励/惩罚机制学习；选项D深度学习是机器学习的子集，并非独立的学习方式。监督学习的典型应用包括图像识别、垃圾邮件检测。"
  },
  {
    "id": "choice-7",
    "type": "choice",
    "question": "AlexNet（2012）的关键创新不包括以下哪项？",
    "options": [
      "Transformer架构",
      "ReLU激活函数",
      "GPU加速训练",
      "Dropout正则化"
    ],
    "answer": 0,
    "hint": "AlexNet是CNN王者，Transformer是后来的NLP大佬～",
    "explanation": "AlexNet的关键创新包括：8层深层架构（5卷积+3全连接）、ReLU激活函数（提升训练速度）、Dropout正则化（防止过拟合）、GPU实现（加速10倍）、数据增强（增加训练量）（对应选项B、C、D）。选项A的Transformer架构是2017年提出的，用于NLP任务（如LLMs），并非AlexNet的创新。AlexNet将图像分类错误率从26%降至15%，标志着深度学习时代的到来。"
  },
  {
    "id": "choice-8",
    "type": "choice",
    "question": "AlphaGo（2016）击败李世石的核心技术不包括以下哪项？",
    "options": [
      "深度强化学习",
      "自我对弈训练",
      "蒙特卡洛树搜索",
      "纯监督学习"
    ],
    "answer": 3,
    "hint": "AlphaGo会自己和自己下棋，不是只靠别人教～",
    "explanation": "AlphaGo的核心技术是深度强化学习（结合CNN和RL）、自我对弈（海量模拟棋局训练）、蒙特卡洛树搜索（优化决策）（对应选项A、B、C）。选项D“纯监督学习”错误，因为AlphaGo并非仅依赖人类棋谱的监督训练，而是通过自我对弈实现能力超越人类。该成就突破了单纯靠计算无法解决的直觉型决策难题，证明了深度学习在复杂任务中的潜力。"
  },
  {
    "id": "fill-1",
    "type": "fill",
    "question": "人工智能的核心能力包括获取信息（学习）、得出结论（______）、自我修正（反馈）、模式识别。",
    "answer": "推理",
    "hint": "学习是输入，推理是加工输出，像大脑思考的过程～",
    "explanation": "人工智能的四大核心能力对应人类智能的关键过程：学习（获取信息）、推理（基于信息得出结论）、反馈（自我修正）、模式识别（感知和分类信息）。这四个能力是AI系统模拟人类智能的基础，也是区分AI与普通程序的核心特征——普通程序仅能执行预设指令，而AI能通过这四大能力实现“类人思考”。"
  },
  {
    "id": "fill-2",
    "type": "fill",
    "question": "专家系统的架构由用户界面、______和知识库三部分组成，其中前者被称为“推理大脑”。",
    "answer": "规则引擎",
    "hint": "知识库是“参考书”，规则引擎是“解题思路”～",
    "explanation": "专家系统的核心架构包括：用户界面（与用户交互）、规则引擎（核心推理模块，相当于“推理大脑”，根据知识库中的规则进行决策）、知识库（存储特定领域的专家知识）。典型案例MYCIN（诊断细菌感染）和XCON（配置计算机系统）均采用该架构，其瓶颈在于知识获取困难（隐性知识难以转化为规则）和脆弱性（超出领域即失效）。"
  },
  {
    "id": "fill-3",
    "type": "fill",
    "question": "机器学习三大类中，______通过与环境交互的“奖励/惩罚”机制学习最优策略，典型应用包括游戏AI和机器人控制。",
    "answer": "强化学习",
    "hint": "像驯兽师训练动物，做对给奖励，做错给惩罚～",
    "explanation": "强化学习（Reinforcement Learning）的核心是智能体与环境交互，通过奖励信号（正反馈）和惩罚信号（负反馈）调整策略，最终学习到最优行为。与监督学习（依赖标签）、无监督学习（依赖数据结构）不同，强化学习强调“试错学习”。典型应用包括AlphaGo的自我对弈、自动驾驶中的路径规划、游戏AI的决策优化。"
  },
  {
    "id": "fill-4",
    "type": "fill",
    "question": "当代AI的四大新兴趋势包括多模态AI、高效AI、可信AI和______，后者追求更广泛的推理和迁移学习能力。",
    "answer": "通用智能",
    "hint": "终极目标是让AI成为“全能管家”，而非“单项冠军”～",
    "explanation": "AI未来四大趋势中，通用智能（General Intelligence）是核心目标之一，旨在实现人类水平的跨领域认知能力，让AI能像人一样理解、学习和处理各种未见过的复杂问题（如贾维斯）。目前AI仍处于弱人工智能阶段，通用智能尚未实现，需要突破常识推理、跨领域迁移学习等瓶颈。其他三大趋势分别解决：多模态AI（整合多种感官信息）、高效AI（降低算力成本）、可信AI（确保公平透明）。"
  },
  {
    "id": "qa-1",
    "type": "qa",
    "question": "简述人工智能三大层级（弱AI、通用AI、超AI）的核心定义及主要区别。",
    "answer": "1. 弱人工智能（Narrow AI）：专为特定任务设计，无跨领域泛化能力，仅能完成预设任务（如Siri、AlphaGo），是目前已实现的AI形态；2. 通用人工智能（General AI）：具备人类水平认知能力，能跨领域理解、学习和处理复杂问题（如贾维斯），目前仍处于理论研究阶段；3. 超人工智能（Super AI）：在所有领域超越人类智能的假设性存在，智力远超人类认知极限，属于遥远未来的推测。主要区别在于：①认知范围（特定领域vs跨领域vs全领域）；②能力水平（任务限定vs人类水平vs超人类水平）；③实现状态（已实现vs未实现vs假设性）。",
    "hint": "记住关键词：弱AI=单项冠军，通用AI=全能管家，超AI=神级存在～",
    "explanation": "AI三大层级的划分基于智能的“泛化能力”和“水平高度”，是理解AI发展阶段的核心框架。弱AI是当前技术主流，聚焦单一任务（如图像识别、语音助手），缺乏常识和自主决策能力；通用AI需要突破常识推理、跨领域学习等瓶颈，是AI研究的长期目标；超AI则是对未来智能的极端假设，涉及伦理、安全等深层问题。这一划分帮助避免对当前AI能力的过度高估（如认为弱AI具备意识）或低估（如忽视通用AI的发展潜力）。"
  },
  {
    "id": "qa-2",
    "type": "qa",
    "question": "分析第一次AI寒冬（1974-1980）的主要成因，并说明这些成因对当代AI发展的启示。",
    "answer": "第一次AI寒冬的主要成因包括：1. 算力限制：组合爆炸导致简单任务需指数级资源，硬件无法支撑；2. 常识缺失：机器缺乏背景知识和直觉，无法处理人类习以为常的琐事；3. 资金削减：ALPAC报告（批评机器翻译）和Lighthill报告（批评AI不切实际）导致信任破产，投资方撤资。对当代AI发展的启示：①平衡预期：避免过度炒作，客观看待技术边界；②重视基础设施：算力和数据是AI发展的关键，需持续投入硬件和数据建设；③突破核心瓶颈：常识推理、跨领域泛化等基础问题需长期攻关；④务实落地：聚焦具体场景的实用价值，避免追求“万能AI”。",
    "hint": "AI寒冬=理想丰满+硬件骨感+承诺落空，当代要“脚踏实地”～",
    "explanation": "第一次AI寒冬是AI发展史上的重要转折点，暴露了早期符号主义AI的局限性：依赖手动编码规则，无法应对复杂现实场景。其启示对当代AI仍有重要意义：①算力方面，摩尔定律和GPU/TPU的发展解决了早期算力不足问题，但高效AI仍需降低算力消耗；②数据方面，大数据时代为机器学习提供了充足“燃料”，但数据质量和隐私问题需重视；③技术路线方面，从“手动编码规则”转向“数据驱动学习”是范式转移的关键，证明了“学习优于手写”；④产业方面，AI应用需聚焦落地场景（如医疗、工业），避免脱离实际的“空中楼阁”。"
  },
  {
    "id": "qa-3",
    "type": "qa",
    "question": "说明机器学习与传统符号主义AI的核心差异，并分别列举机器学习的三大类型及其核心机制。",
    "answer": "一、核心差异：1. 技术路线：符号主义AI是“自上而下”的规则驱动（手动编码知识和逻辑），机器学习是“自下而上”的数据驱动（从数据中自动学习模式）；2. 知识表示：符号主义依赖显式的符号和规则，机器学习依赖隐式的模型参数；3. 泛化能力：符号主义仅能处理预设规则内的任务（脆弱性），机器学习具备一定的跨场景泛化能力；4. 学习方式：符号主义需人工更新规则，机器学习可自主从数据中迭代优化。二、机器学习三大类型及机制：1. 监督学习：从带标签数据中学习输入→输出的映射关系（如图像分类），核心是“有老师辅导的刷题”；2. 无监督学习：从无标签数据中发现隐藏结构（如聚类），核心是“无人指导的分类”；3. 强化学习：通过与环境交互的奖励/惩罚机制学习最优策略（如游戏AI），核心是“试错学习”。",
    "hint": "符号主义=背手册，机器学习=刷真题，三大类型=有老师、无老师、驯兽师～",
    "explanation": "符号主义AI与机器学习的差异本质是“规则驱动”与“数据驱动”的范式之争。符号主义在20世纪50-70年代主导AI领域，但因常识缺失和脆弱性陷入寒冬；机器学习（尤其是深度学习）在90年代后崛起，凭借数据和算力的支撑，在感知、生成等任务中取得突破。机器学习的三大类型覆盖了不同的学习场景：监督学习适用于有明确目标的任务（如预测、分类），无监督学习适用于探索数据结构（如用户分群），强化学习适用于动态决策场景（如机器人控制）。这一分类为AI应用提供了清晰的技术选型框架，是当代AI工程实践的基础。"
  },
  // 第二章——AI智能体
    {
      "id": "choice-1",
      "type": "choice",
      "question": "AI智能体的核心循环顺序正确的是？",
      "options": [
        "行动(Action) → 感知(Perception) → 思考(Thinking) → 循环(Loop)",
        "感知(Perception) → 思考(Thinking) → 行动(Action) → 循环(Loop)",
        "思考(Thinking) → 感知(Perception) → 行动(Action) → 循环(Loop)",
        "感知(Perception) → 行动(Action) → 思考(Thinking) → 循环(Loop)"
      ],
      "answer": 1,
      "hint": "先看再想后动手，像人类一样不冲动～",
      "explanation": "AI智能体的核心循环遵循“感知-思考-行动-循环”的逻辑（对应选项B）。感知是通过传感器获取环境信息（如眼睛看、耳朵听），思考是对感知信息进行决策分析，行动是通过执行器作用于环境，最后重复循环持续互动。选项A、C、D颠倒了感知、思考、行动的顺序，不符合智能体与环境交互的基本逻辑。例如吸尘器智能体先感知“当前位置是否脏”（感知），再决定“吸尘或移动”（思考），最后执行动作（行动），并持续循环。"
    },
    {
      "id": "choice-2",
      "type": "choice",
      "question": "下列哪种场景属于“部分可观测”环境？",
      "options": [
        "下象棋时观察棋盘所有棋子位置",
        "打扑克时看不到对手的手牌",
        "解数独时查看所有空白格子",
        "按照食谱步骤做菜"
      ],
      "answer": 1,
      "hint": "看不到全部信息=部分可观测，像猜盲盒～",
      "explanation": "部分可观测环境的定义是传感器无法检测到环境的所有状态（对应选项B）。打扑克时，玩家只能看到自己的牌，无法获取对手的手牌，属于部分可观测；选项A（下象棋）、C（解数独）能看到全部状态，属于完全可观测；选项D（按食谱做菜）属于确定性环境，与可观测性无关。环境的可观测性是智能体设计的重要前提，部分可观测环境需要智能体具备推理隐藏状态的能力。"
    },
    {
      "id": "choice-3",
      "type": "choice",
      "question": "PEAS设计框架中，“P”对应的核心要素是？",
      "options": [
        "Performance Measure（性能度量）",
        "Environment（环境）",
        "Perception（感知）",
        "Program（程序）"
      ],
      "answer": 0,
      "hint": "PEAS首字母P=Performance，成功的标准呀～",
      "explanation": "PEAS框架是智能体设计的核心四要素，分别对应：P（Performance Measure，性能度量，即成功的标准）、E（Environment，环境）、A（Actuators，执行器）、S（Sensors，传感器）（对应选项A）。选项B是“E”的含义，选项C是智能体核心循环的第一步，选项D并非PEAS框架的要素。例如出租车智能体的性能度量包括安全、快速、合法、利润最大化，直接决定智能体的行动优先级。"
    },
    {
      "id": "choice-4",
      "type": "choice",
      "question": "软件智能体与传统函数（Functions）的核心区别不包括？",
      "options": [
        "智能体具有状态维持能力，函数“算完就忘”",
        "智能体可自主决策行动时机，函数需被动调用",
        "智能体依赖数据驱动，函数依赖规则驱动",
        "智能体是“长寿”的持续运行实体，函数是“短命”的单次执行任务"
      ],
      "answer": 2,
      "hint": "核心区别是“长寿+自主+有记忆”，和驱动方式无关～",
      "explanation": "软件智能体与传统函数的核心区别包括：①状态维持（智能体有记忆，函数无）；②自主性（智能体主动行动，函数被动调用）；③生命周期（智能体持续运行，函数单次执行）（对应选项A、B、D）。选项C“数据驱动vs规则驱动”是机器学习与符号主义AI的区别，并非智能体与函数的差异——智能体和函数都可能是数据驱动或规则驱动（如规则型智能体、数据驱动型函数）。直观理解：函数像外卖员（送完即结束），智能体像私人管家（持续服务、记喜好）。"
    },
    {
      "id": "choice-5",
      "type": "choice",
      "question": "ReAct模式的核心逻辑顺序是？",
      "options": [
        "观察(Observation) → 思考(Thought) → 行动(Action) → 循环",
        "思考(Thought) → 观察(Observation) → 行动(Action) → 循环",
        "思考(Thought) → 行动(Action) → 观察(Observation) → 循环",
        "行动(Action) → 思考(Thought) → 观察(Observation) → 循环"
      ],
      "answer": 2,
      "hint": "先想思路，再动手做，最后看结果～ 像做题一样！",
      "explanation": "ReAct模式的核心逻辑是“思考-行动-观察-循环”（对应选项C）：①思考（明确目标和行动方向，如“需要查某公司营收”）；②行动（执行具体操作，如调用搜索工具）；③观察（获取行动结果，如搜索结果）；④循环（根据观察调整思考和行动）。该模式解决了大模型实时信息获取和“幻觉”问题，模拟人类解题的思维过程。选项A、B、D颠倒了思考、行动、观察的顺序，不符合ReAct的设计初衷。"
    },
    {
      "id": "choice-6",
      "type": "choice",
      "question": "RAG智能体（检索增强生成）的核心目的不包括？",
      "options": [
        "解决大模型“知识截止期”问题",
        "减少大模型的“幻觉”（一本正经胡说八道）",
        "降低模型的训练成本，无需重新训练",
        "提升模型的推理速度，减少计算资源消耗"
      ],
      "answer": 3,
      "hint": "RAG是“开卷考试”，补知识不提速～",
      "explanation": "RAG智能体的核心优势包括：①解决知识截止期（通过外挂知识库更新信息）；②减少幻觉（基于真实文档生成答案）；③无需重新训练（通过检索补充知识，降低训练成本）（对应选项A、B、C）。选项D“提升推理速度”并非RAG的核心目的，反而检索过程可能增加少量延迟。RAG的关键流程是“离线准备（文档切块→向量化→存入向量库）+在线检索（检索→增强→生成）”，本质是给大模型“开卷考试”的机会，而非优化速度。"
    },
    {
      "id": "choice-7",
      "type": "choice",
      "question": "下列哪项不属于Agentic AI的核心特征？",
      "options": [
        "极少的人类干预，高度自主",
        "仅能被动响应用户查询，无法主动决策",
        "能够处理多步复杂任务",
        "主动使用工具辅助完成目标"
      ],
      "answer": 1,
      "hint": "Agentic AI是“项目经理”，不是“问答机器”～",
      "explanation": "Agentic AI的核心特征包括：①高度自主性（极少人类干预）；②处理多步复杂任务；③主动使用工具（对应选项A、C、D）。选项B“被动响应查询”是传统聊天机器人的特征，与Agentic AI“主动决策、搞定过程”的定位相反。直观理解：Agentic AI从“我问你答”进化为“我说目标，你搞定过程”，例如自主帮用户订机票（需查询、对比、下单多步操作）。"
    },
    {
      "id": "choice-8",
      "type": "choice",
      "question": "思维树（Tree-of-Thoughts, ToT）模式的核心逻辑是？",
      "options": [
        "重复生成多个答案，选择出现次数最多的",
        "探索多条推理路径，预演后果后选择最优解",
        "生成草稿后自我评估并修改",
        "将任务拆解为子步骤，逐一执行并验证"
      ],
      "answer": 1,
      "hint": "像下棋预演几步，选最稳的走法～",
      "explanation": "思维树（ToT）模式的核心是探索多条推理路径，像下棋一样预演后续步骤，再选择最优解（对应选项B）。选项A是“自我一致性”模式的逻辑；选项C是“Reflexion”模式的逻辑；选项D是“计划-执行-验证”模式的逻辑。ToT解决了大模型单一推理路径易出错的问题，通过多路径探索提升复杂任务的成功率，例如数学解题、逻辑推理等场景。"
    },
    {
      "id": "fill-1",
      "type": "fill",
      "question": "AI智能体的官方定义是：任何通过______感知环境，并通过执行器作用于环境以实现目标的实体。",
      "answer": "传感器",
      "hint": "人类用眼睛耳朵感知，智能体用“电子感官”～",
      "explanation": "AI智能体的核心组成包括传感器（感知环境）和执行器（作用于环境）：传感器是智能体的“感官”，如摄像头、GPS、麦克风等，用于获取环境状态信息；执行器是智能体的“手脚”，如方向盘、机械臂、喇叭等，用于执行决策后的行动。该定义强调智能体与环境的交互能力，区别于单纯的静态模型（如仅生成文本的大模型）。"
    },
    {
      "id": "fill-2",
      "type": "fill",
      "question": "环境分类的六大维度中，______维度关注“当前决策是否影响未来决策”，对应的两类环境是片段式和序列式。",
      "answer": "片段式 vs 序列式",
      "hint": "这单干完是否影响下单？是就是序列式～",
      "explanation": "片段式 vs 序列式是环境分类的核心维度之一，核心判断标准是“当前决策是否影响未来决策”：片段式环境中，每个任务独立（如辨认单张照片），决策不影响后续；序列式环境中，当前决策会持续影响未来（如下围棋、开车），需考虑长期后果。该维度直接决定智能体的决策逻辑——序列式环境需要智能体具备长期规划和记忆能力。"
    },
    {
      "id": "fill-3",
      "type": "fill",
      "question": "Reflexion模式的核心流程是：生成草稿→______→根据评估修改→输出，通过“内部批评家”提升结果质量。",
      "answer": "自我评估",
      "hint": "像写作文自己先检查，改完再交～",
      "explanation": "Reflexion模式的核心是“自省与自纠”，通过增加自我评估环节解决大模型输出不精准的问题：①生成草稿（初步结果）；②自我评估（分析不足，如“逻辑不连贯”“数据错误”）；③修改优化（根据评估调整）；④输出最终结果。该模式模拟人类“复盘”行为，尤其适用于写作、解题等需要高精度输出的场景，能有效降低错误率。"
    },
    {
      "id": "fill-4",
      "type": "fill",
      "question": "RAG智能体的离线准备阶段包括文档切块、向量化和______三个关键步骤，为在线检索提供基础。",
      "answer": "存入向量数据库",
      "hint": "切好的“知识点”要放进专门的“数字书架”～",
      "explanation": "RAG智能体的离线准备阶段是实现高效检索的前提，三步流程缺一不可：①文档切块（将长文档拆分为短片段，便于精准匹配）；②向量化（将文本转化为计算机可理解的数字向量，捕捉语义信息）；③存入向量数据库（专门存储向量的数据库，支持快速相似性检索）。在线检索时，系统会将用户提问向量化后，在向量数据库中查找最相关的文本片段，再结合大模型生成答案，从而减少幻觉、更新知识。"
    },
    {
      "id": "fill-5",
      "type": "fill",
      "question": "多智能体协作模式的核心逻辑是让不同智能体扮演不同角色，像组建一个全AI的“______”，共同完成复杂任务。",
      "answer": "创业团队",
      "hint": "有人写代码、有人测Bug，分工合作效率高～",
      "explanation": "多智能体协作是Agentic AI的新兴设计模式之一，核心是“分工协作”：将复杂任务拆解为多个子任务，每个智能体负责特定角色（如编程智能体写代码、测试智能体查Bug、文档智能体写说明），像创业团队一样各司其职、协同完成目标。该模式解决了单一智能体能力边界有限的问题，适用于复杂项目（如自主研发、多步骤业务处理），提升任务完成的效率和质量。"
    },
    {
      "id": "qa-1",
      "type": "qa",
      "question": "简述AI智能体的核心定义、核心循环及数学表达，并举例说明经典的“吸尘器世界”智能体如何体现这些要素。",
      "answer": "1. 核心定义：任何通过传感器感知环境，并通过执行器作用于环境以实现目标的实体；2. 核心循环：感知(Perception) → 思考/决策(Thinking) → 行动(Action) → 循环(Loop)；3. 数学表达：$f: P^* \rightarrow A$（将感知历史序列$P^*$映射到行动$A$的函数）。举例：吸尘器世界智能体（两个方格A/B，状态“脏/干净”）：①感知：通过传感器获取“当前位置（A/B）”和“环境状态（脏/干净）”（如感知结果[A, Dirty]）；②思考：根据感知判断行动（脏则吸尘，干净则移动）；③行动：通过执行器执行吸尘、左移、右移等动作；④循环：持续感知环境变化，重复上述流程，最终实现“清洁所有方格”的目标。",
      "hint": "定义抓“传感器+执行器+目标”，循环记“看-想-做-循环”～",
      "explanation": "AI智能体的核心是“与环境的动态交互”，区别于静态模型（如计算器）：①定义强调“感知-行动”闭环，传感器和执行器是物理基础；②核心循环体现了智能体的自主性和持续性，而非单次响应；③数学表达抽象了智能体的本质——输入是历史感知信息，输出是具体行动。吸尘器世界是最简化的智能体案例，直观展示了“感知环境→决策→行动”的闭环，帮助理解复杂智能体的设计逻辑（如自动驾驶、机器人管家）的核心原理。"
    },
    {
      "id": "qa-2",
      "type": "qa",
      "question": "详细说明PEAS设计框架的四要素及其含义，并以“自主研究智能体”为例，逐一对应说明各要素的具体内容。",
      "answer": "PEAS框架是智能体设计的核心四要素，含义如下：1. P（Performance Measure，性能度量）：智能体成功的评价标准；2. E（Environment，环境）：智能体运行的外部空间及相关要素；3. A（Actuators，执行器）：智能体作用于环境的工具或手段；4. S（Sensors，传感器）：智能体感知环境的设备或渠道。以“自主研究智能体”为例：①性能度量：报告的准确性、信息的全面性、完成时间；②环境：互联网、学术数据库、文档管理系统；③执行器：浏览器（检索信息）、文本编辑器（写报告）、数据库查询工具（获取文献）；④传感器：网络爬虫（获取网页信息）、文献阅读器（读取学术论文）、关键词检索工具（筛选相关资料）。",
      "hint": "PEAS=成功标准+工作环境+干活工具+感知渠道，缺一不可～",
      "explanation": "PEAS框架是设计智能体的第一步，明确四要素能避免智能体设计的模糊性：①性能度量决定智能体的行动优先级（如自主研究智能体优先保证报告准确性，而非速度）；②环境定义了智能体的交互边界（如仅能访问公开学术数据库）；③执行器是智能体的“手脚”，决定了它能做什么（如能否编辑文档、调用工具）；④传感器是智能体的“感官”，决定了它能获取什么信息（如能否爬取网页、读取PDF）。该框架适用于所有智能体设计场景（如出租车、客服、编程智能体），是AI工程实践的基础工具。"
    },
    {
      "id": "qa-3",
      "type": "qa",
      "question": "对比ReAct、Reflexion、RAG三种LLM智能体架构的核心逻辑、解决痛点及适用场景，说明它们的本质区别。",
      "answer": "三种架构的核心差异如下：1. ReAct模式：①核心逻辑：思考(Thought)→行动(Action)→观察(Observation)→循环；②解决痛点：大模型无法获取实时信息、易产生幻觉；③适用场景：需要实时交互、调用工具的任务（如查实时数据、订机票）；2. Reflexion模式：①核心逻辑：生成草稿→自我评估→修改→输出；②解决痛点：大模型输出不精准、逻辑不连贯；③适用场景：需要高精度输出的任务（如写论文、解题）；3. RAG模式：①核心逻辑：离线准备（文档切块→向量化→存向量库）+在线检索（检索→增强→生成）；②解决痛点：大模型知识截止期、幻觉问题；③适用场景：需要最新知识、基于特定文档的任务（如企业知识库问答、学术研究）。本质区别：ReAct聚焦“与环境交互”，Reflexion聚焦“自我优化”，RAG聚焦“外部知识补充”，分别解决LLM在交互、精度、知识更新上的核心短板。",
      "hint": "ReAct=互动干活，Reflexion=自我纠错，RAG=开卷考试～",
      "explanation": "三种架构都是为了解决LLM的固有缺陷，但侧重点不同：①ReAct通过“思考-行动-观察”的闭环，让LLM具备与外部工具（如搜索引擎、API）交互的能力，突破了大模型“闭门造车”的限制；②Reflexion通过“自我评估-修改”的流程，让LLM具备复盘纠错能力，提升输出质量；③RAG通过外挂知识库，让LLM无需重新训练即可获取最新知识，同时减少幻觉（基于真实文档生成）。在实际应用中，三种架构可结合使用（如RAG+ReAct：检索知识后调用工具验证；Reflexion+RAG：基于检索到的资料生成答案后自我修正），形成更强大的智能体系统。"
    },
	// 第三章
	
	  {
	    "id": "choice_001",
	    "type": "choice",
	    "question": "目标导向智能体的核心特征是？",
	    "options": [
	      "仅对环境刺激做出本能反应",
	      "为达成特定目标选择一系列行动序列",
	      "只能处理单一固定任务",
	      "依赖外部实时反馈调整状态"
	    ],
	    "answer": 1,
	    "hint": "目标导向=有明确目的地+规划路线～",
	    "explanation": "根据资料定义，目标导向智能体是为了达成特定目标，必须选择一系列行动序列的智能体。选项A描述的是反射型智能体，选项C忽略了智能体的目标导向性（可处理多目标任务），选项D强调实时反馈，而目标导向智能体核心是行动序列规划而非实时反馈。补充背景：目标导向智能体是AI解决问题的核心基础，类似人类为了买房而制定的工作、储蓄等一系列计划。"
	  },
	  {
	    "id": "choice_002",
	    "type": "choice",
	    "question": "问题形式化的四大支柱不包括以下哪项？",
	    "options": [
	      "状态空间",
	      "启发式函数",
	      "目标测试",
	      "路径代价"
	    ],
	    "answer": 1,
	    "hint": "四大支柱是盲目搜索的基础，启发式是“有提示”的搜索～",
	    "explanation": "资料明确指出问题形式化的四大支柱为状态空间、目标测试、后继函数、路径代价。选项B的启发式函数是启发式搜索的核心要素，用于引导搜索方向，不属于盲目搜索依赖的问题形式化支柱。补充背景：问题形式化是将实际问题转化为AI可处理的数学模型，四大支柱缺一不可，就像盖房子需要地基、墙体、屋顶、门窗的完整结构。"
	  },
	  {
	    "id": "choice_003",
	    "type": "choice",
	    "question": "广度优先搜索（BFS）采用的数据结构是？",
	    "options": [
	      "栈（LIFO）",
	      "队列（FIFO）",
	      "优先队列",
	      "哈希表"
	    ],
	    "answer": 1,
	    "hint": "BFS=涟漪扩散，先到先得，排队买奶茶既视感～",
	    "explanation": "资料明确BFS的核心机制是“探索当前深度所有节点后再下一层”，数据结构为队列，遵循先进先出（FIFO）原则。选项A是DFS的数据结构，选项C是UCS的数据结构，选项D用于快速查找，不用于BFS的节点存储。补充背景：队列的FIFO特性保证了BFS的层级遍历，就像排队结账，先排队的人先处理，确保不会跳过当前层级的节点。"
	  },
	  {
	    "id": "choice_004",
	    "type": "choice",
	    "question": "以下哪项不是BFS的关键特性？",
	    "options": [
	      "完备性（存在解时一定能找到）",
	      "最优性（路径最短，当每步代价相同时）",
	      "时间复杂度为O(n)（线性级）",
	      "空间复杂度为O(b^d)（指数级）"
	    ],
	    "answer": 2,
	    "hint": "BFS虽稳但费钱（时间+空间），指数级复杂度了解一下～",
	    "explanation": "资料指出BFS的时间复杂度和空间复杂度均为O(b^d)（b为分支因子，d为解的深度），属于指数级复杂度，而非选项C的线性级O(n)。选项A、B、D均为BFS的核心特性：完备性确保解的存在性，最优性在等代价场景下成立，指数级复杂度是其最大缺点（处理大规模问题时效率低下）。补充背景：分支因子b是每个节点的平均子节点数，比如二叉树的b=2，当d=20时，b^d=2^20≈100万，可见其资源消耗之大。"
	  },
	  {
	    "id": "choice_005",
	    "type": "choice",
	    "question": "深度优先搜索（DFS）的核心机制是？",
	    "options": [
	      "优先探索累积代价最低的路径",
	      "基于递归和回溯，尽可能深地探索分支",
	      "同时从起点和终点双向搜索",
	      "逐步增加深度限制进行迭代搜索"
	    ],
	    "answer": 1,
	    "hint": "DFS=铁头娃，一条道走到黑，走不通再回头～",
	    "explanation": "资料明确DFS的核心机制是“基于递归和回溯的算法，尽可能深地探索分支”。选项A是UCS的机制，选项C是双向搜索的机制，选项D是IDS的机制。补充背景：递归用于深入探索分支，回溯用于在死胡同时返回上一节点，类似走迷宫时贴着墙走，直到无路可走再折返。"
	  },
	  {
	    "id": "choice_006",
	    "type": "choice",
	    "question": "深度受限搜索（DLS）设定深度限制的主要目的是？",
	    "options": [
	      "提高搜索的最优性",
	      "防止DFS陷入无限循环或搜索过深",
	      "减少搜索的时间复杂度",
	      "增强搜索的完备性"
	    ],
	    "answer": 1,
	    "hint": "DLS=给DFS系安全带，防止跑太远～",
	    "explanation": "资料指出DLS是DFS的变体，设定深度限制的目的是“防止DFS陷入无限循环或搜索过深”。选项A错误（DLS不保证最优性），选项C错误（深度限制可能增加时间复杂度，如限制过浅需重复搜索），选项D错误（DLS可能因限制过浅错过解，完备性不如BFS）。补充背景：当搜索空间无限深时，DFS会一直探索无法终止，DLS的深度限制相当于“强制回头信号”，平衡探索深度和效率。"
	  },
	  {
	    "id": "choice_007",
	    "type": "choice",
	    "question": "迭代加深搜索（IDS）结合了哪两种算法的优点？",
	    "options": [
	      "BFS和DFS",
	      "DFS和UCS",
	      "BFS和双向搜索",
	      "UCS和启发式搜索"
	    ],
	    "answer": 0,
	    "hint": "IDS=先近后远的试探，既有BFS的稳，又有DFS的省～",
	    "explanation": "资料明确IDS“结合了BFS和DFS的优点”，通过逐步增加深度限制（类似BFS的层级遍历），每一轮进行DLS（类似DFS的深度探索）。选项B、C、D均不符合定义：UCS强调代价优先，双向搜索强调双向同时搜索，启发式搜索依赖额外信息，均未被IDS结合。补充背景：IDS解决了BFS耗内存和DFS不完备的问题，适用于未知目标深度的大规模搜索场景。"
	  },
	  {
	    "id": "choice_008",
	    "type": "choice",
	    "question": "一致代价搜索（UCS）用于以下哪种场景？",
	    "options": [
	      "无权重的图遍历，追求路径最短",
	      "加权图遍历，追求累积代价最低",
	      "快速找到任意解，不关心代价",
	      "需要同时从起点和终点搜索"
	    ],
	    "answer": 1,
	    "hint": "UCS=精打细算的穷游党，只选最省钱的路～",
	    "explanation": "资料指出UCS“用于遍历加权图（边的成本不同），总是优先探索累积成本最低的路径”。选项A是BFS的场景（边代价相同），选项C是DFS的场景（不考虑代价），选项D是双向搜索的场景。补充背景：UCS的优先队列会根据路径累积代价排序，确保每次取出的都是当前最优路径节点，适用于导航路线规划（考虑时间、过路费等不同代价）。"
	  },
	  {
	    "id": "choice_009",
	    "type": "choice",
	    "question": "双向搜索停止的条件是？",
	    "options": [
	      "其中一个搜索达到深度限制",
	      "两个搜索的节点集合产生交集",
	      "起始节点的所有邻居都被访问",
	      "队列中不再有未访问节点"
	    ],
	    "answer": 1,
	    "hint": "双向搜索=双向奔赴，相遇即终止～",
	    "explanation": "资料明确双向搜索“同时进行两个搜索：一个从起点向后搜，一个从终点向前搜，当两个搜索在中间相遇（交集）时停止”。选项A是DLS的终止条件，选项C是BFS单轮探索的结束条件，选项D是BFS/DFS整体终止条件。补充背景：双向搜索通过减少搜索空间（从O(b^d)降至O(b^(d/2))）提高效率，类似两人从两端找对方，相遇时的路径就是解。"
	  },
	  {
	    "id": "choice_010",
	    "type": "choice",
	    "question": "以下哪项应用场景属于BFS的典型用途？",
	    "options": [
	      "数独游戏求解",
	      "网络爬虫按层级建立索引",
	      "检测图中的环",
	      "拓扑排序"
	    ],
	    "answer": 1,
	    "hint": "BFS=层级扩散，爬虫爬网页就是一层一层来～",
	    "explanation": "资料列出BFS的应用场景包括“网络爬虫：按层级建立索引，从源页面一层层爬取链接”。选项A、C、D均为DFS的应用场景：数独求解依赖回溯（DFS核心），图中环检测和拓扑排序均需深度探索分支。补充背景：BFS的层级遍历特性适合需要按“距离”或“层级”处理的场景，除了网络爬虫，还包括P2P网络邻居发现、GPS周边兴趣点查找等。"
	  },
	  {
	    "id": "fill_001",
	    "type": "fill",
	    "question": "目标导向智能体是为了达成特定目标，必须选择一系列________的智能体。",
	    "options": [],
	    "answer": "行动序列",
	    "hint": "目标+行动组合，就像旅游前规划的行程单～",
	    "explanation": "资料明确目标导向智能体的定义为“为了达成特定目标，必须选择一系列行动序列的智能体”。核心关键词“行动序列”体现了智能体的规划性，区别于无目标的反射型行为。补充背景：行动序列是AI解决问题的核心，每个行动都是从当前状态向目标状态的一步推进，如密室逃脱中“开门→找钥匙→解锁”的连续行动。"
	  },
	  {
	    "id": "fill_002",
	    "type": "fill",
	    "question": "问题形式化的四大支柱包括状态空间、目标测试、后继函数和________。",
	    "options": [],
	    "answer": "路径代价",
	    "hint": "四大支柱=环境+判断+选项+成本，缺一不可～",
	    "explanation": "资料明确问题形式化的四大支柱为“状态空间、目标测试、后继函数、路径代价”。路径代价是衡量行动成本的关键，直接影响搜索算法的最优性判断（如UCS优先选择代价低的路径）。补充背景：路径代价的度量可以是时间、距离、金钱等，如导航中“耗时”“过路费”均属于路径代价的具体形式。"
	  },
	  {
	    "id": "fill_003",
	    "type": "fill",
	    "question": "广度优先搜索（BFS）的时间复杂度和空间复杂度均为________（用公式表示）。",
	    "options": [],
	    "answer": "O(b^d)",
	    "hint": "指数级复杂度，b是分支因子，d是解的深度～",
	    "explanation": "资料指出BFS的时间复杂度和空间复杂度均为O(b^d)，其中b为每个节点的平均分支因子，d为目标状态的深度。该公式体现了BFS的指数级增长特性，当问题规模较大时（d增大），资源消耗会急剧增加。补充背景：例如在二叉树（b=2）中，若解的深度d=10，需处理的节点数约为2^10=1024；d=20时则约为100万，可见其效率限制。"
	  },
	  {
	    "id": "fill_004",
	    "type": "fill",
	    "question": "深度优先搜索（DFS）采用的数据结构是________，遵循后进先出（LIFO）原则。",
	    "options": [],
	    "answer": "栈",
	    "hint": "DFS=先进后出，栈就像叠盘子，最后放的先拿～",
	    "explanation": "资料明确DFS的核心机制是“基于递归和回溯的算法，数据结构为栈（Stack），遵循后进先出（LIFO）原则”。栈的LIFO特性保证了DFS能“一条道走到黑”，即最后加入的节点（最深层节点）先被探索。补充背景：递归实现的DFS本质上是利用程序调用栈来存储节点，手动实现时需显式使用栈数据结构管理待探索节点。"
	  },
	  {
	    "id": "fill_005",
	    "type": "fill",
	    "question": "当所有边的代价都相同时，一致代价搜索（UCS）等同于________算法。",
	    "options": [],
	    "answer": "广度优先搜索（BFS）",
	    "hint": "等代价场景下，UCS的“省钱”和BFS的“短路”是一回事～",
	    "explanation": "资料指出“如果所有边的代价都相同，UCS就等同于BFS”。因为当边代价相同时，累积代价最低的路径就是步数最少的路径，这与BFS的最优性（路径最短）完全一致。补充背景：UCS是BFS的泛化形式，BFS是UCS在边代价均为1时的特例，两者均保证最优性，但UCS更适用于边代价不同的加权图场景。"
	  },
	  {
	    "id": "fill_006",
	    "type": "fill",
	    "question": "双向搜索通过同时从起点和终点进行搜索，当两个搜索的________时停止，以减少搜索空间。",
	    "options": [],
	    "answer": "节点集合产生交集（相遇）",
	    "hint": "双向奔赴的终点就是“相遇”呀～",
	    "explanation": "资料明确双向搜索的核心机制是“同时进行两个搜索：一个从起点向后搜，一个从终点向前搜，当两个搜索在中间相遇（交集）时停止”。交集的出现意味着找到了从起点到终点的路径，此时搜索空间仅为单向搜索的平方根级，大幅提高效率。补充背景：例如从A到B的单向搜索需探索O(b^d)个节点，双向搜索仅需探索O(b^(d/2))个节点，适用于大规模图的路径规划。"
	  },
	  {
	    "id": "qa_001",
	    "type": "qa",
	    "question": "请简述问题形式化的四大支柱及其核心作用。",
	    "options": [],
	    "answer": "问题形式化的四大支柱包括：1. 状态空间：系统可能处于的所有状态的集合，定义了AI操作的环境范围；2. 目标测试：判断当前状态是否为目标状态的标准，用于终止搜索；3. 后继函数：给定状态下所有可能的行动集合，提供状态转移的选项；4. 路径代价：状态转移的成本度量，用于评估路径的优劣。",
	    "hint": "四大支柱=环境范围+终止判断+行动选项+成本评估，记准每个的“职责”～",
	    "explanation": "四大支柱是AI将实际问题转化为数学模型的核心框架：状态空间明确“能在哪里操作”，目标测试明确“什么时候结束”，后继函数明确“能做什么动作”，路径代价明确“哪个动作更好”。缺少任何一个支柱，搜索算法都无法有效工作（如无路径代价则无法判断最优解，无后继函数则无法推进状态）。补充背景：例如“从家到公司”的问题形式化中，状态空间是所有途经的道路节点，目标测试是“是否到达公司”，后继函数是“每个路口的转向选项”，路径代价是“各路段的耗时”。"
	  },
	  {
	    "id": "qa_002",
	    "type": "qa",
	    "question": "对比广度优先搜索（BFS）和深度优先搜索（DFS）的核心区别（至少3点）。",
	    "options": [],
	    "answer": "BFS和DFS的核心区别包括：1. 数据结构：BFS用队列（FIFO），DFS用栈（LIFO）；2. 探索策略：BFS按层级遍历（先近后远），DFS深度优先（一条道走到黑）；3. 完备性：BFS具备完备性（存在解必找到），DFS不具备（可能陷入无限深度）；4. 最优性：BFS具备最优性（等代价下路径最短），DFS不具备；5. 空间复杂度：BFS空间复杂度高（存储当前层所有节点），DFS空间复杂度低（存储当前路径节点）；6. 应用场景：BFS适用于层级遍历（如爬虫、邻居发现），DFS适用于回溯求解（如数独、拓扑排序）。",
	    "hint": "记住：BFS稳（完备最优）但费内存，DFS省内存但不稳～",
	    "explanation": "两者的核心区别源于探索策略的不同：BFS的层级遍历保证了解的完整性和最优性，但需要存储当前所有层级的节点，内存消耗大；DFS的深度探索节省内存，但可能因搜索空间无限而无法终止，且找到的解不一定是最短路径。补充背景：实际应用中，需根据问题特性选择：若需确保找到最短路径（如GPS导航），选BFS；若问题规模大但只需任意解（如数独），选DFS。"
	  },
	  {
	    "id": "qa_003",
	    "type": "qa",
	    "question": "请简述一致代价搜索（UCS）的核心工作原理。",
	    "options": [],
	    "answer": "UCS的核心工作原理包括：1. 适用场景：遍历加权图（边的代价不同）；2. 数据结构：使用优先队列（按路径累积代价排序）；3. 探索策略：总是优先取出优先队列中累积代价最低的节点进行探索；4. 状态转移：对当前节点的所有后继节点，计算从起点到该后继节点的累积代价，若该代价低于已知记录，则更新并加入优先队列；5. 终止条件：当取出的节点为目标状态时，返回该节点的路径（即累积代价最低的最优路径）。",
	    "hint": "UCS=精打细算，永远走最省钱的路，优先队列是它的“计算器”～",
	    "explanation": "UCS的核心是“代价优先”，区别于BFS的“步数优先”。优先队列的排序机制确保了每次探索的都是当前最优路径节点，即使该节点处于较深的层级。补充背景：UCS是解决加权图最短路径问题的经典算法，例如导航中考虑时间、过路费等不同代价时，UCS能规划出最经济的路线；当所有边代价相同时，UCS自动退化为BFS，体现了算法的泛化性。"
	  },
	  {
	    "id": "qa_004",
	    "type": "qa",
	    "question": "盲目搜索和启发式搜索的核心区别是什么？请分别举例说明。",
	    "options": [],
	    "answer": "核心区别：是否使用额外的领域知识（启发式信息）引导搜索方向。1. 盲目搜索：仅使用问题定义中的信息（状态空间、目标测试等），无额外提示，如BFS、DFS、UCS；例如在漆黑房间找出口，只能摸索前进，无任何光线提示。2. 启发式搜索：利用问题领域的额外知识（如目标的大致方向、距离估计）引导搜索，优先探索更可能接近目标的路径，如A*算法；例如寻宝时使用罗盘（启发式信息）知道宝藏方向，优先向该方向搜索，而非盲目摸索。",
	    "hint": "盲目=无提示（盲人摸象），启发式=有导航（寻宝罗盘）～",
	    "explanation": "两者的本质区别在于搜索的“方向性”：盲目搜索是“无导向的遍历”，所有路径被探索的概率相同，效率较低；启发式搜索是“有导向的探索”，通过启发式函数评估节点到目标的距离，优先探索距离近的节点，大幅提高效率。补充背景：启发式信息的质量直接影响搜索效率，例如A*算法的曼哈顿距离、欧氏距离都是常用的启发式函数，适用于路径规划、拼图求解等场景；而盲目搜索因不依赖额外信息，适用于领域知识匮乏的问题。"
	  },
	// 第四章
	
	  {
	    "id": "q1",
	    "type": "choice",
	    "question": "启发式搜索策略的核心组件是什么？",
	    "options": [
	      "启发式函数 h(n)",
	      "估值函数 v(n)",
	      "代价函数 c(n)",
	      "路径函数 p(n)"
	    ],
	    "answer": 0,
	    "hint": "寻宝罗盘的核心是指针，启发式搜索的核心是它的“预估工具”～",
	    "explanation": "启发式搜索的核心是利用问题领域的特定知识引导搜索，而这一功能通过启发式函数 h(n) 实现。h(n) 用于估算当前节点到目标节点的最小代价，是启发式搜索区别于盲目搜索的关键。其他选项中，估值函数常见于博弈算法（如Minimax），代价函数多指代实际消耗（如g(n)），路径函数并非启发式搜索的核心组件，因此正确答案为A。"
	  },
	  {
	    "id": "q2",
	    "type": "choice",
	    "question": "贪婪最佳优先搜索的评估函数 f(n) 是什么？",
	    "options": [
	      "f(n) = h(n)",
	      "f(n) = g(n)",
	      "f(n) = g(n) + h(n)",
	      "f(n) = max(g(n), h(n))"
	    ],
	    "answer": 0,
	    "hint": "急功近利的赶路人只看前方，不回头看走了多远～",
	    "explanation": "贪婪最佳优先搜索的核心策略是“只关注未来距离”，因此评估函数仅依赖启发式函数 h(n)（预估剩余距离），不考虑已花费的代价 g(n)（已走路程）。选项B是仅考虑过去代价的策略，选项C是A*搜索的评估函数，选项D无实际算法对应，因此正确答案为A。"
	  },
	  {
	    "id": "q3",
	    "type": "choice",
	    "question": "A*搜索算法中，可采纳性（Admissibility）的核心要求是？",
	    "options": [
	      "h(n) ≥ h*(n)",
	      "h(n) ≤ h*(n)",
	      "h(n) = h*(n)",
	      "h(n) ≠ h*(n)"
	    ],
	    "answer": 1,
	    "hint": "乐观预估才靠谱，高估困难会错过最佳路径哦～",
	    "explanation": "可采纳性是A*算法最优性的前提，其定义为启发式函数 h(n) 永远不大于实际到达目标的代价 h*(n)（即 h(n) ≤ h*(n)）。这意味着预估代价是“乐观的”，不会高估实际难度，从而保证A*不会因误判而放弃最优路径。选项A是“高估”情况，会导致A*失去最优性；选项C是完全准确预估，属于可采纳性的特殊情况而非核心要求；选项D无意义，因此正确答案为B。"
	  },
	  {
	    "id": "q4",
	    "type": "choice",
	    "question": "Minimax算法主要应用于以下哪种场景？",
	    "options": [
	      "单人决策优化问题",
	      "两人对抗的零和博弈",
	      "多目标优化问题",
	      "无信息盲目搜索问题"
	    ],
	    "answer": 1,
	    "hint": "预判对手的预判，适合“你输我赢”的游戏～",
	    "explanation": "Minimax算法的核心是处理两人对抗的零和博弈，其特点是完美信息、轮流行动、一方收益即另一方损失（如井字棋、国际象棋）。选项A适合启发式搜索或动态规划；选项C需要多目标优化算法（如NSGA系列）；选项D是盲目搜索的应用场景，与Minimax无关，因此正确答案为B。"
	  },
	  {
	    "id": "q5",
	    "type": "choice",
	    "question": "Alpha-Beta剪枝的触发条件是什么？",
	    "options": [
	      "α > β",
	      "α ≥ β",
	      "α < β",
	      "α ≤ β"
	    ],
	    "answer": 1,
	    "hint": "老板觉得新方案顶多赚80，不如现有100，直接叫停～",
	    "explanation": "Alpha-Beta剪枝的核心规则是当 α ≥ β 时触发剪枝。其中，α 是MAX方的最优选择下界（越大越好），β 是MIN方的最优选择上界（越小越好）。当 α ≥ β 时，当前分支的最优可能已经低于已发现的最优路径，继续搜索无意义，因此触发剪枝。选项A是剪枝的充分条件但非核心规则（核心规则包含等于情况），选项C和D不会触发剪枝，因此正确答案为B。"
	  },
	  {
	    "id": "q6",
	    "type": "choice",
	    "question": "当启发式函数 h(n) = 0 时，启发式搜索会退化为？",
	    "options": [
	      "盲目搜索",
	      "A*搜索",
	      "贪婪最佳优先搜索",
	      "Minimax算法"
	    ],
	    "answer": 0,
	    "hint": "寻宝罗盘指针不动了，跟没罗盘一样瞎转悠～",
	    "explanation": "启发式搜索的核心是 h(n) 提供的“预估信息”，当 h(n) = 0 时，意味着没有任何启发式信息引导搜索，此时算法会退化为盲目搜索（如广度优先、深度优先搜索）。选项B的A*搜索需要 h(n) 和 g(n) 共同作用，选项C的贪婪搜索依赖 h(n) ≠ 0，选项D是博弈算法，与启发式搜索退化无关，因此正确答案为A。"
	  },
	  {
	    "id": "q7",
	    "type": "choice",
	    "question": "A*搜索算法具备最优性的前提是什么？",
	    "options": [
	      "h(n) 不可采纳",
	      "h(n) 可采纳",
	      "g(n) 为负数",
	      "h(n) 为负数"
	    ],
	    "answer": 1,
	    "hint": "靠谱的预估才能规划出最优路线，不然容易走弯路～",
	    "explanation": "A*算法的最优性依赖于启发式函数 h(n) 的可采纳性（h(n) ≤ h*(n)）。可采纳的 h(n) 保证了算法不会高估剩余代价，从而不会错过代价更小的最优路径。选项A会导致A*失去最优性；选项C和D违反了启发式函数“非负”的基本要求（h(n) 和 g(n) 均为非负），因此正确答案为B。"
	  },
	  {
	    "id": "q8",
	    "type": "choice",
	    "question": "Alpha-Beta剪枝在最理想情况下的时间复杂度是？",
	    "options": [
	      "O(b^m)",
	      "O(b^(m/2))",
	      "O(b^2m)",
	      "O(m^b)"
	    ],
	    "answer": 1,
	    "hint": "剪枝就是“砍树枝”，最理想情况能少看一半的节点～",
	    "explanation": "Minimax算法的时间复杂度为 O(b^m)（b为分支因子，m为最大深度）。Alpha-Beta剪枝通过排除无意义分支，在最理想情况下（先检查最优移动），时间复杂度可降低至 O(b^(m/2))，相当于计算能力不变时，搜索深度翻倍。选项A是Minimax的时间复杂度，选项C和D无实际算法对应，因此正确答案为B。"
	  },
	  {
	    "id": "q9",
	    "type": "fill",
	    "question": "启发式搜索中，曼哈顿距离的计算方式是坐标差的______之和。",
	    "options": [],
	    "answer": "绝对值",
	    "hint": "城市里开车不能斜着走，坐标差得“取正”才能相加～",
	    "explanation": "曼哈顿距离模拟城市街区移动（只能横向或纵向），其计算公式为：d = |x1 - x2| + |y1 - y2|，核心是坐标差的“绝对值”之和。若忽略绝对值，会出现正负抵消的错误，因此空缺处应填“绝对值”。"
	  },
	  {
	    "id": "q10",
	    "type": "fill",
	    "question": "贪婪最佳优先搜索的策略是总是选择当前______离目标最近的节点进行扩展。",
	    "options": [],
	    "answer": "看起来",
	    "hint": "急功近利的人只看“表面”，不考虑实际情况～",
	    "explanation": "贪婪最佳优先搜索的核心是“短视”策略，仅根据 h(n)（预估剩余距离）判断，选择“看起来”离目标最近的节点，而不考虑该节点的实际路径代价（如是否为死胡同）。因此空缺处应填“看起来”，强调其基于预估而非实际情况的选择逻辑。"
	  },
	  {
	    "id": "q11",
	    "type": "fill",
	    "question": "A*搜索算法的评估函数 f(n) 由______和 h(n) 组成，其中前者表示从起点到当前节点的实际代价。",
	    "options": [],
	    "answer": "g(n)",
	    "hint": "总代价 = 已走路程 + 预计剩程，已走路程就是g(n)～",
	    "explanation": "A*算法的评估函数定义为 f(n) = g(n) + h(n)。其中 g(n) 是从起点到当前节点 n 的实际代价（已消耗资源），h(n) 是从 n 到目标节点的预估代价（剩余资源）。两者结合使A*既能考虑过去的消耗，又能引导未来的方向，因此空缺处应填“g(n)”。"
	  },
	  {
	    "id": "q12",
	    "type": "fill",
	    "question": "Minimax算法中，MAX角色的目标是让______的分数最大化，而MIN角色则使其最小化。",
	    "options": [],
	    "answer": "估值函数",
	    "hint": "下棋时双方都在“打分”，MAX要争最高分～",
	    "explanation": "Minimax算法通过估值函数评估博弈节点的优劣（如赢为正分、输为负分）。MAX角色（我方）的目标是选择估值函数分数最大的行动，MIN角色（对手）则选择分数最小的行动，模拟双方的最优对抗。因此空缺处应填“估值函数”。"
	  },
	  {
	    "id": "q13",
	    "type": "fill",
	    "question": "Alpha-Beta剪枝中，Alpha是MAX方目前发现的“最好选择”的______，表示至少能获得的分数。",
	    "options": [],
	    "answer": "下界",
	    "hint": "老板的底线是“至少赚100”，这个底线就是下界～",
	    "explanation": "Alpha-Beta剪枝中，Alpha 定义为 MAX 方当前找到的最优路径的最低分数（下界），且会随着搜索过程不断更新（越大越好）；Beta 是 MIN 方当前找到的最优路径的最高分数（上界），会不断减小（越小越好）。当 α ≥ β 时，当前分支无意义，触发剪枝。因此空缺处应填“下界”。"
	  },
	  {
	    "id": "q14",
	    "type": "qa",
	    "question": "简述A*搜索算法与贪婪最佳优先搜索的核心区别。",
	    "options": [],
	    "answer": "两者的核心区别在于评估函数和决策逻辑：1. 评估函数不同：贪婪最佳优先搜索的 f(n) = h(n)，仅考虑未来的预估代价；A*的 f(n) = g(n) + h(n)，同时考虑过去的实际代价（g(n)）和未来的预估代价（h(n)）；2. 决策逻辑不同：贪婪搜索“短视”，仅选择当前看起来离目标最近的节点，不考虑实际路径是否最优或存在死胡同；A*“全局考量”，选择总预估代价最小的节点，在 h(n) 可采纳的前提下能保证最优性；3. 算法特性不同：贪婪搜索不完备、不最优；A*搜索完备且最优（前提是 h(n) 可采纳）。",
	    "hint": "一个只看前方，一个既看身后也看前方～",
	    "explanation": "两者的本质区别是是否考虑“已消耗代价”：贪婪搜索忽略 g(n)，导致决策短视，容易陷入死胡同或非最优路径；A*结合 g(n) 和 h(n)，既避免了盲目探索，又能通过可采纳的 h(n) 保证找到最优解。例如，从A到B有两条路：一条看似直线但有高墙（贪婪会选），一条绕路但无阻碍（A*会选，因总代价更小），这体现了两者的核心差异。"
	  },
	  {
	    "id": "q15",
	    "type": "qa",
	    "question": "说明Minimax算法的核心流程，并解释其角色定义。",
	    "options": [],
	    "answer": "核心流程：1. 生成博弈树：从当前状态出发，递归生成所有可能的行动路径，直到终端状态（游戏结束，如赢、输、平局）；2. 计算效用值：为所有终端节点分配效用值（如赢为+10，输为-10，平局为0）；3. 回溯传递：自底向上遍历博弈树，MAX节点选择子节点中的最大效用值，MIN节点选择子节点中的最小效用值，最终根节点的取值即为当前状态下的最优行动。角色定义：1. MAX（我方）：目标是最大化估值函数/效用值，代表主动寻求胜利的一方；2. MIN（对手）：目标是最小化估值函数/效用值，代表阻碍我方胜利、寻求自身胜利的一方，假设对手会采取最优对抗策略。",
	    "hint": "先画所有可能的走法，再从最后一步倒着推最优选择～",
	    "explanation": "Minimax算法的核心是“预判对手行为”：通过生成完整博弈树，假设对手（MIN）会做出对我方（MAX）最不利的选择，因此从终端状态回溯时，MAX取最大值（选对自己最有利的），MIN取最小值（选对MAX最不利的）。例如井字棋中，我方落子后，会考虑对手所有可能的堵位，再选择对手堵位后我方仍能赢的落子方式，这正是Minimax的流程体现。"
	  },
	  {
	    "id": "q16",
	    "type": "qa",
	    "question": "解释Alpha-Beta剪枝的核心目标和剪枝规则，并说明节点排序对其效率的影响。",
	    "options": [],
	    "answer": "核心目标：对Minimax算法进行优化，在不改变最终决策结果的前提下，减少需要搜索的节点数量，从而提升算法效率（更快搜索或搜索更深层次）。剪枝规则：1. 定义参数：Alpha（α）是MAX方当前的最优选择下界（至少能获得的分数，越大越好）；Beta（β）是MIN方当前的最优选择上界（至多会失去的分数，越小越好）；2. 触发条件：当 α ≥ β 时，当前分支的最优可能已低于已发现的最优路径，继续搜索无意义，触发剪枝。节点排序的影响：节点排序直接决定剪枝效率——若先搜索最优移动（MAX先看高分节点，MIN先看低分节点），能尽早更新α和β，触发更多剪枝，最理想情况下时间复杂度从 O(b^m) 降至 O(b^(m/2))；若先搜索较差移动，α和β更新缓慢，剪枝效果差，甚至接近Minimax的原始复杂度。",
	    "hint": "剪枝就像砍没用的树枝，先看最好的树枝能砍更多～",
	    "explanation": "Alpha-Beta剪枝的本质是“排除无效分支”：例如MAX已找到一个能得10分的路径（α=10），当搜索另一个分支时，MIN节点的子节点最高分为8（β=8），此时 α ≥ β，该分支无论后续如何，都不可能超过10分，因此可直接剪枝。节点排序的关键是“尽早找到最优解”，让α和β快速达到剪枝条件，从而减少无效计算，这是提升剪枝效率的核心因素。"
	  },
	  // 第五章
	  
	    {
	      "id": "KR-choice-001",
	      "type": "choice",
	      "question": "下列关于知识表示的核心定义，表述最准确的是？",
	      "options": [
	        "将原始数据存储在计算机中的技术",
	        "用计算机可利用的形式存储信息，使系统能通过推理解决复杂问题",
	        "对信息进行分类和整理的过程",
	        "计算机进行逻辑推理的具体算法"
	      ],
	      "answer": 1,
	      "hint": "知识表示不是“存数据”，而是教计算机“理解世界”哦～",
	      "explanation": "知识表示的核心是让计算机以可利用的形式存储信息，关键在于支持推理解决复杂问题，而非单纯存储数据（A错误）、分类整理信息（C错误）或推理算法本身（D错误）。它的本质是“教计算机理解世界”，使信息能够被用于推导新结论，这是AI系统实现智能决策的基础。"
	    },
	    {
	      "id": "KR-choice-002",
	      "type": "choice",
	      "question": "“骑自行车时，若车身向左倾斜则将龙头向左拐”属于哪种类型的知识？",
	      "options": [
	        "陈述性知识",
	        "过程性知识",
	        "元知识",
	        "启发式知识"
	      ],
	      "answer": 1,
	      "hint": "记住：“是什么”是陈述性，“怎么做”是过程性～",
	      "explanation": "过程性知识描述“怎么做”的规则、策略和步骤，题干中的内容是具体的操作技巧，符合过程性知识的定义（B正确）。陈述性知识是“是什么”的事实（如“自行车有两个轮子”，A错误）；元知识是“关于知识的知识”（如“我知道骑行技巧需要练习”，C错误）；启发式知识是基于经验的直觉法则（如“骑行时保持重心稳定不容易倒”，D错误）。"
	    },
	    {
	      "id": "KR-choice-003",
	      "type": "choice",
	      "question": "某KR系统能根据“所有哺乳动物都是恒温动物”和“猫是哺乳动物”，自动得出“猫是恒温动物”，这体现了该系统的哪种属性？",
	      "options": [
	        "表示充分性",
	        "推理充分性",
	        "推理效率",
	        "获取效率"
	      ],
	      "answer": 1,
	      "hint": "能从已知推未知，这是“脑子转得动”的表现～",
	      "explanation": "推理充分性指系统利用现有知识推导出新知识的能力，题干中系统通过两个前提得出新结论，符合该属性（B正确）。表示充分性强调能否表示所需知识类型（如是否能描述“恒温动物”的概念，A错误）；推理效率关注推导速度和方向（如是否快速找到推导路径，C错误）；获取效率指新增知识的难易程度（如是否容易添加“狗是哺乳动物”的知识，D错误）。"
	    },
	    {
	      "id": "KR-choice-004",
	      "type": "choice",
	      "question": "命题逻辑的主要局限性是什么？",
	      "options": [
	        "无法处理真/假逻辑判断",
	        "不能表达具体的对象和关系",
	        "只能使用AND和OR两个连接词",
	        "无法与计算机编程结合"
	      ],
	      "answer": 1,
	      "hint": "命题逻辑像“固定句子”，一阶逻辑像“带参数的函数”～",
	      "explanation": "命题逻辑仅处理简单的真/假陈述句（命题），无法表达具体对象（如“特定的猫”）和对象间的关系（如“猫比老鼠大”），这是其核心局限性（B正确）。命题逻辑的核心就是处理真/假判断（A错误），它支持AND、OR、NOT、Implication、Equivalence五种连接词（C错误），其逻辑规则可用于计算机编程中的条件判断（D错误）。"
	    },
	    {
	      "id": "KR-choice-005",
	      "type": "choice",
	      "question": "在一阶逻辑中，全称量词（∀）通常搭配哪种连接词使用？",
	      "options": [
	        "∧ (AND)",
	        "∨ (OR)",
	        "⇒ (Implication)",
	        "⇔ (Equivalence)"
	      ],
	      "answer": 2,
	      "hint": "全称量词是“所有都满足”，蕴含关系是“如果A则B”，天生一对～",
	      "explanation": "全称量词（∀）表示“所有对象都满足某条件”，通常搭配蕴含连接词（⇒），例如“∀x Cat(x) ⇒ Mammal(x)”（所有猫都是哺乳动物），表示“对于任意x，若x是猫，则x是哺乳动物”（C正确）。存在量词（∃）通常搭配AND连接词（如“∃x Color(x, Red)”，存在红色的东西），OR和Equivalence很少与全称量词搭配使用（A、B、D错误）。"
	    },
	    {
	      "id": "KR-choice-006",
	      "type": "choice",
	      "question": "语义网络中“Is-A”关系的核心作用是什么？",
	      "options": [
	        "描述对象的具体属性（如“猫有尾巴”）",
	        "表示继承关系（如“麻雀是鸟”）",
	        "定义事件的发生顺序（如“先下雨后地湿”）",
	        "区分不同类型的知识（如“陈述性vs过程性”）"
	      ],
	      "answer": 1,
	      "hint": "Is-A = “是一种”，比如“苹果是水果”，自然能继承水果的属性～",
	      "explanation": "语义网络中的“Is-A”关系表示“个体属于类别”或“子类属于父类”的继承关系，例如“麻雀Is-A鸟”，则麻雀可继承鸟的属性（如“有翅膀”，B正确）。描述对象属性的是“Has-A”关系（如“猫Has-A尾巴”，A错误）；描述事件顺序需通过其他关系（如“Before”，C错误）；区分知识类型与语义网络的关系无关（D错误）。"
	    },
	    {
	      "id": "KR-choice-007",
	      "type": "choice",
	      "question": "下列哪种知识表示方法最接近编程中的“对象（Object）”概念？",
	      "options": [
	        "命题逻辑",
	        "语义网络",
	        "框架（Frames）",
	        "产生式规则"
	      ],
	      "answer": 2,
	      "hint": "框架是“填表”，对象是“属性+值”，都是打包好的信息单元～",
	      "explanation": "框架（Frames）将某个对象的所有典型信息集合在一个单元中，包含“槽（属性名称）”和“填充物（属性值）”，与编程中“对象=属性+方法”的结构高度相似（C正确）。命题逻辑是简单真/假陈述（A错误）；语义网络是节点和弧的图形结构（B错误）；产生式规则是“IF-THEN”的条件反射式结构（D错误）。"
	    },
	    {
	      "id": "KR-choice-008",
	      "type": "choice",
	      "question": "“先确定论文论点（目标），再查找资料寻找论据支持”，这种思维方式对应的推理机制是？",
	      "options": [
	        "正向推理",
	        "反向推理",
	        "启发式推理",
	        "结构化推理"
	      ],
	      "answer": 1,
	      "hint": "正向是“从事实到结论”，反向是“从结论到事实”，论文写作是先定结论哦～",
	      "explanation": "反向推理是目标驱动的推理，从目标出发反向寻找支持该目标的证据，题干中“先定论点（目标），再找论据（证据）”符合反向推理的逻辑（B正确）。正向推理是数据驱动，从已知事实出发推导结论（如福尔摩斯探案，A错误）；启发式推理是基于经验法则的推理（如“燕子低飞要下雨”，C错误）；结构化推理不是独立的推理机制（D错误）。"
	    },
	    {
	      "id": "KR-fill-001",
	      "type": "fill",
	      "question": "知识库代理（Knowledge-Based Agent）的循环包括：感知（Perceive）、学习更新（Learn/Update）、______和行动（Act）四个步骤。",
	      "answer": "推理（Reason）",
	      "hint": "感知世界后，要“思考”才能行动，这个思考过程就是推理～",
	      "explanation": "知识库代理的核心循环是“感知-学习-推理-行动”：通过感知获取外部信息，学习更新知识库，基于现有知识推理得出结论，最后执行相应行动。推理是连接知识与行动的关键环节，没有推理就无法将知识转化为决策。"
	    },
	    {
	      "id": "KR-fill-002",
	      "type": "fill",
	      "question": "优秀KR系统的四大属性分别是：表示充分性、推理充分性、推理效率和______。",
	      "answer": "获取效率（Acquisitional Efficiency）",
	      "hint": "前三个是“能不能表示、能不能推理、推理快不快”，最后一个是“学新知识容易不容易”～",
	      "explanation": "获取效率指KR系统获取和插入新信息的难易程度，是衡量系统实用性的重要指标。如果添加新知识需要重写整个代码库，说明获取效率低，无法适应动态变化的知识需求。"
	    },
	    {
	      "id": "KR-fill-003",
	      "type": "fill",
	      "question": "命题逻辑的核心连接词包括：∧（AND）、∨（OR）、¬（NOT）、⇒（Implication）和______（Equivalence）。",
	      "answer": "⇔",
	      "hint": "Equivalence是“当且仅当”，符号像两个方向的箭头，记住“双向蕴含”～",
	      "explanation": "命题逻辑的五大连接词分别对应不同的逻辑关系：AND（同时为真）、OR（至少一个为真）、NOT（取反）、Implication（如果A则B）、Equivalence（A当且仅当B）。⇔是Equivalence的符号表示，用于表达两个命题之间的等价关系。"
	    },
	    {
	      "id": "KR-fill-004",
	      "type": "fill",
	      "question": "框架（Frames）的核心结构由“槽（Slots）”和______（Fillers/Facets）组成，其中槽表示属性名称，后者表示属性的值。",
	      "answer": "填充物",
	      "hint": "槽是“表格的栏目”，填充物就是“栏目里填的内容”～",
	      "explanation": "框架是结构化的知识表示方法，槽（Slots）定义了对象的属性（如“姓名”“年龄”），填充物（Fillers）是属性的具体值（如“张三”“25岁”），填充物还可以是数据、过程或另一个框架，使框架能灵活表示复杂对象的信息。"
	    },
	    {
	      "id": "KR-fill-005",
	      "type": "fill",
	      "question": "推理机制的两大核心方向是______（数据驱动，从事实推导结论）和反向推理（目标驱动，从目标寻找证据）。",
	      "answer": "正向推理（Forward Chaining）",
	      "hint": "正向是“顺着事实往下推”，就像侦探从线索找凶手～",
	      "explanation": "正向推理以已知事实为起点，不断应用规则推导新结论，直到达到目标，属于数据驱动的推理方式（如从“脚印+烟灰”推导出“凶手是谁”）。它与反向推理（目标驱动）互为补充，适用于不同的问题场景。"
	    },
	    {
	      "id": "KR-qa-001",
	      "type": "qa",
	      "question": "简述数据（Data）、信息（Information）和知识（Knowledge）的区别与联系，并各举一个例子。",
	      "answer": "区别：1. 数据是原始的、未处理的数字或字符（如“37, 38”）；2. 信息是经过处理、具有含义的数据（如“体温37度，体温38度”）；3. 知识是经过整合、能指导行动的信息（如“体温38度意味着发烧，需要吃药”）。联系：数据是信息的基础，信息是知识的前提，三者是从原始到有用、从零散到系统的递进关系。",
	      "hint": "记住“数据无意义，信息有含义，知识能行动”的口诀～",
	      "explanation": "数据是最底层的原始素材，不包含任何上下文或含义；信息通过对数据进行解释和处理，赋予其意义（如给数字“38”加上“体温”的上下文，就成为信息）；知识则是对信息的进一步整合和提炼，包含了因果关系、规则等，能够指导实际行动（如根据“体温38度”的信息，得出“需要吃药”的决策）。三者的递进关系是AI系统实现智能的基础：先收集数据，再转化为信息，最后构建为知识。"
	    },
	    {
	      "id": "KR-qa-002",
	      "type": "qa",
	      "question": "对比一阶逻辑（First-Order Logic）与命题逻辑（Propositional Logic）的核心差异，说明一阶逻辑表达能力更强的原因。",
	      "answer": "核心差异：1. 命题逻辑处理简单的真/假陈述句（命题），无法表达具体对象和关系；一阶逻辑引入了对象、谓词和量词，能表达更复杂的语义。2. 命题逻辑是“固定值”式的逻辑（如“天上下雨”）；一阶逻辑是“带参数”式的逻辑（如“∃x Cloud(x) ∧ RainUnder(x)”，存在某朵云下面在下雨）。表达能力更强的原因：一阶逻辑通过常量（具体对象）、变量（任意对象）、谓词（关系/属性）和量词（所有/存在），突破了命题逻辑“只能描述整体事实”的限制，能够精确描述个体、个体间的关系以及普遍/特殊情况，适用于更复杂的知识表示场景。",
	      "hint": "命题逻辑是“小学生造句”，一阶逻辑是“大学生写论文”，表达更细致～",
	      "explanation": "命题逻辑的局限性在于只能处理整体层面的真/假判断，无法区分具体对象（如“猫”和“特定的猫Tom”），也无法描述对象间的关系（如“Tom抓老鼠”）。而一阶逻辑通过引入核心要素：常量（Tom、Mouse）、变量（x、y）、谓词（Catch(x,y)）、量词（∀、∃），能够将逻辑表达从“整体事实”细化到“个体及关系”，例如“∃x ∃y (Cat(x) ∧ Mouse(y) ∧ Catch(x,y))”（存在一只猫和一只老鼠，猫抓老鼠），这种精细化的表达能力使一阶逻辑能覆盖更广泛的知识场景，成为AI中最常用的逻辑表示法之一。"
	    },
	    {
	      "id": "KR-qa-003",
	      "type": "qa",
	      "question": "简述正向推理与反向推理的逻辑流程、核心特点，并各举一个适用场景。",
	      "answer": "一、正向推理：1. 逻辑流程：从已知事实出发，匹配知识库中的规则，推导新事实，重复该过程直到得出结论（数据驱动）；2. 核心特点：发散性强，能发现多个可能结论，但效率较低（可能推导无关信息）；3. 适用场景：故障诊断（如从设备异常现象推导故障原因）、侦探探案（从线索推导凶手）。二、反向推理：1. 逻辑流程：从目标结论出发，反向寻找支持该结论的规则和证据，若所有证据都满足则目标成立（目标驱动）；2. 核心特点：针对性强，效率高（聚焦目标），但需要明确的目标；3. 适用场景：论文写作（从论点寻找论据）、数学证明（从结论推导前提条件）、医疗诊断（从疑似疾病寻找症状证据）。",
	      "hint": "正向是“顺藤摸瓜”，反向是“按图索骥”，场景对应“找原因”和“证结论”～",
	      "explanation": "正向推理的关键是“从事实到结论”，不需要预先明确目标，适合探索性问题（如“根据设备的异常声音、温度升高，判断哪里出了问题”），但可能会推导大量与最终目标无关的中间结论，导致效率较低。反向推理的关键是“从结论到事实”，需要先明确目标，再针对性地寻找证据，适合验证性问题（如“怀疑患者得了流感，寻找发烧、咳嗽等症状证据”），效率更高但依赖于目标的明确性。两种推理机制在AI系统中常结合使用，以兼顾探索性和效率。"
	    },
		
	  // 第六章
	  
	  {"id":"ml-choice-01","type":"choice","question":"以下哪项是机器学习的核心逻辑？","options":["规则+数据=答案","数据+答案=规则","规则+答案=数据","数据+规则=答案"],"answer":1,"hint":"记牢：传统是“给食谱做菜”，ML是“尝菜反推食谱”","explanation":"机器学习的核心逻辑与传统编程存在本质区别。传统编程是先定义明确的规则，输入数据后得到答案，即“规则+数据=答案”；而机器学习是通过已知的数据和对应的答案，反向学习总结出潜在规则，用于后续未知数据的预测，即“数据+答案=规则”。选项A是传统编程的逻辑，选项C、D为逻辑混乱的干扰项。"},
	  {"id":"ml-choice-02","type":"choice","question":"根据Tom Mitchell的定义，机器学习程序的改进依赖于哪个核心要素？","options":["固定的规则库","大量的硬件资源","经验E","预设的标签集"],"answer":2,"hint":"T-E-P三件套，核心是“经验”驱动进步","explanation":"Tom Mitchell对机器学习的定义明确：若一个程序在任务T上的性能P随着经验E而提高，则该程序具备学习能力。其中，经验E是程序性能提升的核心驱动因素，比如下棋程序通过大量对弈（经验E）提升赢棋概率（性能P）。选项A是传统编程的依赖要素，选项B是深度学习的运行需求，选项D是监督学习的特定数据要求，均非该定义的核心依赖。"},
	  {"id":"ml-choice-03","type":"choice","question":"以下哪种学习类型使用“标记数据”进行训练？","options":["无监督学习","监督学习","强化学习","半监督学习"],"answer":1,"hint":"“标记数据”=带标准答案，像有老师辅导～","explanation":"监督学习的核心特征是使用带有标签（即标准答案）的标记数据进行训练，学习输入到输出的映射关系，类似学生做带答案的练习题。选项A无监督学习使用未标记数据，选项C强化学习依赖环境的奖励/惩罚信号，选项D半监督学习是监督与无监督的结合（少量标记+大量未标记数据），均不符合题干要求。"},
	  {"id":"ml-choice-04","type":"choice","question":"下列哪项属于监督学习中的回归任务？","options":["判断邮件是否为垃圾邮件","预测明天的气温","将客户分群","训练机器人握手"],"answer":1,"hint":"回归是“连续数值”，分类是“离散类别”，记准啦！","explanation":"监督学习包含分类和回归两大任务：分类预测离散的类别（如“是/否”“A/B/C类”），回归预测连续的数值（如温度、价格、时间等）。选项A属于分类任务，选项C属于无监督学习的聚类任务，选项D属于强化学习任务，只有选项B（预测气温，连续数值）符合回归任务的定义。"},
	  {"id":"ml-choice-05","type":"choice","question":"深度学习与传统机器学习相比，最核心的优势之一是？","options":["训练速度更快","需要的数据量更少","可自动提取特征","仅需普通CPU即可运行"],"answer":2,"hint":"深度学习是“聪明的自动提取工”，不用人工费劲找特征","explanation":"深度学习的关键特征是能够自动从原始数据中提取特征，无需人工干预；而传统机器学习需要专家手工进行特征工程，耗时耗力。选项A错误，深度学习训练速度极慢（可能需几周），传统机器学习训练快；选项B错误，深度学习需要海量数据，传统机器学习在小数据量下表现良好；选项D错误，深度学习高度依赖高端GPU，传统机器学习可在普通CPU运行。"},
	  {"id":"ml-choice-06","type":"choice","question":"人工神经网络的“深度”主要体现在哪个部分？","options":["输入层的数量","隐藏层的数量","输出层的神经元数量","特征的维度"],"answer":1,"hint":"“深”就深在中间的“隐藏层”多，像多层接力赛～","explanation":"人工神经网络由输入层、隐藏层和输出层组成。深度学习之所以“深”，核心是因为包含多个隐藏层，信息需经过多层隐藏层的加工处理，才能从原始数据中提炼出抽象特征。输入层仅负责接收原始数据，输出层负责输出结果，二者数量与“深度”无关；特征维度是数据本身的属性，并非网络深度的体现。"},
	  {"id":"ml-choice-07","type":"choice","question":"下列哪项应用不属于计算机视觉的范畴？","options":["人脸识别","自动驾驶汽车的环境感知","虚拟助手Siri的语音交互","医学影像分析"],"answer":2,"hint":"计算机视觉是让电脑“看”，语音交互是让电脑“听”～","explanation":"计算机视觉的核心是教会电脑“看”世界，主要应用包括人脸识别、自动驾驶环境感知、医学影像分析等。选项C中虚拟助手的语音交互属于自然语言处理（NLP）的范畴，自然语言处理的核心是让电脑“理解”和“交互”人类语言，与“视觉”无关。其他三个选项均为计算机视觉的典型应用。"},
	  {"id":"ml-fill-01","type":"fill","question":"Tom Mitchell对机器学习的定义中，程序在____（任务T）上的性能____（性能P）随着____（经验E）而提高。","answer":"任务T、性能P、经验E","hint":"记成“特工（T）派（P）经验（E）”，轻松搞定三个字母～","explanation":"Tom Mitchell的定义是机器学习领域的经典定义，明确了机器学习的核心三要素：任务（T）、性能（P）、经验（E）。该定义的核心逻辑是“经验驱动性能提升”，比如下棋程序（任务T=下棋）的赢棋概率（性能P）会随着对弈次数（经验E）的增加而提高。这三个要素是理解机器学习本质的关键，必须准确记忆。"},
	  {"id":"ml-fill-02","type":"fill","question":"无监督学习的核心任务是____，即把相似的事物按照隐藏模式分组。","answer":"聚类","hint":"“聚”就是凑一堆，无监督就是自己找“同类”～","explanation":"无监督学习使用未标记数据训练，模型需自主发现数据中的隐藏结构。聚类是其最主要的任务，核心是基于数据的内在相似性（如大小、颜色、特征值）将数据分组，比如电商平台的客户分群（按消费习惯将客户分为不同群体）。除聚类外，无监督学习还有降维等任务，但聚类是最核心、最典型的任务。"},
	  {"id":"ml-fill-03","type":"fill","question":"在机器学习术语中，____是用来训练模型的“课本”，____是用来检验模型效果的“期末试卷”。","answer":"训练集、测试集","hint":"“训练”是学习过程（看课本），“测试”是考核过程（考试卷）～","explanation":"数据集是机器学习的基础，通常分为训练集和测试集。训练集的作用是供模型学习规则，就像学生学习用的课本；测试集的作用是评估模型的泛化能力（对未知数据的预测能力），就像检验学习效果的期末试卷。两者需严格区分，不能混淆使用，否则会导致模型评估结果不准确。"},
	  {"id":"ml-fill-04","type":"fill","question":"强化学习中，智能体通过与____互动，依据____或____信号学习最佳策略。","answer":"环境、奖励、惩罚","hint":"像训练狗狗：环境是家里，奖励是肉干，惩罚是批评～","explanation":"强化学习的核心逻辑是“交互反馈学习”。智能体（如训练的狗狗、自动驾驶汽车）需要处于特定环境中，通过执行动作与环境互动；环境会根据动作的正确性给出反馈——正确动作获得奖励，错误动作获得惩罚。智能体通过不断积累这种反馈，逐渐学习到能最大化奖励的最佳策略。环境、奖励、惩罚是强化学习的三个核心要素。"},
	  {"id":"ml-qa-01","type":"qa","question":"请简述机器学习与传统编程的核心逻辑差异，并分别用做菜的比喻说明。","answer":"核心逻辑差异：传统编程是“规则+数据=答案”；机器学习是“数据+答案=规则”。做菜比喻：传统编程——给机器人详细食谱（规则）和食材（数据），机器人照着做出菜（答案）；机器学习——给机器人尝一万道好吃的菜（数据+答案），让它反推总结食谱（规则），后续能做出新菜。","hint":"记住“谁是输入、谁是输出”，比喻记牢“食谱”和“尝菜”的区别～","explanation":"传统编程的核心是人类先明确制定规则，计算机仅需按照规则处理输入数据，最终输出答案，规则是提前固定的，计算机不具备“学习”能力。而机器学习的核心是人类不制定明确规则，而是给计算机提供大量数据和对应的答案，让计算机自主学习总结出规则，规则是动态生成的，计算机能通过经验积累优化规则。做菜的比喻直观体现了这种差异：传统编程是“按规则做事”，机器学习是“从结果反推规则”。"},
	  {"id":"ml-qa-02","type":"qa","question":"请分别解释监督学习、无监督学习、强化学习的核心定义，并说明三者最关键的区别。","answer":"核心定义：1. 监督学习：用标记数据（带标准答案）训练，学习输入到输出的映射；2. 无监督学习：用未标记数据训练，自主发现数据隐藏结构；3. 强化学习：智能体通过与环境互动，依据奖励/惩罚信号学习最佳策略。最关键区别：数据类型/学习方式不同——监督学习依赖标记数据（有“老师”指导），无监督学习依赖未标记数据（自主探索），强化学习依赖环境反馈（交互学习）。","hint":"用“学习场景”区分：监督=有老师改作业，无监督=自学找规律，强化=做动作拿奖惩～","explanation":"三者是机器学习的三大核心类型，核心差异源于“学习的依据和方式”：监督学习的核心是“标记数据”，相当于有老师提供标准答案，学习目标明确；无监督学习的核心是“未标记数据”，无标准答案，学习目标是发现数据内在规律；强化学习的核心是“环境反馈”，无固定数据，通过与环境的持续交互和奖惩机制优化策略。这种差异导致三者的应用场景不同：监督学习适用于预测任务（分类、回归），无监督学习适用于探索任务（聚类），强化学习适用于决策任务（机器人控制、游戏博弈）。"},
	  {"id":"ml-qa-03","type":"qa","question":"请简述深度学习的关键特征，并说明其与传统机器学习在数据依赖性、硬件需求上的差异。","answer":"深度学习关键特征：是机器学习的子集，受大脑结构启发，使用多层神经网络，能自动从原始数据中提取特征（无需人工干预）。差异：1. 数据依赖性：传统机器学习在小数据量下表现良好，深度学习需海量数据才能发挥威力；2. 硬件需求：传统机器学习可在普通CPU运行，深度学习高度依赖高端GPU（用于矩阵运算）。","hint":"深度学习=“深”（多层）+“智能”（自动提特征），数据和硬件都是“大需求”～","explanation":"深度学习的核心优势是“自动特征提取”，这解决了传统机器学习中人工特征工程耗时耗力的问题，但也带来了更高的资源需求。数据方面，自动特征提取需要大量数据来学习足够的特征模式，小数据量下深度学习无法充分训练，而传统机器学习算法（如决策树、SVM）在小数据量下就能达到较好效果。硬件方面，深度学习的多层神经网络涉及大量矩阵运算，普通CPU运算速度慢，无法满足训练需求，高端GPU的并行计算能力能大幅提升训练效率，而传统机器学习的运算量较小，普通CPU即可支撑。"},
	  {"id":"ml-qa-04","type":"qa","question":"请解释机器学习术语中“特征”和“标签”的定义，并举例说明。","answer":"定义：1. 特征：输入数据的属性，是模型学习的依据；2. 标签：我们要预测的答案，是模型学习的目标。举例：预测房子价格时，房子的面积、卧室数量、地理位置等是特征，房子的具体售价是标签。","hint":"“特征”是“已知条件”，“标签”是“待求答案”，像做数学题的已知量和未知量～","explanation":"特征和标签是机器学习中的基础术语，二者共同构成了监督学习的核心数据要素。特征是对输入数据的描述，必须是可量化、可提取的属性，比如判断是否为猫时，图片的像素值、物体的轮廓、颜色等都是特征；标签是模型最终要预测的结果，对于分类任务是离散类别（如“是猫”“不是猫”），对于回归任务是连续数值（如房子价格、气温）。在无监督学习中，数据仅有特征，没有标签，模型需仅通过特征发现数据规律。"},
	  
	
	// 第七章
	
	  {
	    "id": "NN-001-choice",
	    "type": "choice",
	    "question": "人工神经网络（ANN）的核心学习方式是什么？",
	    "options": [
	      "通过预设的固定规则执行任务",
	      "通过分析例子自主拟合数据规律",
	      "直接存储输入数据以便快速查询",
	      "依赖手工提取的特征进行计算"
	    ],
	    "answer": 1,
	    "hint": "想想神经网络像不像“刷题学霸”，不是死记硬背而是找规律～",
	    "explanation": "解析：ANN的核心特点是通过“例子”学习，而非传统编程的固定规则（排除A）；它不存储原始数据，而是通过权重矩阵拟合数据规律（排除C）；手工提取特征是传统机器学习的方式，神经网络可自动提取特征（排除D）。正确答案为B，体现了ANN的学习本质——自主从数据中发现规律。"
	  },
	  {
	    "id": "NN-002-choice",
	    "type": "choice",
	    "question": "生物神经元的突触在人工神经网络中对应的组件是？",
	    "options": [
	      "输入层神经元",
	      "权重（Weights）",
	      "激活函数",
	      "偏置（Bias）"
	    ],
	    "answer": 1,
	    "hint": "突触决定信号传递强度，就像“交接棒的默契度”～",
	    "explanation": "解析：生物神经元的突触是连接接点，决定信号传递强度；人工神经网络中，权重用于衡量每个输入的重要性，与突触的功能一致（对应B）。输入层神经元对应树突的信号接收功能（排除A）；激活函数是神经元的“开关”（排除C）；偏置是移动激活阈值的基础分（排除D）。"
	  },
	  {
	    "id": "NN-003-choice",
	    "type": "choice",
	    "question": "人工神经元数学模型y=f(∑(w_i*x_i)+b)中，偏置（b）的作用是？",
	    "options": [
	      "衡量输入数据的重要性",
	      "计算加权输入的总和",
	      "移动激活函数的阈值",
	      "直接决定神经元的输出值"
	    ],
	    "answer": 2,
	    "hint": "偏置=“同情分”，就算交白卷也可能给几分哦～",
	    "explanation": "解析：偏置的核心作用是允许移动激活函数的阈值，即使输入为0（交白卷），也能通过偏置让神经元更容易或更难被激活（对应C）。衡量输入重要性的是权重（w）（排除A）；计算加权总和的是求和函数（∑）（排除B）；输出值由激活函数（f）决定，而非偏置直接决定（排除D）。"
	  },
	  {
	    "id": "NN-004-choice",
	    "type": "choice",
	    "question": "深度学习被称为“深”的关键原因是？",
	    "options": [
	      "输入层数据维度极高",
	      "隐藏层数量特别多",
	      "输出层可处理多种任务",
	      "权重矩阵规模庞大"
	    ],
	    "answer": 1,
	    "hint": "隐藏层=“大脑皮层”，层数越多“思考”越深入～",
	    "explanation": "解析：深度学习的“深”特指网络架构中隐藏层的数量多（对应B）。输入层维度高是数据特点，与“深”无关（排除A）；输出层功能是任务相关，不影响“深”的定义（排除C）；权重矩阵规模由神经元数量决定，而非层数（排除D）。"
	  },
	  {
	    "id": "NN-005-choice",
	    "type": "choice",
	    "question": "神经网络学习过程中，“反向传播”的核心作用是？",
	    "options": [
	      "将输入数据传递到输出层得到预测值",
	      "计算预测值与真实值的误差",
	      "根据误差调整权重和偏置",
	      "重复迭代直到误差最小"
	    ],
	    "answer": 2,
	    "hint": "反向传播=“错题订正”，告诉神经元哪里错了该怎么改～",
	    "explanation": "解析：反向传播的核心是将误差反向传回网络，指导各神经元调整权重和偏置（对应C）。选项A是前向传播的作用（排除A）；选项B是计算误差的步骤（排除B）；选项D是迭代的定义（排除D）。"
	  },
	  {
	    "id": "NN-006-choice",
	    "type": "choice",
	    "question": "以下哪项不属于神经网络的核心应用场景？",
	    "options": [
	      "人脸识别（模式识别）",
	      "股票预测（预测任务）",
	      "文本编辑（语法纠错）",
	      "疾病诊断（分类任务）"
	    ],
	    "answer": 2,
	    "hint": "神经网络擅长“找规律”，不是“改错别字”哦～",
	    "explanation": "解析：神经网络的核心应用包括模式识别（A）、预测（B）、分类（D），均需从复杂数据中找规律。文本编辑的语法纠错主要依赖自然语言处理中的规则引擎或序列模型的特定优化，不属于神经网络的核心应用场景（对应C）。"
	  },
	  {
	    "id": "NN-007-choice",
	    "type": "choice",
	    "question": "神经网络中“全连接”的定义是？",
	    "options": [
	      "输入层与输出层直接相连，无隐藏层",
	      "上一层每个神经元与下一层每个神经元相连",
	      "所有神经元共享相同的权重和偏置",
	      "网络可处理任意类型的输入数据"
	    ],
	    "answer": 1,
	    "hint": "全连接=“手拉手”，上一层每个都和下一层每个交朋友～",
	    "explanation": "解析：全连接是网络的连接方式，指上一层的每个神经元都与下一层的每个神经元相连（对应B）。选项A是单层感知机的结构（排除A）；所有神经元共享权重偏置是共享参数机制（排除C）；处理任意输入是数据预处理的作用（排除D）。"
	  },
	  {
	    "id": "NN-008-fill",
	    "type": "fill",
	    "question": "人工神经网络由大量高度互连的处理元件____组成，协同工作解决特定问题。",
	    "answer": "神经元",
	    "hint": "神经网络的基本组成单元，和生物神经系统的核心元件同名～",
	    "explanation": "解析：人工神经网络（ANN）的核心组成单元是神经元（处理元件），模仿生物神经系统的神经元结构，通过互连实现信息处理。这是ANN定义的核心关键词，体现了其结构基础。"
	  },
	  {
	    "id": "NN-009-fill",
	    "type": "fill",
	    "question": "人工神经元数学模型中，____函数的作用是决定神经元是否“被激活”，使网络具备处理非线性问题的能力。",
	    "answer": "激活",
	    "hint": "就像“及格线”，总分超过就激活，没到就不激活～",
	    "explanation": "解析：激活函数（f）是人工神经元的核心组件，通过设置阈值决定神经元是否输出信号（被激活）。非线性激活函数（如ReLU、Sigmoid）让网络能够处理复杂的非线性问题，这是神经网络解决实际任务的关键能力。"
	  },
	  {
	    "id": "NN-010-fill",
	    "type": "fill",
	    "question": "神经网络学习过程的第一步是____，即数据从输入层流向输出层得到预测值。",
	    "answer": "前向传播",
	    "hint": "相当于“做题”的过程，从读题到算出答案～",
	    "explanation": "解析：前向传播是神经网络学习流程的首个步骤，数据按输入层→隐藏层→输出层的顺序传递，通过加权求和、激活函数计算得到预测值。这是后续计算误差、反向传播的基础。"
	  },
	  {
	    "id": "NN-011-fill",
	    "type": "fill",
	    "question": "神经网络的____层负责特征提取和模式识别，因其不可直接观测而得名。",
	    "answer": "隐藏",
	    "hint": "相当于“大脑皮层”，思考过程别人看不见～",
	    "explanation": "解析：隐藏层位于输入层和输出层之间，其核心功能是自动提取数据中的特征并进行模式识别，由于其计算过程不可直接观测（相对于输入输出层的明确数据），故称为“隐藏”层。深度学习的“深”即体现在隐藏层的数量上。"
	  },
	  {
	    "id": "NN-012-qa",
	    "type": "qa",
	    "question": "简述人工神经网络（ANN）的核心定义和两个核心特点。",
	    "answer": "核心定义：受生物神经系统结构和功能启发的信息处理范式，由大量高度互连的神经元组成，协同解决特定问题。核心特点：1. 通过“例子”学习，而非传统编程规则；2. 具有概括能力，能处理未见过的数据。",
	    "hint": "定义抓“生物启发+神经元+协同工作”，特点抓“例子学习+概括能力”～",
	    "explanation": "解析：定义需涵盖ANN的灵感来源（生物神经系统）、结构基础（互连神经元）、核心目的（解决特定问题）；核心特点是其与传统编程的关键区别——无需预设规则，通过数据自主学习，且能泛化到未见过的数据（概括能力），这也是其在复杂任务中表现出色的原因。"
	  },
	  {
	    "id": "NN-013-qa",
	    "type": "qa",
	    "question": "说明生物神经元与人工神经元的结构映射关系（至少列出3组对应关系）。",
	    "answer": "1. 树突 ↔ 输入（Inputs）：均负责接收来自其他神经元的信号；2. 胞体 ↔ 节点/求和计算（Node/Summation）：均负责处理和整合接收的信号；3. 轴突 ↔ 输出（Output）：均负责传输处理后的信号；4. 突触 ↔ 权重（Weights）：均决定信号传递的强度。",
	    "hint": "记住“树突接、胞体算、轴突传、突触调强度”的对应口诀～",
	    "explanation": "解析：生物神经元与人工神经元的结构映射是ANN设计的核心灵感来源，需明确各生物结构的功能与人工组件的功能匹配：树突（接收）→输入、胞体（整合）→求和计算、轴突（传输）→输出、突触（传递强度）→权重。这种映射确保了ANN能模拟生物神经系统的信息处理逻辑。"
	  },
	  {
	    "id": "NN-014-qa",
	    "type": "qa",
	    "question": "简述神经网络学习过程的四个核心步骤，并解释每个步骤的作用。",
	    "answer": "1. 前向传播：数据从输入层流向输出层，通过加权求和和激活函数计算得到预测值，作用是完成“预测”过程；2. 计算误差：对比预测值与真实值的差距，作用是明确模型的“错误程度”；3. 反向传播：将误差反向传回网络，指导各神经元调整权重和偏置，作用是“定位错误并给出修正方向”；4. 迭代：重复上述三步，直到误差最小，作用是不断优化模型，提升预测准确性。",
	    "hint": "类比“做题→对答案→订正→刷题”的学霸成长路径～",
	    "explanation": "解析：神经网络的学习本质是调整权重和偏置，四个步骤形成闭环：前向传播是模型的“预测执行”，计算误差是“错误评估”，反向传播是“修正指导”，迭代是“持续优化”。通过这一闭环，模型能逐步拟合数据规律，降低预测误差，最终实现准确的分类、预测等任务。"
	  },
	  
	  // 第八章
	    
	      {
	        "id": "DL-GAI-001-choice",
	        "type": "choice",
	        "question": "深度学习中“深度”的核心含义是指？",
	        "options": [
	          "输入数据的维度极高",
	          "神经网络包含多个隐藏层",
	          "输出层可处理多种任务",
	          "训练数据的规模庞大"
	        ],
	        "answer": 1,
	        "hint": "想想“层层剥洋葱”，层数越多越“深”哦～",
	        "explanation": "解析：深度学习的“深度”特指神经网络中拥有多个（通常很多个）隐藏层，能够学习数据中复杂的层级特征（对应B）。输入数据维度高是数据特点（排除A）；输出层功能与“深度”无关（排除C）；训练数据规模大是深度学习的训练条件，而非“深度”的定义（排除D）。"
	      },
	      {
	        "id": "DL-GAI-002-choice",
	        "type": "choice",
	        "question": "下列关于AI、ML、DL三者关系的描述，正确的是？",
	        "options": [
	          "DL包含ML，ML包含AI",
	          "AI包含ML，ML包含DL",
	          "ML包含AI，AI包含DL",
	          "三者是相互独立的技术领域"
	        ],
	        "answer": 1,
	        "hint": "大雨伞套小雨伞，DL是最小的那个～",
	        "explanation": "解析：AI（人工智能）是最广泛的概念，包含所有智能技术；ML（机器学习）是AI的子集，专注于让机器从数据中学习；DL（深度学习）是ML的子集，特指多层神经网络学习（对应B）。其他选项的包含关系均颠倒或错误（排除A、C、D）。"
	      },
	      {
	        "id": "DL-GAI-003-choice",
	        "type": "choice",
	        "question": "反向传播（Backpropagation）的核心作用是？",
	        "options": [
	          "将输入数据传递到输出层得到预测值",
	          "计算预测值与真实值的误差",
	          "根据误差计算梯度，指导权重调整",
	          "直接最小化损失函数"
	        ],
	        "answer": 2,
	        "hint": "反向传播=“找背锅侠”，算出谁该为误差负责～",
	        "explanation": "解析：反向传播的核心是从输出层反向传递误差，计算每个神经元对误差的“贡献”（梯度），为权重调整提供依据（对应C）。选项A是前向传播的作用（排除A）；选项B是损失函数的作用（排除B）；直接最小化损失函数的是优化器（排除D）。"
	      },
	      {
	        "id": "DL-GAI-004-choice",
	        "type": "choice",
	        "question": "ReLU激活函数的特点是？",
	        "options": [
	          "将输出压缩到0-1之间，类似概率",
	          "负数归零，正数保持不变，高效简洁",
	          "输出值在-1到1之间，对称分布",
	          "能解决所有梯度消失问题"
	        ],
	        "answer": 1,
	        "hint": "简单粗暴！没信号（负数）就关，有信号（正数）就过～",
	        "explanation": "解析：ReLU的定义是“负数归零，正数不变”，这种特性使其计算高效，避免了部分梯度消失问题（对应B）。选项A是Sigmoid函数的特点（排除A）；选项C是Tanh函数的特点（排除C）；ReLU不能解决所有梯度消失问题（如深层网络仍可能出现）（排除D）。"
	      },
	      {
	        "id": "DL-GAI-005-choice",
	        "type": "choice",
	        "question": "卷积神经网络（CNN）最适合处理的任务是？",
	        "options": [
	          "自然语言翻译",
	          "图像识别与计算机视觉",
	          "时间序列预测",
	          "语音转文字"
	        ],
	        "answer": 1,
	        "hint": "CNN擅长找图像的“花纹”和“轮廓”，像个视觉侦探～",
	        "explanation": "解析：CNN的核心优势是提取空间局部特征，适用于图像识别、计算机视觉等任务（对应B）。自然语言翻译和语音转文字属于序列数据处理，更适合RNN或Transformer（排除A、D）；时间序列预测主要用RNN（排除C）。易错点：CNN不擅长处理序列数据，关注空间结构。"
	      },
	      {
	        "id": "DL-GAI-006-choice",
	        "type": "choice",
	        "question": "循环神经网络（RNN）的核心机制是？",
	        "options": [
	          "自注意力机制，并行处理序列",
	          "局部特征提取与维度降低",
	          "记忆功能，前一步输出作为下一步输入",
	          "生成器与判别器的对抗训练"
	        ],
	        "answer": 2,
	        "hint": "像读书一样，带着上文的记忆读下文～",
	        "explanation": "解析：RNN的核心是“记忆”功能，前一时刻的输出会作为当前时刻的输入，使其能处理序列数据（对应C）。选项A是Transformer的机制（排除A）；选项B是CNN的机制（排除B）；选项D是GAN的机制（排除D）。易错点：传统RNN存在梯度消失问题，记不住长序列。"
	      },
	      {
	        "id": "DL-GAI-007-choice",
	        "type": "choice",
	        "question": "生成对抗网络（GANs）中，生成器和判别器的关系是？",
	        "options": [
	          "生成器辅助判别器优化，共同提升分类准确率",
	          "两者互搏进化，生成器造假，判别器抓假",
	          "生成器负责特征提取，判别器负责生成新样本",
	          "两者串行工作，生成器先处理数据，判别器再评估"
	        ],
	        "answer": 1,
	        "hint": "假钞团伙（生成器）vs 警察（判别器），互相卷起来～",
	        "explanation": "解析：GAN的核心是“对抗训练”，生成器负责生成假样本，判别器负责区分真假样本，两者在对抗中不断优化，直到生成器的假样本能以假乱真（对应B）。选项A、C、D均颠倒了两者的功能或关系（排除）。"
	      },
	      {
	        "id": "DL-GAI-008-choice",
	        "type": "choice",
	        "question": "下列哪种现象属于“过拟合”？",
	        "options": [
	          "模型在训练集和测试集上表现都很差",
	          "模型在训练集表现极好，测试集表现大幅下降",
	          "模型无法学习到训练数据的基本规律",
	          "模型训练时损失函数一直上升"
	        ],
	        "answer": 1,
	        "hint": "像死记硬背练习册答案，换题就不会～",
	        "explanation": "解析：过拟合是指模型过度学习训练数据的细节（包括噪声），导致在未见过的测试集上表现不佳（对应B）。选项A和C是欠拟合的表现（排除）；选项D是训练过程异常（如学习率过高）（排除）。"
	      },
	      {
	        "id": "DL-GAI-009-fill",
	        "type": "fill",
	        "question": "深度学习是机器学习的子集，其核心在于“深度”，即神经网络中拥有多个____，能够学习数据中复杂的特征表示。",
	        "answer": "隐藏层",
	        "hint": "“层层剥洋葱”的每一层，看不见的思考过程～",
	        "explanation": "解析：深度学习的“深度”定义为多个隐藏层的存在。隐藏层负责特征的层级提取（从低级到高级），这是其区别于传统浅层神经网络的关键，也是其能处理复杂任务的核心原因。"
	      },
	      {
	        "id": "DL-GAI-010-fill",
	        "type": "fill",
	        "question": "____是衡量模型预测值与真实值之间差异的数学函数，常见的有均方误差（MSE）和交叉熵。",
	        "answer": "损失函数（Loss Function）",
	        "hint": "像老师改卷子的“打分板”，扣分越少表现越好～",
	        "explanation": "解析：损失函数是深度学习训练的核心指标，其值反映了模型预测的准确程度。训练的目标就是通过优化器调整权重，最小化损失函数的值，使模型预测更接近真实值。"
	      },
	      {
	        "id": "DL-GAI-011-fill",
	        "type": "fill",
	        "question": "CNN的关键组件包括____（提取局部特征）和____（降低数据维度，保留核心特征）。",
	        "answer": "卷积层（Convolution Layer），池化层（Pooling Layer）",
	        "hint": "卷积层=放大镜找花纹，池化层=缩小图片省眼力～",
	        "explanation": "解析：卷积层通过滤波器扫描图像，提取边缘、纹理等局部特征；池化层通过下采样降低数据维度，减少计算量，同时保留关键特征，两者共同构成CNN处理图像的核心流程。"
	      },
	      {
	        "id": "DL-GAI-012-fill",
	        "type": "fill",
	        "question": "生成式AI的核心目标是学习训练数据的____，然后生成符合该规律的新样本。",
	        "answer": "分布规律",
	        "hint": "像画家学习梵高的风格（分布），画出新的向日葵～",
	        "explanation": "解析：生成式AI与判别式AI的本质区别在于，前者不局限于分类或预测，而是通过学习训练数据的分布规律（如图像风格、文本语法），创造出从未见过但符合该规律的新数据。"
	      },
	      {
	        "id": "DL-GAI-013-fill",
	        "type": "fill",
	        "question": "传统RNN容易出现____问题，导致无法记住过长的序列数据。",
	        "answer": "梯度消失",
	        "hint": "记性不好，记不住长句子～",
	        "explanation": "解析：传统RNN在处理长序列时，反向传播过程中的梯度会逐渐衰减至接近零，导致早期神经元的权重无法有效更新，即“梯度消失”问题，这也是LSTM、GRU等改进模型出现的原因。"
	      },
	      {
	        "id": "DL-GAI-014-qa",
	        "type": "qa",
	        "question": "简述生成式AI与判别式AI的核心区别，并分别用直观理解说明。",
	        "answer": "核心区别：判别式AI专注于分类或预测（判断数据属于哪一类），生成式AI专注于创造新的、符合训练数据规律的样本。直观理解：判别式AI像鉴赏家，能判断一幅画是梵高还是莫奈的；生成式AI像画家，学习梵高的风格后，能画出新的向日葵画作。",
	        "hint": "一个“判断”一个“创造”，鉴赏家vs画家的区别～",
	        "explanation": "解析：判别式AI的目标是学习输入数据到标签的映射关系（如“图片→猫/狗”），核心是“判别”类别；生成式AI的目标是学习数据本身的分布规律（如“猫的图像分布”），核心是“生成”新数据。两者的应用场景互补，判别式AI适合分类、预测任务，生成式AI适合内容创作、数据补全等任务。"
	      },
	      {
	        "id": "DL-GAI-015-qa",
	        "type": "qa",
	        "question": "对比CNN、RNN、Transformer三种架构的核心用途和关键机制，并说明各自的优势场景。",
	        "answer": "1. CNN：核心用途是图像识别、计算机视觉；关键机制是卷积层提取局部特征、池化层降维；优势场景：处理具有空间结构的数据（图像）。2. RNN：核心用途是处理序列数据（时间序列、自然语言）；关键机制是记忆功能，前一步输出作为下一步输入；优势场景：短序列数据的时序依赖建模（如语音识别）。3. Transformer：核心用途是NLP（如BERT、GPT）、计算机视觉；关键机制是自注意力机制，并行处理序列；优势场景：长序列数据的全局依赖建模（如文本翻译、大语言模型）。",
	        "hint": "CNN看空间，RNN记时序，Transformer抓全局～",
	        "explanation": "解析：三种架构的设计初衷基于不同的数据特点：CNN针对图像的空间局部相关性，RNN针对序列的时序依赖性，Transformer针对序列的全局相关性且支持并行计算。CNN不擅长序列数据，RNN受梯度消失限制，Transformer在长序列和并行处理上有明显优势，是当前NLP领域的主流架构。"
	      },
	      {
	        "id": "DL-GAI-016-qa",
	        "type": "qa",
	        "question": "什么是过拟合和欠拟合？请分别描述其现象、直观理解及核心原因。",
	        "answer": "1. 过拟合：现象：模型在训练集表现极好，测试集表现大幅下降；直观理解：学生死记硬背练习册答案，换题就不会；核心原因：模型复杂度过高，过度学习训练数据中的噪声和细节，泛化能力差。2. 欠拟合：现象：模型在训练集和测试集上表现都很差；直观理解：小学生考微积分，完全无法理解；核心原因：模型复杂度过低，无法学习到训练数据的基本规律。",
	        "hint": "过拟合=学太死，欠拟合=学不会～",
	        "explanation": "解析：过拟合和欠拟合是深度学习训练中的两大核心问题。过拟合的解决方法包括正则化、 dropout、增加训练数据等；欠拟合的解决方法包括增加模型复杂度（如增加隐藏层数量）、延长训练时间、优化特征工程等。两者的本质都是模型复杂度与数据规律的不匹配。"
	      },
	    
  // 第九章
    
      {
        "id": "cs-ai-001",
        "type": "choice",
        "question": "认知系统的核心定位是什么？",
        "options": [
          "完全替代人类进行决策，实现自动化任务",
          "增强人类决策能力，提供AI驱动的洞察辅助",
          "仅处理结构化数据，完成单一预设任务",
          "通过实体交互从环境中涌现智能"
        ],
        "answer": 1,
        "hint": "认知系统是“决策参谋”不是“独裁者”，记住“辅助”这个关键词～",
        "explanation": "认知系统的官方定义明确其核心是“以AI驱动的洞察辅助人类决策而非仅自动化任务”，核心是增强人类决策能力，而非替代人类决策（选项A错误）；仅处理结构化数据、完成单一任务是窄AI的特征（选项C错误）；通过实体交互涌现智能是具身AI的核心（选项D错误）。"
      },
      {
        "id": "cs-ai-002",
        "type": "choice",
        "question": "具身AI的智能来源不包括以下哪项？",
        "options": [
          "主体与环境的实时感知-行动交互",
          "预设的抽象符号操纵程序",
          "通过感觉运动学习建立的感知-行动映射",
          "物理实体的传感器与执行器互动"
        ],
        "answer": 1,
        "hint": "具身AI是“在做事中变聪明”，不是“靠预设程序变聪明”～",
        "explanation": "具身AI的核心观点是智能源于主体、身体与环境的交互，而非抽象符号操纵（选项B是传统AI的认知方式，不属于具身AI智能来源）；选项A（感知-行动交互）、C（感觉运动学习）、D（传感器与执行器互动）均是具身AI智能涌现的关键途径。"
      },
      {
        "id": "cs-ai-003",
        "type": "choice",
        "question": "SOAR认知架构的核心循环是以下哪一组？",
        "options": [
          "感知-行动-反馈-迭代",
          "状态-操作符-结果（State-Operator-Result）",
          "规划-执行-反思-更新",
          "陈述性记忆-程序性记忆-中央匹配"
        ],
        "answer": 1,
        "hint": "SOAR是“超级问题解决者”，记住“状态-操作-结果”的解题流程～",
        "explanation": "SOAR架构的官方定义明确核心循环为State（状态）、Operator（操作符）、Result（结果），通过产生式规则系统处理问题（选项B正确）；选项A是具身AI的感知-行动回路逻辑；选项C是LLM-based自主代理的认知循环；选项D是ACT-R架构的核心机制（记忆模块与中央协调）。"
      },
      {
        "id": "cs-ai-004",
        "type": "choice",
        "question": "现代认知架构的核心特征是什么？",
        "options": [
          "纯符号推理，依赖预设规则系统",
          "纯神经网络学习，仅从数据中自适应",
          "融合符号推理与神经网络学习，互补优势",
          "仅聚焦单一任务，提升专项技能效率"
        ],
        "answer": 2,
        "hint": "现代架构是“理性法官+灵活学徒”的组合，既懂规矩又会变通～",
        "explanation": "现代认知架构的核心是克服纯符号（脆弱）和纯神经网络（难解释）的局限，实现“数据学习”与“高层知识操纵”的结合（选项C正确）；选项A是传统符号主义架构的特征；选项B是纯连接主义的特征；选项D是窄AI的特征，与现代认知架构追求的通用智能相悖。"
      },
      {
        "id": "cs-ai-005",
        "type": "choice",
        "question": "以下哪项不属于具身AI模拟环境的核心优势？",
        "options": [
          "高速训练（比现实快数千倍）",
          "安全探索（无硬件损坏/人员伤亡风险）",
          "需依赖真实物理硬件才能训练",
          "大规模并行（数百个模拟主体同时学习）"
        ],
        "answer": 2,
        "hint": "模拟环境是“虚拟训练场”，不用真家伙也能练～",
        "explanation": "具身AI模拟环境的核心优势包括高速训练、安全探索、大规模并行，其核心价值是脱离真实硬件的限制（选项C描述的是真实环境训练的要求，不属于模拟环境优势），因此选项C错误，其余选项均为模拟环境的官方定义优势。"
      },
      {
        "id": "cs-ai-006",
        "type": "choice",
        "question": "LLM与认知系统结合的核心循环不包括以下哪个环节？",
        "options": [
          "规划任务集",
          "执行（LLM生成行动+工具落地）",
          "直接输出最终结果，无需反思",
          "反思结果并更新计划"
        ],
        "answer": 2,
        "hint": "LLM+认知系统是“会反思的工作者”，不是“一次性输出机器”～",
        "explanation": "LLM与认知系统结合的核心循环是“规划-执行-反思-更新”，需通过迭代优化提升结果质量（选项C描述的“直接输出无需反思”不符合该循环逻辑）；其余选项均为官方定义的核心环节，缺一不可。"
      },
      {
        "id": "cs-ai-007",
        "type": "choice",
        "question": "认知系统与具身AI的伦理设计核心不包括以下哪项？",
        "options": [
          "事后补救偏见与隐私问题",
          "多样化训练数据缓解偏见",
          "从设计阶段植入隐私保护机制",
          "保留人类对AI决策的干预权"
        ],
        "answer": 0,
        "hint": "伦理设计是“事前预防”不是“事后救火”～",
        "explanation": "认知系统与具身AI的伦理核心原则是“安全、偏见、自主权、隐私是设计核心，而非事后补充”（选项A描述的事后补救不符合该原则）；选项B（缓解偏见的措施）、C（隐私设计）、D（人类干预权）均是伦理设计的官方要求。"
      },
      {
        "id": "cs-ai-008",
        "type": "choice",
        "question": "ACT-R认知架构区分的两种记忆类型是？",
        "options": [
          "短期记忆与长期记忆",
          "陈述性记忆（事实）与程序性记忆（技能）",
          "视觉记忆与语言记忆",
          "显性记忆与隐性记忆"
        ],
        "answer": 1,
        "hint": "ACT-R是“复刻人类大脑模块”，记住“事实”和“技能”分开存～",
        "explanation": "ACT-R的官方定义明确区分陈述性记忆（事实知识，如“地球是圆的”，以“块”存储）和程序性记忆（技能，如“骑自行车”，以产生式规则存储）（选项B正确）；选项A是心理学中通用的记忆分类，并非ACT-R的核心区分；选项C、D均不符合ACT-R的模块设计逻辑。"
      },
      {
        "id": "cs-ai-009",
        "type": "fill",
        "question": "传统AI被比喻为“坐在办公室里处理文件的职员”，而认知系统与具身AI被比喻为“________”，前者只碰数据，后者要动手动脑融入真实环境。",
        "answer": "亲自到现场解决问题的工程师",
        "hint": "关键词是“到现场”“解决问题”，和“办公室职员”形成对比～",
        "explanation": "学习资料中明确给出直观理解：传统AI是“坐在办公室里处理文件的职员”，认知系统与具身AI是“亲自到现场解决问题的工程师”，核心是突出后者“融入真实环境、动手行动”的特征，与传统AI的“无实体数据处理”形成差异。"
      },
      {
        "id": "cs-ai-010",
        "type": "fill",
        "question": "具身AI的核心机制是________，即主体通过传感器感知环境、执行器采取行动，行动引发新感知的实时闭合循环。",
        "answer": "感知-行动回路",
        "hint": "记住“感知→思考→行动→新感知”的闭环，关键词是“感知”和“行动”～",
        "explanation": "具身AI的关键机制是感知-行动回路，官方定义为“主体通过传感器持续感知世界，将感知输入认知系统决策，再通过执行器执行行动，行动引发新感知，形成实时循环”，这是具身AI智能涌现的核心路径，区别于抽象数据处理。"
      },
      {
        "id": "cs-ai-011",
        "type": "fill",
        "question": "SOAR认知架构通过________机制将子目标解决方案编译为新规则，提升后续问题解决效率，类似人类积累经验的过程。",
        "answer": "分块（chunking）",
        "hint": "SOAR“分块”学习，就像把小知识点整合为大模块，记得更牢～",
        "explanation": "SOAR架构的核心学习机制是“分块（chunking）”，官方定义为“通过‘分块’将子目标解决方案编译为新规则，提升效率”，本质是将复杂问题的解决经验转化为可复用的规则，模拟人类“举一反三”的学习能力。"
      },
      {
        "id": "cs-ai-012",
        "type": "fill",
        "question": "感觉运动学习的两种主要方式是________和模仿学习，前者通过试错和奖励信号调整行为，后者通过观察示范行为学习。",
        "answer": "强化学习",
        "hint": "“有奖有罚”的学习是强化学习，“跟着老师学”是模仿学习～",
        "explanation": "具身AI的感觉运动学习包括强化学习和模仿学习：强化学习是“通过试错学习，主体尝试不同行为，根据奖励信号调整”；模仿学习是“通过观察示范行为学习所需技能”，二者共同支撑具身主体从经验中获取技能，适应复杂环境。"
      },
      {
        "id": "cs-ai-013",
        "type": "fill",
        "question": "AI系统的偏见主要来源于________和设计者的主观倾向，缓解措施包括多样化训练数据、公平性约束等。",
        "answer": "训练数据",
        "hint": "AI像“镜子”，数据里的偏见会被照出来，所以源头之一是“数据”～",
        "explanation": "伦理与安全考量中明确，AI系统的偏见来源包括“数据或设计者处继承”，训练数据若存在不平衡（如性别、种族偏向），会导致AI学习到偏见并体现在决策中（如GPT-2的案例），因此多样化训练数据是关键缓解措施之一。"
      },
      {
        "id": "cs-ai-014",
        "type": "qa",
        "question": "简述认知系统与传统AI的核心区别。",
        "answer": "传统AI侧重“无实体”的单一任务数据处理，仅实现自动化任务；认知系统模拟人类认知（学习、推理、记忆等），核心是整合记忆、知识表征、推理等能力，提供AI驱动的洞察辅助人类决策，而非替代人类，追求更接近人类的灵活智能和多任务处理能力，是迈向通用智能的关键。",
        "hint": "核心区别在“是否模拟人类认知”“是否辅助决策”“是否局限单一任务”～",
        "explanation": "传统AI的本质是“窄AI”，擅长单一预设任务（如下棋、人脸识别），仅关注数据处理和自动化；认知系统的核心是“类人认知模拟”，通过整合记忆、注意力、推理等模块，实现“理解-决策-辅助”的闭环，核心价值是增强人类决策能力（而非替代），突破窄AI的技能局限，追求通用智能，这是二者最根本的差异。"
      },
      {
        "id": "cs-ai-015",
        "type": "qa",
        "question": "简述具身AI中“智能源于交互”的核心含义，并举例说明。",
        "answer": "核心含义：具身AI的智能并非预设在程序中，而是源于主体（物理实体）、身体（传感器、执行器）与环境的实时交互，智能在感知-行动的持续循环中涌现，挑战“认知是抽象符号操纵”的传统观点。举例：扫地机器人通过传感器检测垃圾（感知）→控制器规划路径（思考）→电机移动清理（行动），遇障碍物（新感知）→重新规划路径（新思考），其清理垃圾的智能的是在与环境的动态交互中逐步实现的，而非初始程序完全预设。",
        "hint": "记住“智能是做出来的不是想出来的”，结合扫地机器人、自动驾驶等例子～",
        "explanation": "“智能源于交互”是具身AI的核心观点，强调智能的涌现性和情境性：主体必须“嵌入”环境，通过传感器获取实时反馈，执行器调整行为，形成感知-行动闭环，智能在这个过程中逐步优化（如机械臂学杂耍、无人机稳定飞行）。与传统AI“抽象数据处理”不同，具身AI的智能依赖物理接地（与现实世界的直接互动），无法通过纯符号计算实现，这也是其区别于认知系统（侧重“大脑”）的核心特征——具身AI强调“身体+交互”。"
      },
      {
        "id": "cs-ai-016",
        "type": "qa",
        "question": "现代认知架构融合符号推理与神经网络学习的原因是什么？请说明两种方法的互补优势。",
        "answer": "原因：纯符号推理的优势是结构化、可解释性强，但脆弱（难以适应新数据）；纯神经网络学习的优势是自适应能力强、能从数据中学习，但可解释性差、难以处理高层知识操纵，现代认知架构融合二者是为了克服单一架构的局限，实现“数据学习”与“高层知识操纵”的统一。互补优势：1. 符号推理提供结构化知识表征和逻辑推理能力，保证决策的可解释性和规则性；2. 神经网络学习提供灵活的自适应能力，能从海量数据中学习新模式，适应复杂多变的环境，二者结合使认知系统兼具可解释性和适应性。",
        "hint": "符号是“法官”（讲规则），神经是“学徒”（会学习），结合起来才完美～",
        "explanation": "现代认知架构的设计目标是打造“兼具可解释性和适应性”的认知系统：纯符号架构（如早期SOAR）能清晰表征知识和规则，但无法应对未预设的新场景；纯神经网络架构（如深度学习模型）能从数据中自适应学习，但决策过程“黑箱”，难以处理复杂逻辑推理。融合后，符号推理负责高层知识操纵（如规划、决策），保证可解释性；神经网络负责数据驱动的学习（如特征提取、模式识别），保证适应性，共同支撑通用智能的实现，这是现代认知系统突破窄AI局限的关键技术路径。"
      },
    
  // 第十章
  
    {
      "id": "cv-choice-001",
      "type": "choice",
      "question": "计算机视觉的核心目标是自动化以下哪个过程？",
      "options": [
        "观察和解读视觉世界",
        "生成三维虚拟场景",
        "优化计算机图形渲染",
        "模拟人类神经信号传递"
      ],
      "answer": 0,
      "hint": "记住核心关键词：‘观察+解读’，像给电脑装‘眼睛+大脑’～",
      "explanation": "计算机视觉的官方定义明确其核心是自动化‘观察和解读视觉世界’的过程，通过从数字图像/视频中获取有意义信息并采取行动。选项B是计算机图形学的目标，选项C是图形渲染优化的任务，选项D是神经科学的研究范畴，均与计算机视觉核心目标不符。"
    },
    {
      "id": "cv-choice-002",
      "type": "choice",
      "question": "以下哪个阶段标志着计算机视觉进入‘深度学习时代’？",
      "options": [
        "1960s黎明期",
        "1990s统计学习期",
        "2010s爆发期",
        "2000s特征革命期"
      ],
      "answer": 2,
      "hint": "深度学习靠CNN和GPU，2010s才‘爆发’，记‘2010=深度’～",
      "explanation": "2010s，CNN在图像分类任务上达到人类水平，依托大数据和GPU算力，成为计算机视觉的‘爆发期’，正式进入深度学习时代。1960s是简单字符识别的黎明期，1990s转向统计学习，2000s以SIFT/SURF等局部特征为标志，均未进入深度学习阶段。"
    },
    {
      "id": "cv-choice-003",
      "type": "choice",
      "question": "下列哪项属于计算机视觉在医疗健康领域的核心应用？",
      "options": [
        "自动驾驶车道检测",
        "医学影像早期疾病检测",
        "无人超市智能库存管理",
        "AR导航路面标箭头"
      ],
      "answer": 1,
      "hint": "医疗=影像+疾病，其他选项看领域关键词：自动驾驶、超市、AR～",
      "explanation": "计算机视觉在医疗健康领域的核心应用是自动化医学影像分析，从X光、MRI中早期检测疾病，辅助医生诊断。选项A属于汽车领域，选项C属于零售电商领域，选项D属于增强现实领域，均与医疗健康无关。"
    },
    {
      "id": "cv-choice-004",
      "type": "choice",
      "question": "计算机视觉与计算机图形学的核心关系是？",
      "options": [
        "计算机视觉是图形学的上层领域",
        "两者均专注于3D模型生成",
        "反向操作（2D→3D vs 3D→2D）",
        "图形学是视觉的预处理步骤"
      ],
      "answer": 2,
      "hint": "视觉是‘看2D猜3D’，图形学是‘画3D成2D’，反向操作像‘拆积木vs搭积木’～",
      "explanation": "计算机视觉的核心是从2D图像还原3D世界（2D→3D），而计算机图形学是将3D模型转换为2D图像（3D→2D），两者是典型的‘反向问题’。选项A错误，AI是计算机视觉的上层领域；选项B错误，视觉不专注3D生成；选项D错误，图形学与视觉是平行相关领域，非预处理关系。"
    },
    {
      "id": "cv-choice-005",
      "type": "choice",
      "question": "Canny边缘检测的正确流程顺序是？",
      "options": [
        "梯度计算→噪音去除→非极大值抑制→双阈值处理→边缘跟踪",
        "噪音去除→梯度计算→非极大值抑制→双阈值处理→边缘跟踪",
        "非极大值抑制→噪音去除→梯度计算→双阈值处理→边缘跟踪",
        "噪音去除→双阈值处理→梯度计算→非极大值抑制→边缘跟踪"
      ],
      "answer": 1,
      "hint": "口诀：‘去噪→梯度→细化→阈值→连接’，先清洁再找边～",
      "explanation": "Canny边缘检测的经典流程为：1. 噪音reduction（高斯滤波）；2. 梯度计算（x/y方向强度梯度）；3. 非极大值抑制（边缘细化）；4. 双阈值处理（分类强/弱/非边缘）；5. 边缘跟踪（连接弱边缘）。选项A、C、D均打乱了核心步骤顺序，导致边缘检测效果失效。"
    },
    {
      "id": "cv-choice-006",
      "type": "choice",
      "question": "下列哪种目标检测方法属于‘单阶段方法’？",
      "options": [
        "Faster R-CNN",
        "YOLO",
        "R-CNN",
        "Fast R-CNN"
      ],
      "answer": 1,
      "hint": "单阶段=‘一眼看穿’，YOLO=You Only Look Once，名字就暴露了～",
      "explanation": "YOLO（You Only Look Once）将检测视为回归问题，从像素直接预测边界框和类别概率，属于单阶段方法，速度极快（30+ FPS）。R-CNN、Fast R-CNN、Faster R-CNN均需先生成候选区域再分类，属于两阶段方法，精准度高但速度较慢。"
    },
    {
      "id": "cv-choice-007",
      "type": "choice",
      "question": "计算机视觉与人类视觉相比，其核心优势不包括？",
      "options": [
        "精准度高、一致性强",
        "不知疲倦、可规模化",
        "上下文理解、泛化能力强",
        "24小时持续工作无疲劳"
      ],
      "answer": 2,
      "hint": "计算机‘没脑子’，不懂上下文和泛化，人类才擅长‘举一反三’～",
      "explanation": "上下文理解、抽象思维、泛化能力、创造力是人类视觉的核心优势；计算机视觉的优势包括精准度高、一致性强、不知疲倦、可规模化。选项A、B、D均为计算机视觉优势，选项C是人类视觉独有的优势，故为正确答案。"
    },
    {
      "id": "cv-choice-008",
      "type": "choice",
      "question": "卷积神经网络（CNN）中，负责‘压缩特征图、提供平移不变性’的层是？",
      "options": [
        "卷积层",
        "池化层",
        "全连接层",
        "激活层"
      ],
      "answer": 1,
      "hint": "池化=‘浓缩精华’，像把大照片缩成小照片，保留关键信息～",
      "explanation": "池化层（如下采样、最大池化）的核心作用是减少特征图尺寸（压缩数据），降低计算量，同时提供平移不变性（物体轻微移动仍能识别）。卷积层负责提取局部特征，全连接层负责组合高级特征分类，激活层引入非线性，均不具备压缩和提供平移不变性的功能。"
    },
    {
      "id": "cv-choice-009",
      "type": "choice",
      "question": "当前最先进的生成式视觉模型（如Stable Diffusion）采用的核心技术是？",
      "options": [
        "生成对抗网络（GANs）",
        "变分自编码器（VAEs）",
        "扩散模型",
        "卷积神经网络（CNNs）"
      ],
      "answer": 2,
      "hint": "扩散=‘去噪生图’，像从混沌噪音中变出清晰图像，当前最火～",
      "explanation": "扩散模型通过迭代去噪随机噪音生成数据，是当前最先进的生成式视觉模型技术，驱动了DALL-E、Stable Diffusion、Midjourney等工具。GANs通过生成器与判别器博弈生成图像，VAEs擅长样本插值，CNNs是分类/检测核心技术，均非当前生成式模型的主流。"
    },
    {
      "id": "cv-choice-010",
      "type": "choice",
      "question": "视觉SLAM（V-SLAM）的核心任务是？",
      "options": [
        "从单张图像重建3D模型",
        "机器人同时构建地图与定位自身",
        "实现图像的全景拼接",
        "检测视频中的异常行为"
      ],
      "answer": 1,
      "hint": "SLAM=Simultaneous Localization and Mapping，直译‘同时定位与建图’～",
      "explanation": "视觉SLAM以相机为主要传感器，核心任务是机器人进入未知环境时，同时构建环境地图并确定自身在地图中的位置。选项A是SfM（运动恢复结构）的任务，选项C是特征匹配的应用，选项D是安全监控领域的任务，均与SLAM核心无关。"
    },
    {
      "id": "cv-fill-001",
      "type": "fill",
      "question": "计算机视觉是人工智能的一个领域，核心是自动化‘____和____’视觉世界的过程。",
      "answer": "观察；解读",
      "hint": "记‘看+懂’，像人类先观察再解读～",
      "explanation": "根据官方定义，计算机视觉的核心是自动化‘观察和解读视觉世界’的过程，通过数字图像/视频获取有意义信息。‘观察’对应接收视觉输入，‘解读’对应分析输入内容，两者是计算机视觉的核心动作，缺一不可。"
    },
    {
      "id": "cv-fill-002",
      "type": "fill",
      "question": "2000s计算机视觉进入‘特征革命期’，标志性技术包括____和____等鲁棒局部特征。",
      "answer": "SIFT；SURF",
      "hint": "两个‘S’开头的特征，记‘特征革命双S组合’～",
      "explanation": "2000s的特征革命期以SIFT（尺度不变特征变换）和SURF（加速稳健特征）为核心，这些局部特征具备尺度不变性和旋转不变性，即使物体角度、尺寸变化也能识别，为目标识别、全景拼接等应用奠定基础。"
    },
    {
      "id": "cv-fill-003",
      "type": "fill",
      "question": "CNN的关键层包括____、____和全连接层，其中____负责提取局部特征并保留空间关系。",
      "answer": "卷积层；池化层；卷积层",
      "hint": "CNN=‘卷积提特征+池化压数据+全连接做判断’～",
      "explanation": "卷积神经网络（CNN）专为图像设计，核心层包括卷积层、池化层和全连接层。卷积层通过可学习滤波器滑动输入，检测边缘、纹理等局部特征，同时保留像素间的空间关系；池化层负责下采样压缩数据；全连接层组合高级特征实现分类/回归。"
    },
    {
      "id": "cv-fill-004",
      "type": "fill",
      "question": "目标检测的评估指标____（交并比）用于衡量预测边界框与真实边界框的重叠程度，通常____以上视为检测正确。",
      "answer": "IoU；0.5",
      "hint": "IoU=Intersection over Union，交并比越大越准，0.5是‘及格线’～",
      "explanation": "IoU（交并比）是目标检测的核心评估指标，计算预测边界框与真实边界框的交集面积与并集面积之比。行业通用标准为IoU>0.5时，视为检测正确，该阈值平衡了检测精度与灵活性，适用于大多数场景。"
    },
    {
      "id": "cv-fill-005",
      "type": "fill",
      "question": "语义分割的核心是给图像____贴类别标签，而实例分割在此基础上还能区分同一类的____。",
      "answer": "每个像素；不同个体",
      "hint": "语义=分类（同类同色），实例=区分（同类异色）～",
      "explanation": "语义分割是像素级分类，给每个像素贴类别标签（如所有车贴红色），不区分同一类的不同物体；实例分割是语义分割的进阶，不仅分类像素，还能区分同一类的不同个体（如车A贴红色，车B贴粉色），实现更细粒度的场景理解。"
    },
    {
      "id": "cv-fill-006",
      "type": "fill",
      "question": "迁移学习中，通常会____预训练模型的早期层（保留通用特征），并____针对特定任务的新分类层。",
      "answer": "冻结；添加并训练",
      "hint": "迁移=‘借通用特征+练专属分类’，冻结早期=不改变已学的基础能力～",
      "explanation": "迁移学习的核心是利用预训练模型的通用特征（如边缘、纹理），避免从零训练。具体步骤为：加载预训练模型→移除原分类层→冻结早期层（防止通用特征被破坏）→添加新分类层→训练新层适配特定任务（如猫狗分类），可大幅减少数据需求和训练时间。"
    },
    {
      "id": "cv-qa-001",
      "type": "qa",
      "question": "简述计算机视觉与人类视觉在‘学习方式’和‘优势’上的核心区别。",
      "answer": "学习方式区别：人类视觉是终身学习、少量样本即可掌握（如小孩看几次猫就认识所有猫），且具备上下文理解能力；计算机视觉需要海量数据集和特定训练方案（如看几十万张猫图才能认猫），缺乏自然的上下文迁移。优势区别：人类视觉擅长上下文理解、抽象思维、泛化能力和创造力（能举一反三）；计算机视觉的优势是精准度高、一致性强、不知疲倦、可规模化（能24小时处理海量图像，认错率低）。",
      "hint": "学习方式=‘少样本vs海量数据’，优势=‘会创造vs能扛活’～",
      "explanation": "该问题考察计算机视觉与人类视觉的核心差异，需从‘学习方式’和‘优势’两个维度分别对比。学习方式的本质是‘生物学习’与‘机器学习’的区别，人类依赖进化形成的视觉系统和少量样本归纳，计算机依赖数据驱动的算法训练；优势差异源于两者的设计目标不同，人类视觉服务于生存和认知，计算机视觉服务于自动化和增强人类能力。"
    },
    {
      "id": "cv-qa-002",
      "type": "qa",
      "question": "什么是卷积神经网络（CNN）的‘参数共享’？其核心作用是什么？",
      "answer": "参数共享是CNN的核心特点，指卷积层中使用的滤波器（核）在整个输入图像上滑动时，权重参数保持不变，而非给每个像素单独分配参数。核心作用：1. 大幅减少网络参数数量，降低计算量和过拟合风险（如1000×1000图像用3×3核，仅需9个参数而非100万个）；2. 利用图像的空间局部性，假设相邻像素的特征具有相关性，滤波器可捕捉全局一致的局部特征（如边缘、纹理），符合图像数据的本质特性。",
      "hint": "参数共享=‘一个滤镜用到底’，作用=‘省算力+抓共性’～",
      "explanation": "参数共享是CNN区别于传统神经网络的关键创新，解决了传统全连接网络处理图像时参数爆炸的问题。传统网络将图像展平为向量，每个像素对应独立权重，参数数量随图像尺寸呈平方增长；而CNN通过参数共享，使滤波器权重复用，参数数量仅与滤波器大小、数量相关，同时利用图像局部相关性，确保特征提取的有效性和高效性。"
    },
    {
      "id": "cv-qa-003",
      "type": "qa",
      "question": "简述生成式视觉模型的三大类型（GANs、VAEs、扩散模型）及其核心原理差异。",
      "answer": "生成式视觉模型的三大类型及核心原理：1. GANs（生成对抗网络）：双玩家博弈机制，生成器负责生成假图像，判别器负责区分真假图像，两者相互竞争迭代优化，最终生成器可生成高度逼真的合成图像（核心是‘对抗训练’）；2. VAEs（变分自编码器）：概率生成模型，先将图像编码为低维 latent 空间（压缩），再从 latent 空间解码生成图像（还原），擅长样本插值和生成平滑过渡的图像（核心是‘概率编码-解码’）；3. 扩散模型：通过迭代去噪过程生成图像，先向真实图像添加随机噪音，再训练模型逐步去除噪音还原真实图像，本质是‘从混沌到有序’的去噪过程，当前是最先进的生成式技术（如Stable Diffusion）。",
      "hint": "GANs=‘造假vs鉴假’，VAEs=‘压缩vs还原’，扩散=‘去噪vs生图’～",
      "explanation": "该问题考察生成式视觉模型的核心分类及原理，三者均用于生成逼真图像，但技术路径差异显著。GANs依赖对抗训练实现生成，优势是图像逼真度高；VAEs基于概率模型，优势是 latent 空间平滑可解释；扩散模型通过去噪迭代生成，兼顾逼真度和多样性，成为当前主流。理解三者差异有助于掌握生成式视觉的技术演进和应用场景选择。"
    },
    {
      "id": "cv-qa-004",
      "type": "qa",
      "question": "计算机视觉的‘边缘部署’与‘云部署’相比，核心优势和局限性分别是什么？适用场景有哪些？",
      "answer": "核心优势：1. 低延迟：模型在本地设备运行，无需网络传输，响应速度快（如自动驾驶需实时决策）；2. 离线可用：不依赖网络连接，适用于无网络或弱网络环境（如偏远地区监控）；3. 隐私保护：数据在本地处理，无需上传云端，降低数据泄露风险（如医疗影像、个人隐私图像）；4. 降低成本：减少云端服务器算力消耗和网络带宽费用。局限性：1. 设备算力有限：受手机、摄像头等边缘设备的CPU/GPU、内存、功耗限制，无法运行复杂大型模型；2. 模型优化难度高：需将模型转换为TF Lite、ONNX等轻量化格式，可能牺牲部分性能；3. 更新维护复杂：需逐个设备更新模型，而非云端统一更新。适用场景：自动驾驶、智能摄像头、医疗设备、手机端AI应用（如人脸解锁、实时滤镜）等对延迟、隐私、离线性有要求的场景。",
      "hint": "边缘=‘本地干活’（快、隐私、离线），云端=‘远程干活’（强、好更）～",
      "explanation": "边缘部署和云部署是计算机视觉模型落地的两种核心方式，其差异源于‘计算位置’的不同。边缘部署将推理过程放在终端设备，云部署将推理放在云端服务器。选择时需权衡延迟、隐私、算力、成本等因素：对实时性、隐私性要求高的场景优先边缘部署；对模型复杂度、更新灵活性要求高的场景（如大规模图像分析、复杂生成任务）优先云部署，或采用‘边缘+云端’混合部署方案。"
    },
  // 第十一章
  
  {
    "id": "nlp-001",
    "type": "choice",
    "question": "下列关于结构化数据与非结构化数据的描述，错误的是？",
    "options": [
      "结构化数据有预定义数据模型，类似Excel表格",
      "非结构化数据无固定schema，但内部可能存在隐性结构",
      "文本是最典型的结构化数据，占所有生成数据的80%-90%",
      "聊天记录、朋友圈文案属于非结构化数据"
    ],
    "answer": 2,
    "hint": "记住：结构化=表格，非结构化=自由文案，文本可是非结构化的主力军哦～",
    "explanation": "解析：根据资料，文本是最典型的非结构化数据，而非结构化数据占所有生成数据的80%-90%，因此选项C表述错误。选项A正确，结构化数据有明确的行列分类，类似Excel；选项B正确，非结构化数据无统一组织方式，但可能存在内在逻辑（如聊天记录的上下文）；选项D正确，自由书写的内容均属于非结构化数据。核心考点是两类数据的定义和典型案例。"
  },
  {
    "id": "nlp-002",
    "type": "choice",
    "question": "在文本预处理中，下列哪种场景不适合去除停用词？",
    "options": [
      "新闻文本分类任务，需聚焦核心主题词",
      "情感分析任务，判断用户评论的情绪倾向",
      "通用文本的关键词提取，减少计算量",
      "学术论文摘要的浓缩，保留核心观点"
    ],
    "answer": 1,
    "hint": "停用词里的“not”可是情感分析的“关键反转剂”，删了可就闹笑话啦！",
    "explanation": "解析：资料明确提到，停用词去除需基于任务选择，情感分析中否定词（如not）不能去除，否则会丢失语义（如“不喜欢”会变成“喜欢”，导致情感判断错误），因此选项B正确。其他选项均为适合去除停用词的场景：新闻分类、关键词提取、论文摘要浓缩均需聚焦核心词汇，去除高频低信息量的停用词可提升效率和准确性。核心考点是停用词去除的适用场景。"
  },
  {
    "id": "nlp-003",
    "type": "choice",
    "question": "关于词干提取（Stemming）和词形还原（Lemmatization）的区别，下列说法正确的是？",
    "options": [
      "词干提取考虑词性和语境，结果一定是合法单词",
      "词形还原不依赖词汇表，仅通过去除词缀得到根形式",
      "数据稀疏时优先使用词干提取，需精准语义时用词形还原",
      "词干提取速度慢但精准，词形还原速度快但结果可能不合法"
    ],
    "answer": 2,
    "hint": "词干提取=粗暴裁剪（快但可能残），词形还原=精细修剪（准但费功夫）",
    "explanation": "解析：根据资料，词干提取的特点是不考虑词性和语境，速度快但结果可能非合法单词；词形还原需考虑词性和语境，依赖词汇表，结果合法但更复杂。因此选项A、B、D表述错误。选项C正确，数据稀疏时需减少词汇量，词干提取可快速合并相似词；需精准语义（如情感分析、机器翻译）时，词形还原能保证语义准确性。核心考点是两者的定义、特点及适用场景对比。"
  },
  {
    "id": "nlp-004",
    "type": "choice",
    "question": "Transformer-based语言模型的核心优势不包括下列哪项？",
    "options": [
      "通过自注意力机制捕捉全局上下文关系",
      "支持并行计算，训练效率更高",
      "仅能处理固定长度的上下文窗口",
      "能有效捕捉长距离语义依赖"
    ],
    "answer": 2,
    "hint": "Transformer=全景摄像头，固定窗口=望远镜，视野差距很大哦～",
    "explanation": "解析：资料指出，Transformer-based LM的核心优势包括：理解全局上下文（自注意力机制）、支持并行计算、捕捉长距离语义依赖。选项C“仅能处理固定长度的上下文窗口”是Feedforward NLMs的特点，而非Transformer的优势，因此为错误选项。核心考点是Transformer-based LM的核心优势，需与其他类型神经LM区分。"
  },
  {
    "id": "nlp-005",
    "type": "choice",
    "question": "统计语言模型（N-gram）面临的主要问题是？",
    "options": [
      "无法处理短距离上下文依赖",
      "数据稀疏性导致未见过的词序列概率为0",
      "过度依赖语义理解，计算成本高",
      "仅能处理单语言文本，不支持多语言"
    ],
    "answer": 1,
    "hint": "N-gram：没见过的组合=不存在？这可太“刻板”啦！",
    "explanation": "解析：资料明确统计语言模型的局限性包括数据稀疏性（罕见或未见过的词组合概率为0）、固定上下文窗口、缺乏语义理解。选项A错误，N-gram可处理短距离依赖（如trigram处理前2个词）；选项C错误，统计LM不依赖语义理解，仅基于词频；选项D错误，统计LM可通过多语言语料训练支持多语言。核心考点是统计LM的局限性。"
  },
  {
    "id": "nlp-006",
    "type": "fill",
    "question": "非结构化数据占所有生成数据的______，其最典型的形式是______。",
    "answer": "80%-90%；文本",
    "hint": "非结构化数据=文字海洋，占比超八成，记住“八九十”和“文本”就稳啦！",
    "explanation": "解析：资料明确提到“非结构化数据无固定schema，内部有结构但无统一组织，文本是最典型的非结构化数据，占所有生成数据的80%-90%”。核心考点是非结构化数据的占比和典型形式，为基础记忆类知识点。"
  },
  {
    "id": "nlp-007",
    "type": "fill",
    "question": "NLP流水线分为三个阶段，分别是______、______和应用层。",
    "answer": "文本预处理；语言处理",
    "hint": "NLP流水线=工厂加工：先洗原料（预处理），再加工（语言处理），最后出产品（应用）",
    "explanation": "解析：资料指出NLP流水线包括文本预处理（清洁与标准化文本、分词等）、语言处理（词性标注、NER、句法分析等）、应用层（情感分析、文本分类等）。核心考点是NLP流水线的三个核心阶段，需按顺序记忆。"
  },
  {
    "id": "nlp-008",
    "type": "fill",
    "question": "神经语言模型中，将单词映射为低维密集向量的核心组件是______，其本质是给每个单词分配一张“语义身份证”。",
    "answer": "词嵌入（Word Embeddings）",
    "hint": "单词→向量=身份证，这个组件叫“词嵌入”，嵌入=融入语义呀！",
    "explanation": "解析：资料定义词嵌入为“将单词映射为低维密集向量，是神经网络的输入层”，且直观理解为“给每个单词发一张‘语义身份证’”。核心考点是神经LM的核心组件——词嵌入的定义，需明确其功能。"
  },
  {
    "id": "nlp-009",
    "type": "fill",
    "question": "大型语言模型（LLMs）的核心特点包括训练数据规模大、______和______。",
    "answer": "模型参数多；通用能力强",
    "hint": "LLM=博学学者：读得多（数据大）、脑子活（参数多）、本事全（通用强）",
    "explanation": "解析：资料提到LLMs的核心特点是“训练数据规模大（互联网级语料：网页、书籍、代码）、模型参数多（数十亿级）、通用能力强（一次训练可适配多种任务，无需大量微调）”。核心考点是LLMs的核心特点，需准确记忆三个关键特征。"
  },
  {
    "id": "nlp-010",
    "type": "qa",
    "question": "请简述NLP中文本预处理的核心步骤（至少列出5个）及其主要作用。",
    "answer": "文本预处理的核心步骤及作用如下：1. 分词（Tokenization）：将文本拆分为有意义的tokens，为后续处理提供基础单元；2. 小写化（Lowercasing）：统一文本大小写，提升数据一致性；3. 噪音去除（Noise Removal）：去除标点、特殊字符等无意义元素，突出核心文本；4. 停用词去除（Stopwords Removal）：过滤高频低信息量词，减少计算量；5. 词干提取/词形还原：合并相似词，减少词汇量，提升模型泛化能力；6. 文本归一化：将非标准表达转换为标准词，适配嘈杂文本。",
    "hint": "预处理=给文本“大扫除+精装修”，步骤就是：切分→统一→去脏→减重→变形→规范",
    "explanation": "解析：资料详细介绍了文本预处理的多个核心步骤，每个步骤的作用均围绕“清洁、标准化、简化文本，为后续语言处理和应用层任务奠定基础”。核心考点是文本预处理的步骤及功能，需理解各步骤的必要性和实际作用，而非单纯记忆。"
  },
  {
    "id": "nlp-011",
    "type": "qa",
    "question": "请对比统计语言模型（N-gram）与神经语言模型（Neural LMs）的核心差异（至少从3个维度对比）。",
    "answer": "两者的核心差异如下：1. 建模方式：N-gram基于词频统计，仅关注词序列的出现频率；神经LM通过神经网络学习词序列模式，捕捉语义信息；2. 上下文处理：N-gram受固定上下文窗口限制（如trigram仅看前2个词），神经LM（尤其是Transformer）可处理长距离依赖，甚至全局上下文；3. 数据稀疏性：N-gram面临严重的数据稀疏性，未见过的词组合概率为0；神经LM通过词嵌入和语义学习，可泛化到未见过的词组合；4. 语义理解：N-gram无语义理解能力，仅基于统计规律；神经LM能学习词的语义关联（如同义词、类比关系）。",
    "hint": "N-gram=记账先生（记次数），神经LM=语言学者（懂意思），差异全在“统计”vs“语义”",
    "explanation": "解析：资料分别介绍了统计LM和神经LM的定义、特点、优势及局限性，核心差异可从建模逻辑、上下文捕捉能力、数据稀疏性应对、语义理解能力等维度展开。对比类题目需明确两者在同一维度的不同表现，核心考点是两类语言模型的本质区别，需结合其原理和应用场景理解。"
  },
  {
    "id": "nlp-012",
    "type": "choice",
    "question": "下列关于语言模型下一词预测的应用场景，说法错误的是？",
    "options": [
      "语音识别中区分同音异义短语，选择概率更高的序列",
      "机器翻译中确保目标语言输出语法正确、流畅自然",
      "拼写纠错仅能纠正单词本身的拼写错误，无法处理合法词的语境错误",
      "邮件自动补全功能基于语言模型的下一词预测逻辑"
    ],
    "answer": 2,
    "hint": "拼写纠错：不仅看单词对不对，还看语境合不合哦！",
    "explanation": "解析：资料提到拼写纠错的应用场景是“基于上下文纠正拼写错误（错误单词本身是合法词）”，例如“minuets”（小步舞）在“fifteen minuets”中需纠正为“minutes”（分钟），因此选项C表述错误。其他选项均符合语言模型下一词预测的应用场景：语音识别（区分同音异义）、机器翻译（流畅性排序）、邮件补全（下一词联想）。核心考点是语言模型下一词预测的具体应用场景。"
  },
  {
    "id": "nlp-013",
    "type": "fill",
    "question": "词形还原（Lemmatization）需要考虑单词的______和______，确保转换后的基础形式（Lemma）具有实际意义。",
    "answer": "词性（POS）；语境",
    "hint": "词形还原=精细修剪，要知道单词“身份”（词性）和“处境”（语境）才不会剪错！",
    "explanation": "解析：资料定义词形还原为“考虑单词的词性（POS）和语境，将其转换为有意义的基础形式（Lemma），依赖词汇表和形态学分析”。核心考点是词形还原的关键依赖因素，需与词干提取（不考虑词性和语境）区分。"
  },
  {
    "id": "nlp-014",
    "type": "qa",
    "question": "请解释“N-gram与搭配（Collocations）的核心区别”，并举例说明。",
    "answer": "核心区别：N-gram是对连续n个词序列的无差别统计，仅基于位置和频率，不考虑语义合理性；搭配是频繁共现且具有约定俗成意义的词对/短语，聚焦有意义的组合。举例：N-gram会统计“seat and”“and made”等无独立意义的词对；搭配仅识别“take a seat”“make a suggestion”“strong tea”等常用且有特定含义的组合。",
    "hint": "N-gram=扫街式计数，搭配=精品筛选，一个“广撒网”，一个“抓重点”",
    "explanation": "解析：资料明确N-gram的特点是“统计所有连续的n个词序列，仅基于位置和频率，不考虑语义是否合理”，搭配的特点是“频繁共现、具有约定俗成意义的词对/短语”，核心区别在于是否“筛选有意义的组合”。举例需紧扣定义，体现两者的差异。核心考点是N-gram与搭配的本质区别，需理解统计规律与语义合理性的关系。"
  }
  	
];