/* --- 数据库 (这里只放了一部分示例，你可以把之前的都加进来) --- */
window.DB = /* --- 完整无遗漏版：请将此代码块复制到 DB 数组中 --- */

[
    // ==========================================
    // 核心定义与层级
    // ==========================================
   // ==========================================
       // 第一章：核心定义与层级
       // ==========================================
       {
           id: "Def-01",
           term: "什么是人工智能 (AI)",
           parent: "人工智能概览",
           rarity: "R",
           hint: "不是死记硬背的书呆子。",
           def: "在计算机系统中模拟人类智能过程（学习、推理、自我修正、感知）。",
           analogy: "就像教一个“数字徒弟”，让它不仅能死记硬背，还能像人一样思考、纠错和举一反三。",
           pitfall: "核心能力包含：获取信息（学习）、得出结论（推理）、自我修正（反馈）、模式识别。"
       },
       {
           id: "Def-02",
           term: "弱人工智能 (Narrow AI)",
           parent: "AI系统的三大层级",
           rarity: "R",
           hint: "严重偏科的单项冠军。",
           def: "专为特定任务设计的系统，无法跨领域泛化。",
           analogy: "如下棋只会下棋的AlphaGo，让它去识别猫它就傻了。就像Siri或Alexa。",
           pitfall: "目前主流应用（如垃圾邮件过滤器）均属此类。"
       },
       {
           id: "Def-03",
           term: "通用人工智能 (General AI)",
           parent: "AI系统的三大层级",
           rarity: "SSR",
           hint: "钢铁侠的贾维斯。",
           def: "具备人类水平的认知能力，能跨领域理解、学习和应用知识。",
           analogy: "“全能管家”，能像人一样处理各种未见过的复杂问题。",
           pitfall: "现状：尚未实现，仍是理论研究热点。"
       },
       // 
       // 展示弱人工智能（单任务）与通用人工智能（多任务/跨领域）的能力范围对比。
   
       {
           id: "Def-04",
           term: "超人工智能 (Super AI)",
           parent: "AI系统的三大层级",
           rarity: "UR",
           hint: "神一般的存在。",
           def: "在所有领域都超越人类智能的假设性存在。",
           analogy: "智力远超人类认知的极限，人类看它就像蚂蚁看人类。",
           pitfall: "时间线：高度推测性，属于遥远的未来。"
       },
   
       // ==========================================
       // 第二章：历史与起源 (1943-1956)
       // ==========================================
       {
           id: "Hist-01",
           term: "M-P 神经元 (1943)",
           parent: "AI的黎明 (1943-1956)",
           rarity: "SR",
           hint: "把大脑变成开关。",
           def: "麦卡洛克-皮茨提出的首个神经网络数学模型，证明神经元可以计算逻辑函数。",
           analogy: "就像把大脑神经元简化成了一个“电子开关”，奠定了“机器大脑”的电路图基础。"
       },
       // 
       // 帮助理解如何用简单的神经元模型实现与门、或门等逻辑运算。
   
       {
           id: "Hist-02",
           term: "图灵测试 (1950)",
           parent: "AI的黎明 (1943-1956)",
           rarity: "SR",
           hint: "隔着屏幕的蒙眼盲测。",
           def: "艾伦·图灵提出：询问者通过文本与人类和机器对话，如果分辨不出谁是机器，则机器通过测试。",
           analogy: "只要能骗过人类裁判，装得像个人，就算你有智能。",
           pitfall: "现代意义：启发了聊天机器人(Chatbot)和NLP的发展。"
       },
       {
           id: "Hist-03",
           term: "达特茅斯会议 (1956)",
           parent: "AI的黎明 (1943-1956)",
           rarity: "SSR",
           hint: "AI的出生证明。",
           def: "约翰·麦卡锡等人正式提出“人工智能”一词，确立AI为一门独立的学科。",
           analogy: "一群大佬开会决定给这个新出生的孩子起名叫“人工智能”。"
       },
   
       // ==========================================
       // 第三章：符号主义时期
       // ==========================================
       {
           id: "Sym-01",
           term: "逻辑理论家 (Logic Theorist)",
           parent: "黄金年代与符号主义 (1956-1974)",
           rarity: "R",
           hint: "机器也能证明数学题。",
           def: "证明了《数学原理》中的数学定理。",
           analogy: "证明了机器可以进行“类人推理”。"
       },
       {
           id: "Sym-02",
           term: "ELIZA (1966)",
           parent: "黄金年代与符号主义 (1956-1974)",
           rarity: "R",
           hint: "最早的话术大师。",
           def: "通过模式匹配模拟心理治疗师的程序。",
           analogy: "虽然它不懂你在说什么，但它会套用句式（如“你为什么...”）假装在听。",
           pitfall: "本质只是简单的关键词匹配。"
       },
       {
           id: "Sym-03",
           term: "通用问题求解器 (GPS)",
           parent: "黄金年代与符号主义 (1956-1974)",
           rarity: "SR",
           hint: "试图打造万能钥匙。",
           def: "试图将“解题策略”与“具体问题”分离的系统。",
           analogy: "想用一套逻辑解开所有类型的锁，结果失败了。"
       },
       {
           id: "Sym-04",
           term: "符号主义范式 (Symbolic AI)",
           parent: "黄金年代与符号主义 (1956-1974)",
           rarity: "SSR",
           hint: "严格按手册办事的法条主义者。",
           def: "认为智能可简化为符号操作，基于明确逻辑和规则。自上而下(Top-down)，显式知识表示。",
           analogy: "认为智能就是背熟一本厚厚的《规则手册》，严格按手册办事。"
       },
   
       // ==========================================
       // 第四章：第一次寒冬与专家系统
       // ==========================================
       {
           id: "Winter-01",
           term: "算力限制 (组合爆炸)",
           parent: "第一次AI寒冬 (1974-1980)",
           rarity: "R",
           hint: "算盘算不过台风。",
           def: "简单任务需要的资源呈指数级增长，导致计算不可能完成。",
           analogy: "理想很丰满，硬件很骨感。想用算盘去模拟台风路径，根本算不过来。"
       },
       {
           id: "Winter-02",
           term: "常识缺失",
           parent: "第一次AI寒冬 (1974-1980)",
           rarity: "R",
           hint: "高分低能的书呆子。",
           def: "机器缺乏背景知识和直觉，无法处理显而易见的琐事。",
           analogy: "AI会解微积分，但不知道“下雨要收衣服”。"
       },
       {
           id: "Winter-03",
           term: "资金削减",
           parent: "第一次AI寒冬 (1974-1980)",
           rarity: "R",
           hint: "承诺落空，金主撤资。",
           def: "因ALPAC报告等批评，导致信任破产，经费被砍。",
           analogy: "画的大饼实现不了，投资人愤怒离场。"
       },
       {
           id: "Exp-01",
           term: "专家系统 (Expert Systems)",
           parent: "专家系统的复兴 (1980-1987)",
           rarity: "SR",
           hint: "把老专家的脑子数字化。",
           def: "捕捉特定领域专家知识，基于规则库进行决策的程序。架构：UI + 规则引擎 + 知识库。",
           analogy: "变成一本可以自动查阅的《超级百科全书》。"
       },
       // 
       // 展示用户界面、推理引擎和知识库之间的交互关系。
   
       {
           id: "Exp-02",
           term: "专家系统典型案例",
           parent: "专家系统的复兴 (1980-1987)",
           rarity: "R",
           hint: "MYCIN 和 XCON。",
           def: "MYCIN(1976)诊断细菌感染匹敌专家；XCON(1980)配置计算机系统省下巨款。",
           analogy: "证明了AI在特定领域能赚钱、能干活。"
       },
       {
           id: "Exp-03",
           term: "知识获取瓶颈",
           parent: "知识工程的瓶颈",
           rarity: "R",
           hint: "只可意会不可言传。",
           def: "专家很难将隐性知识表达为显性规则，提取过程费时费力。",
           analogy: "老中医的经验很难写成代码。"
       },
       {
           id: "Exp-04",
           term: "脆弱性 (Brittleness)",
           parent: "知识工程的瓶颈",
           rarity: "R",
           hint: "只会做番茄炒蛋。",
           def: "一旦超出设定领域，系统直接崩溃，无法处理意外。",
           analogy: "给只会做番茄炒蛋的机器人一个青椒，它就死机了。"
       },
       {
           id: "Exp-05",
           term: "缺乏学习能力",
           parent: "知识工程的瓶颈",
           rarity: "R",
           hint: "不教就不会。",
           def: "规则必须手动更新，无法从经验中自我进化。",
           analogy: "没有自学能力，只能靠人喂。"
       },
       {
           id: "Winter-04",
           term: "第二次AI寒冬 (1987-1993)",
           parent: "第二次AI寒冬 (1987-1993)",
           rarity: "R",
           hint: "太贵，不如雇人。",
           def: "市场萎缩，维护成本高昂（更新规则太麻烦），项目失败率高（约75%被废弃）。",
           analogy: "企业发现维护这套系统比雇个活人还贵。"
       },
   
       // ==========================================
       // 第五章：机器学习革命
       // ==========================================
       {
           id: "ML-01",
           term: "范式转移 (Paradigm Shift)",
           parent: "机器学习革命 (1993-2011)",
           rarity: "UR",
           hint: "从死记硬背到题海战术。",
           def: "从“手动编码规则”转向“从数据中学习模式”。驱动力：摩尔定律+大数据+算法突破。",
           analogy: "以前是给AI喂“死记硬背的课本”，现在是给AI看“海量真题”，让它自己找规律。"
       },
       {
           id: "ML-02",
           term: "监督学习 (Supervised Learning)",
           parent: "机器学习三大类",
           rarity: "R",
           hint: "有老师辅导的刷题。",
           def: "从“带标签”的例子中学习映射关系（输入->输出）。应用：图像识别、垃圾邮件检测。",
           analogy: "做完题老师告诉你对错，你修正思路。"
       },
       // 
       // 对比监督学习（有标签分类）和无监督学习（无标签聚类）的数据处理方式。
   
       {
           id: "ML-03",
           term: "无监督学习 (Unsupervised Learning)",
           parent: "机器学习三大类",
           rarity: "R",
           hint: "无人指导的积木分类。",
           def: "在“无标签”数据中发现隐藏结构和模式。应用：聚类、异常检测。",
           analogy: "给你一堆积木，你自己按形状或颜色把它们分开。"
       },
       {
           id: "ML-04",
           term: "强化学习 (Reinforcement Learning)",
           parent: "机器学习三大类",
           rarity: "SR",
           hint: "驯兽模式。",
           def: "通过与环境交互，基于“奖励/惩罚”机制学习最优策略。应用：游戏AI、机器人控制。",
           analogy: "做对了给骨头（奖励），做错了打手心（惩罚），慢慢学会规矩。"
       },
   
       // ==========================================
       // 第六章：深度学习与未来
       // ==========================================
       {
           id: "DL-01",
           term: "AlexNet (2012)",
           parent: "深度学习时代 (2012-至今)",
           rarity: "SSR",
           hint: "AI的开眼时刻。",
           def: "将图像分类错误率从26%降至15%。关键创新：深层架构、ReLU、Dropout、GPU实现、数据增强。",
           analogy: "给电脑装上了“视网膜”和“视觉皮层”，并用游戏显卡做涡轮增压，AI终于能看懂图了。"
       },
       // 
       // 展示AlexNet的多层卷积结构，是深度学习爆发的标志性模型。
   
       {
           id: "Future-01",
           term: "多模态 AI",
           parent: "未来趋势与启示",
           rarity: "SR",
           hint: "眼观六路，耳听八方。",
           def: "整合视觉、语言等多种感官信息。",
           analogy: "AI不再是“瞎子听力好”或“聋子视力好”，而是全才。"
       },
       {
           id: "Future-02",
           term: "高效 AI (Efficient AI)",
           parent: "未来趋势与启示",
           rarity: "R",
           hint: "既要马儿跑，又要马儿少吃草。",
           def: "通过新架构降低算力成本和环境影响。",
           analogy: "目标是省电、省算力。"
       },
       {
           id: "Future-03",
           term: "可信 AI",
           parent: "未来趋势与启示",
           rarity: "SR",
           hint: "三观要正。",
           def: "确保公平性、透明度、鲁棒性，符合人类价值观。",
           analogy: "AI不仅要聪明，还要不偏见、不干坏事。"
       },
       {
           id: "Future-04",
           term: "通用智能 (目标)",
           parent: "未来趋势与启示",
           rarity: "UR",
           hint: "终极追求。",
           def: "追求更广泛的推理和迁移学习能力。",
           analogy: "未来的发展方向。"
       },
   
       // ==========================================
       // 第七章：历史教训与基础
       // ==========================================
       {
           id: "Lesson-01",
           term: "炒作周期",
           parent: "历史的教训",
           rarity: "R",
           hint: "捧杀风险。",
           def: "管理预期至关重要，避免捧杀。",
           analogy: "不要在期望膨胀期过度神话AI。"
       },
       {
           id: "Lesson-02",
           term: "数据与算力",
           parent: "历史的教训",
           rarity: "R",
           hint: "燃料与引擎。",
           def: "基础设施投资与算法创新同等重要。",
           analogy: "没有数据和算力，算法跑不起来。"
       },
       {
           id: "Lesson-03",
           term: "学习优于手写",
           parent: "历史的教训",
           rarity: "SSR",
           hint: "苦涩的教训。",
           def: "可扩展性：让机器自己学习比人类手动教效率高得多。",
           analogy: "手写规则总有尽头，自我学习潜力无穷。"
       },
       {
           id: "Lesson-04",
           term: "跨学科基础",
           parent: "历史的教训",
           rarity: "R",
           hint: "AI是混血儿。",
           def: "AI是计算机、数学、神经科学、心理学、哲学的结晶。",
           analogy: "多学科交叉的产物。"
       },
	// ==========================================
	    // 1. 核心定义与范式 (Foundations)
	    // ==========================================
	    {
	        id: "Agent-01",
	        term: "核心范式转变 (The Paradigm Shift)",
	        parent: "Root",
	        rarity: "UR",
	        hint: "从计算器到实习生。",
	        def: "AI从‘静态模型’（单纯生成输出）向‘动态智能体’（感知、决策、并在时间循环中迭代行动）的演变。",
	        analogy: "以前的AI像个‘计算器’，按一下出一个结果；现在的AI像个‘数字实习生’，能在这个世界里连续工作、观察并搞定任务。",
	        pitfall: "是从被动工具到主动实体的质变。"
	    },
	    {
	        id: "Agent-02",
	        term: "什么是智能体 (Agent)",
	        parent: "Root",
	        rarity: "SSR",
	        hint: "有感知、有思考、有行动的实体。",
	        def: "任何通过传感器感知环境，并通过执行器作用于环境以实现目标的实体。数学表达：$f: P^* \\rightarrow A$ (感知历史映射到行动)。",
	        analogy: "就像人类：眼睛耳朵是传感器，大脑是处理器，手脚是执行器，一直在不停地与世界互动。",
	        pitfall: "核心循环：感知(Perception) -> 思考(Thinking) -> 行动(Action) -> 循环。"
	    },
	    // 
	    // 展示智能体通过传感器接收环境反馈，通过执行器改变环境的闭环过程。
	
	    // ==========================================
	    // 2. 环境分类 (Environment Dimensions)
	    // ==========================================
	    {
	        id: "Env-01",
	        term: "完全 vs 部分可观测",
	        parent: "环境的核心定义",
	        rarity: "R",
	        hint: "下棋 vs 打牌。",
	        def: "完全可观测指传感器能检测到环境所有状态；部分可观测指只能看到一部分。",
	        analogy: "下象棋（全看得到，完全可观测） vs 打扑克/麻将（看不到对手的牌，部分可观测）。"
	    },
	    {
	        id: "Env-02",
	        term: "确定性 vs 随机性",
	        parent: "环境的核心定义",
	        rarity: "R",
	        hint: "菜谱 vs 彩票。",
	        def: "确定性指下一步完全由当前状态和行动决定；随机性指结果包含运气成分。",
	        analogy: "按照食谱做菜（确定） vs 买彩票/炒股（充满随机运气）。"
	    },
	    {
	        id: "Env-03",
	        term: "片段式 vs 序列式",
	        parent: "环境的核心定义",
	        rarity: "R",
	        hint: "看图 vs 下棋。",
	        def: "片段式指当前决策不影响未来；序列式指当前决策会引发连锁反应。",
	        analogy: "辨认一张照片（这单做完就完了） vs 下围棋/开车（一步走错，全盘皆输）。"
	    },
	    {
	        id: "Env-04",
	        term: "静态 vs 动态",
	        parent: "环境的核心定义",
	        rarity: "R",
	        hint: "数独 vs 即时战略。",
	        def: "静态指思考时环境不变；动态指环境会随时间自动变化。",
	        analogy: "解数独（你不填数字它不动） vs 开车/打王者荣耀（你发呆一秒，车可能就撞了）。"
	    },
	    {
	        id: "Env-05",
	        term: "离散 vs 连续",
	        parent: "环境的核心定义",
	        rarity: "R",
	        hint: "格子 vs 角度。",
	        def: "离散指状态/行动数量有限；连续指数量无限。",
	        analogy: "下棋（格子是固定的） vs 扔飞镖/开车（角度和力度有无限种可能）。"
	    },
	    {
	        id: "Env-06",
	        term: "单智能体 vs 多智能体",
	        parent: "环境的核心定义",
	        rarity: "R",
	        hint: "填字游戏 vs 早高峰。",
	        def: "环境中是否包含其他正在互动的智能体。",
	        analogy: "一个人玩填字游戏 vs 在早高峰的车流中变道（需要预判别人的预判）。"
	    },
	
	    // ==========================================
	    // 3. 核心设计要素 (PEAS & Terminology)
	    // ==========================================
	    {
	        id: "PEAS-01",
	        term: "PEAS 核心四要素",
	        parent: "Root",
	        rarity: "SR",
	        hint: "设计智能体的第一步。",
	        def: "P(Performance 性能), E(Environment 环境), A(Actuators 执行器), S(Sensors 传感器)。",
	        analogy: "以出租车为例：P=安全快速赚钱；E=道路天气；A=方向盘油门；S=摄像头GPS。",
	        pitfall: "必须明确定义这四个维度，智能体才能设计出来。"
	    },
	    // 
	    // 具体的表格或图示，列出PEAS四个字母对应的具体组件。
	
	    {
	        id: "Term-01",
	        term: "软件智能体 vs 传统函数",
	        parent: "软件智能体 vs 传统程序",
	        rarity: "R",
	        hint: "长寿的管家 vs 短命的外卖员。",
	        def: "智能体有状态维持（记忆）和自主性（自己决定何时动）；函数算完就忘，被动调用。",
	        analogy: "函数像‘外卖员’，送完这单就结束；智能体像‘私人管家’，一直陪着你，记得你的喜好，主动安排。"
	    },
	    {
	        id: "Term-02",
	        term: "智能体术语辨析",
	        parent: "软件智能体术语辨析",
	        rarity: "SR",
	        hint: "大脑 vs 完整的人。",
	        def: "Model=大脑(GPT-4)；Agent=大脑+手脚+记忆；Environment=外部背景。",
	        analogy: "Model是‘缸中之脑’；Agent是装备齐全的‘打工人’；Environment是它的‘办公室’。"
	    },
	    {
	        id: "Term-03",
	        term: "自主智能体 (Autonomous Concepts)",
	        parent: "核心概念",
	        rarity: "SSR",
	        hint: "从聊天到干活。",
	        def: "具有高度自主性，极少人类干预，能处理多步复杂任务并主动使用工具。",
	        analogy: "从‘我问你答’的聊天机器人，进化成‘我说目标，你搞定过程’的项目经理。"
	    },
	
	    // ==========================================
	    // 4. 设计模式 (Design Patterns)
	    // ==========================================
	    {
	        id: "Pattern-ReAct",
	        term: "ReAct 模式 (Reason + Act)",
	        parent: "ReAct 模式",
	        rarity: "SSR",
	        hint: "想一步，做一步。",
	        def: "思考(Thought) -> 行动(Action) -> 观察(Observation) -> 循环。解决大模型无法获取实时信息和幻觉问题。",
	        analogy: "就像人做题：先想思路(Think)，再草稿纸上算(Act)，看结果对不对(Obs)，最后写答案。",
	        pitfall: "工作流：思考需求 -> 调用工具 -> 观察结果 -> 整理答案。"
	    },
	    // 
	    // 展示思考、行动、观察的循环流程图。
	
	    {
	        id: "Pattern-Reflexion",
	        term: "Reflexion 模式",
	        parent: "Reflexion 模式",
	        rarity: "SR",
	        hint: "自带内部批评家。",
	        def: "在生成结果后增加‘自我评估’环节：生成草稿 -> 自我批评 -> 修改 -> 输出。",
	        analogy: "就像写作文，写完自己先读一遍，改改错别字和不通顺的地方，再交给老师。"
	    },
	    {
	        id: "Pattern-RAG-01",
	        term: "RAG 智能体 (检索增强生成)",
	        parent: "RAG 智能体",
	        rarity: "SSR",
	        hint: "考试允许开卷查书。",
	        def: "外挂知识库，解决幻觉和知识截止期问题。包含离线索引和在线检索两部分。",
	        analogy: "大模型记不住所有事，给它配个图书馆，回答问题前先去翻翻书。"
	    },
	    // 
	    // 展示从文档切片、向量化存储到检索生成的全流程。
	
	    {
	        id: "Pattern-RAG-02",
	        term: "RAG流程：离线准备",
	        parent: "RAG 智能体",
	        rarity: "R",
	        hint: "把书切碎了存起来。",
	        def: "1. 文档切块(Chunking)；2. 向量化(Embedding，变数字向量)；3. 存入向量数据库(Vector DB)。",
	        analogy: "为了方便查找，把整本书撕成小纸条，贴上标签放到档案柜里。"
	    },
	    {
	        id: "Pattern-RAG-03",
	        term: "RAG流程：在线检索",
	        parent: "RAG 智能体",
	        rarity: "R",
	        hint: "找资料，贴小抄。",
	        def: "1. 提问；2. 检索(Retrieve)；3. 增强(Augment，把资料贴Prompt里)；4. 生成(Generate)。",
	        analogy: "收到问题 -> 去档案柜找相关纸条 -> 把纸条夹在问题旁边 -> 抄写答案。"
	    },
	
	    // ==========================================
	    // 5. 新兴模式与应用 (Emerging & Apps)
	    // ==========================================
	    {
	        id: "New-01",
	        term: "自我一致性 (Self-Consistency)",
	        parent: "五大新兴设计模式",
	        rarity: "SR",
	        hint: "三个臭皮匠，顶个诸葛亮。",
	        def: "同样的推理跑多遍，选出现次数最多的答案。",
	        analogy: "少数服从多数，防止一次偶然的‘脑抽’。"
	    },
	    {
	        id: "New-02",
	        term: "思维树 (ToT)",
	        parent: "五大新兴设计模式",
	        rarity: "SR",
	        hint: "在脑子里预演未来。",
	        def: "探索多条推理路径，像下棋一样预演几步后果，选最好的。",
	        analogy: "脑暴出A、B、C三个方案，分别推演一下结局，最后选B。"
	    },
	    {
	        id: "New-03",
	        term: "计划-执行-验证",
	        parent: "五大新兴设计模式",
	        rarity: "R",
	        hint: "项目管理标准流程。",
	        def: "把大任务拆解(Plan)，执行(Execute)，做完检查(Verify)。",
	        analogy: "像包工头一样，先把活儿分好，干完验收，没问题再交付。"
	    },
	    {
	        id: "New-04",
	        term: "多智能体协作",
	        parent: "五大新兴设计模式",
	        rarity: "SSR",
	        hint: "全AI创业团队。",
	        def: "不同的智能体扮演不同角色（如产品经理、程序员、测试员）共同完成任务。",
	        analogy: "左手画圆右手画方很难，不如找两个人，一个画圆一个画方。"
	    },
	    {
	        id: "New-05",
	        term: "元控制 (Meta-control)",
	        parent: "五大新兴设计模式",
	        rarity: "UR",
	        hint: "智能体的管理者。",
	        def: "有一个高级经理智能体，决定何时调用什么模型或资源。",
	        analogy: "大老板不干活，只负责指挥哪个部门该上了。"
	    },
	    {
	        id: "Apps-01",
	        term: "现实世界应用",
	        parent: "现实世界应用",
	        rarity: "R",
	        hint: "超级Siri与AI员工。",
	        def: "对话助手(订票)、客户服务(退款)、自主研究(写报告)、编程智能体(Debug)、多模态保安(看监控)。",
	        analogy: "AI开始真正‘进厂打工’了。"
	    },
		// ==========================================
		    // 1. AI解决问题的核心基础
		    // ==========================================
		    {
		        id: "Core-01",
		        term: "AI解决问题的定义",
		        parent: "AI解决问题的核心基础",
		        rarity: "R",
		        hint: "从起点到终点的旅程。",
		        def: "从给定的‘初始状态’移动到期望的‘目标状态’的过程。",
		        analogy: "就像玩‘密室逃脱’或迷宫游戏。你站在入口（Start），必须找到出口（Goal）。中间做的每一个决定（左转、右转）都是一个行动（Action），需要一连串正确的行动才能通关。"
		    },
		    {
		        id: "Core-02",
		        term: "目标导向智能体 (Goal-Directed Agent)",
		        parent: "AI解决问题的核心基础",
		        rarity: "SR",
		        hint: "为了目的不择手段的智能体。",
		        def: "为了达成特定目标，必须选择一系列行动序列的智能体。",
		        analogy: "它不像条件反射的动物，而是像有计划的猎人，为了抓兔子（目标），会先设陷阱、隐藏气味（行动序列）。"
		    },
		    {
		        id: "Pillar-01",
		        term: "问题形式化四大支柱 (4 Pillars)",
		        parent: "AI解决问题的核心基础",
		        rarity: "SSR",
		        hint: "构建AI问题的四根柱子。",
		        def: "1. 状态空间 (State Space); 2. 目标测试 (Goal Test); 3. 后继函数 (Successor Function); 4. 路径代价 (Path Cost)。",
		        analogy: "这四样东西定义了AI眼中的世界。"
		    },
		    {
		        id: "Pillar-State",
		        term: "状态空间 (State Space)",
		        parent: "问题形式化四大支柱 (4 Pillars)",
		        rarity: "R",
		        hint: "地图上所有的点。",
		        def: "系统可能处于的所有状态的集合，即AI操作的环境。",
		        analogy: "棋盘上所有棋子可能摆放的位置组合，或者是地图上所有可能的坐标点。"
		    },
		    {
		        id: "Pillar-Goal",
		        term: "目标测试 (Goal Test)",
		        parent: "问题形式化四大支柱 (4 Pillars)",
		        rarity: "R",
		        hint: "我到了吗？",
		        def: "确定当前状态是否就是目标状态的判断标准。",
		        analogy: "每走一步都要问一下系统：‘我到了吗？’或者‘游戏结束了吗？’"
		    },
		    {
		        id: "Pillar-Succ",
		        term: "后继函数 (Successor Function)",
		        parent: "问题形式化四大支柱 (4 Pillars)",
		        rarity: "R",
		        hint: "下一步能去哪？",
		        def: "给定状态下所有可能采取的行动集合。",
		        analogy: "站在十字路口，你的导航显示你能‘向东’或‘向西’走，这些选项就是后继函数提供的。"
		    },
		    {
		        id: "Pillar-Cost",
		        term: "路径代价 (Path Cost)",
		        parent: "问题形式化四大支柱 (4 Pillars)",
		        rarity: "R",
		        hint: "过路费。",
		        def: "从一个状态移动到另一个状态所需的努力或成本度量。",
		        analogy: "导航里的‘耗时’最短或‘过路费’最少。代价越低，方案越优。"
		    },
		    {
		        id: "Type-Blind",
		        term: "盲目搜索 (Uninformed Search)",
		        parent: "AI解决问题的核心基础",
		        rarity: "SR",
		        hint: "盲人摸象。",
		        def: "仅使用问题定义中可用的信息，没有任何关于目标的额外提示。",
		        analogy: "在漆黑的房间里找出口，看不见光（无提示），只能沿着墙壁一步步摸索。包含BFS, DFS, UCS等。"
		    },
		    {
		        id: "Type-Informed",
		        term: "启发式搜索 (Heuristic Search)",
		        parent: "AI解决问题的核心基础",
		        rarity: "SR",
		        hint: "寻宝罗盘。",
		        def: "利用关于问题领域的额外知识（启发式信息）来引导搜索方向。",
		        analogy: "虽然没去过终点，但手里的罗盘告诉你‘宝藏在北方’，你会优先往北走，而不是乱撞。"
		    },
		
		    // ==========================================
		    // 2. 广度优先搜索 (BFS)
		    // ==========================================
		    {
		        id: "BFS-01",
		        term: "广度优先搜索 (BFS)",
		        parent: "广度优先搜索 (BFS)",
		        rarity: "SSR",
		        hint: "平静水面的涟漪。",
		        def: "在探索下一层级之前，先探索当前深度的所有节点。使用队列(Queue)，遵循FIFO原则。",
		        analogy: "就像往湖中心扔石子，波纹一圈圈均匀扩散。先把离起点最近的邻居找遍，再找下一圈。排队买奶茶，先到先得。"
		    },
		    // 
		    // 动态展示节点如何按层级（Level-by-Level）被访问。
		
		    {
		        id: "BFS-02",
		        term: "BFS关键特性",
		        parent: "广度优先搜索 (BFS)",
		        rarity: "R",
		        hint: "稳但慢且占内存。",
		        def: "完备性：是（有解必找到）；最优性：是（每步代价相同时）；复杂度：时间O(b^d)，空间O(b^d)。",
		        analogy: "虽然保证能找到最近的解，但如果目标太远，内存会被撑爆。"
		    },
		    {
		        id: "BFS-03",
		        term: "BFS算法步骤",
		        parent: "广度优先搜索 (BFS)",
		        rarity: "R",
		        hint: "入队，标记，找邻居。",
		        def: "1. 起点入队；2. 取出队首标记已访问；3. 未访问邻居入队尾；4. 重复直到队空。",
		        analogy: "标准的排队处理流程。"
		    },
		    {
		        id: "BFS-04",
		        term: "BFS应用场景",
		        parent: "广度优先搜索 (BFS)",
		        rarity: "R",
		        hint: "找最近的人或网页。",
		        def: "P2P网络找最近节点、网络爬虫层级抓取、GPS找周边兴趣点、网络广播扩散。",
		        analogy: "凡是涉及‘最近’或‘层级扩散’的场景都用它。"
		    },
		
		    // ==========================================
		    // 3. 深度优先搜索 (DFS)
		    // ==========================================
		    {
		        id: "DFS-01",
		        term: "深度优先搜索 (DFS)",
		        parent: "深度优先搜索 (DFS)",
		        rarity: "SSR",
		        hint: "不撞南墙不回头的铁头娃。",
		        def: "基于递归和回溯，尽可能深地探索分支。使用栈(Stack)，遵循LIFO原则。",
		        analogy: "一条道走到黑！走进死胡同才回头（回溯）。走迷宫贴着左手墙一直走。"
		    },
		    // 
		    // 对比图：BFS像水波扩散，DFS像一条蛇钻到底。
		
		    {
		        id: "DFS-02",
		        term: "DFS易错点",
		        parent: "深度优先搜索 (DFS)",
		        rarity: "SR",
		        hint: "可能掉进无底洞。",
		        def: "如果搜索空间无限深，DFS可能会陷入死循环，永远找不到解（不具备完备性）。",
		        analogy: "就像在一个无限深的矿井里一直往下挖，可能永远挖不到底，也回不来。"
		    },
		    {
		        id: "DFS-03",
		        term: "DFS应用场景",
		        parent: "深度优先搜索 (DFS)",
		        rarity: "R",
		        hint: "解谜与拓扑。",
		        def: "单解谜题（走迷宫、数独）、检测图中的环、拓扑排序。",
		        analogy: "适合那些需要找到‘一条路’而不是‘最短路’的问题。"
		    },
		
		    // ==========================================
		    // 4. 其他盲目搜索策略
		    // ==========================================
		    {
		        id: "DLS-01",
		        term: "深度受限搜索 (DLS)",
		        parent: "深度受限搜索 (DLS)",
		        rarity: "R",
		        hint: "系着安全绳的探险。",
		        def: "DFS的变体，设定预定义深度限制(Limit)。防止无限循环。",
		        analogy: "虽然是一条道走到黑，但在腰上系了50米绳子。绳子崩直了必须回头，不能无限走。"
		    },
		    {
		        id: "IDS-01",
		        term: "迭代加深搜索 (IDS)",
		        parent: "迭代加深搜索 (IDS)",
		        rarity: "SSR",
		        hint: "由近及远的试探。",
		        def: "结合BFS和DFS优点。逐步增加深度限制（Limit=0, 1, 2...）进行DLS。",
		        analogy: "漆黑房间找钥匙：先摸脚边（深0），没摸到；蹲下摸手臂范围（深1），没摸到；再站起来走两步（深2）。"
		    },
		    {
		        id: "IDS-02",
		        term: "IDS适用场景",
		        parent: "迭代加深搜索 (IDS)",
		        rarity: "R",
		        hint: "不知深浅时最好用。",
		        def: "当搜索空间很大，且不知道目标大概在多深的位置时。",
		        analogy: "既能像BFS找到最近解，又能像DFS省内存。"
		    },
		    {
		        id: "UCS-01",
		        term: "一致代价搜索 (UCS)",
		        parent: "一致代价搜索 (UCS)",
		        rarity: "SR",
		        hint: "精打细算的穷游党。",
		        def: "用于遍历加权图，总是优先探索累积成本最低的路径。使用优先队列。",
		        analogy: "BFS认为路路平等，UCS知道有的路贵有的路便宜。它只走当前累计路费最少的那条路。"
		    },
		    {
		        id: "BiDi-01",
		        term: "双向搜索 (Bidirectional Search)",
		        parent: "双向搜索 (Bidirectional Search)",
		        rarity: "SR",
		        hint: "双向奔赴挖隧道。",
		        def: "同时进行两个搜索：一个从起点向后，一个从终点向前。相遇时停止。",
		        analogy: "两队人从山两头挖隧道，中间打通就完工。比一队挖到底快得多（指数级减少范围）。"
		    },
			// ==========================================
			    // 1. 启发式搜索策略 (Informed Search)
			    // ==========================================
			    {
			        id: "Info-01",
			        term: "启发式搜索策略 (Informed Search)",
			        parent: "Root",
			        rarity: "SR",
			        hint: "拿着寻宝罗盘赶路。",
			        def: "利用关于问题领域的特定知识（启发式信息）来引导搜索过程，关键在于使用 h(n) 评估距离。",
			        analogy: "盲目搜索是无头苍蝇；启发式搜索是手里拿着罗盘，虽然没到终点，但罗盘会告诉你‘往这边走离宝藏更近’。"
			    },
			    {
			        id: "Info-02",
			        term: "启发式函数 h(n)",
			        parent: "启发式搜索策略 (Informed Search)",
			        rarity: "R",
			        hint: "直觉与预估。",
			        def: "估算从当前节点 n 到目标节点的最小代价。",
			        analogy: "这就是你的‘直觉’。比如看地图预估还有多少直线距离。",
			        pitfall: "h(n) 必须非负；若 h(n)=0 则退化为盲目搜索。"
			    },
			    {
			        id: "Info-03",
			        term: "曼哈顿 vs 欧几里得距离",
			        parent: "启发式搜索策略 (Informed Search)",
			        rarity: "R",
			        hint: "出租车 vs 鸟。",
			        def: "曼哈顿：只能横竖走（坐标差绝对值和）；欧几里得：直线飞行（坐标差平方和开根）。",
			        analogy: "曼哈顿像在城市街区开车（不能穿墙）；欧几里得像鸟儿飞（两点一线）。"
			    },
			    // 
			    // 直观展示网格上的折线路径（曼哈顿）与直线路径（欧几里得）的区别。
			
			    // ==========================================
			    // 2. 贪婪最佳优先搜索 (Greedy BFS)
			    // ==========================================
			    {
			        id: "Greedy-01",
			        term: "贪婪最佳优先搜索 (Greedy BFS)",
			        parent: "Root",
			        rarity: "R",
			        hint: "急功近利的赶路人。",
			        def: "评估函数 f(n) = h(n)。总是选择当前看起来离目标最近的节点进行扩展。",
			        analogy: "爬山时只选‘指向山顶’的路，完全不考虑好不好走或是否死胡同。只要方向对，就闷头冲。"
			    },
			    {
			        id: "Greedy-02",
			        term: "Greedy 算法特性",
			        parent: "贪婪最佳优先搜索 (Greedy BFS)",
			        rarity: "R",
			        hint: "短视的代价。",
			        def: "完备性：否（易陷死循环）；最优性：否（可能绕远路）；忽略了已花费代价 g(n)。",
			        analogy: "因为它只看眼前利益（h），可能选了一条看似很近但实际是大坑的路。"
			    },
			
			    // ==========================================
			    // 3. A* 搜索算法 (A* Search)
			    // ==========================================
			    {
			        id: "AStar-01",
			        term: "A* 搜索算法",
			        parent: "Root",
			        rarity: "SSR",
			        hint: "精打细算的旅行家。",
			        def: "评估函数 f(n) = g(n) + h(n)。综合考虑已花费代价 g(n) 和预估剩余代价 h(n)。",
			        analogy: "超级聪明的导航仪。不仅考虑‘还剩多少路’(h)，还计算‘耗了多少油’(g)。总是选总成本最低的路。"
			    },
			    // 
			    // 展示A*算法如何平衡已知路径代价和预估代价来选择最优路径。
			
			    {
			        id: "AStar-02",
			        term: "可采纳性 (Admissibility)",
			        parent: "A* 搜索算法 (A* Search Algorithm)",
			        rarity: "UR",
			        hint: "永远不要吓自己。",
			        def: "h(n) 必须永远不大于实际到达目标的代价 (h(n) <= h*(n))。",
			        analogy: "你的‘预估’必须是乐观的。实际还有10公里，你不能估成20公里，否则A*会因为害怕困难而错过最佳捷径。",
			        pitfall: "这是保证 A* 最优性的核心前提。"
			    },
			    {
			        id: "AStar-03",
			        term: "A* 与 Greedy 的区别",
			        parent: "A* 搜索算法 (A* Search Algorithm)",
			        rarity: "R",
			        hint: "看未来 vs 看全程。",
			        def: "Greedy 只看未来 (h)，A* 既看过去 (g) 也看未来 (h)。",
			        analogy: "Greedy是短视者，A*是全局规划者。"
			    },
			
			    // ==========================================
			    // 4. 极小极大算法 (Minimax)
			    // ==========================================
			    {
			        id: "Mini-01",
			        term: "极小极大算法 (Minimax)",
			        parent: "Root",
			        rarity: "SR",
			        hint: "预判你的预判。",
			        def: "用于两人对抗零和博弈。MAX方想赢（最大化分数），MIN方想让你输（最小化分数）。",
			        analogy: "下棋时假设对手绝顶聪明：‘如果我走这步，他肯定堵我（MIN）；在被堵的情况下，我选最不坏的结果（MAX）。’"
			    },
			    // 
			    // 展示博弈树结构，MAX层选最大值，MIN层选最小值向上传递。
			
			    {
			        id: "Mini-02",
			        term: "Minimax 流程",
			        parent: "极小极大算法 (Minimax Algorithm)",
			        rarity: "R",
			        hint: "推演到结局再回头。",
			        def: "1. 生成博弈树到终局；2. 计算效用值；3. 自底向上回溯（MAX选大，MIN选小）。",
			        analogy: "先把棋推演到最后一步，看看谁赢了，然后一步步倒推现在该怎么走。",
			        pitfall: "本质是DFS，深度太深会算不过来。"
			    },
			
			    // ==========================================
			    // 5. Alpha-Beta 剪枝
			    // ==========================================
			    {
			        id: "AB-01",
			        term: "Alpha-Beta 剪枝",
			        parent: "Root",
			        rarity: "SSR",
			        hint: "别谈了，没必要。",
			        def: "Minimax的优化。当 α ≥ β 时剪枝。减少计算量但不改变结果。",
			        analogy: "精明的老板(MAX)与采购员(MIN)。老板已有赚100的方案(α)，采购员新谈的方案顶多赚80(β)，老板直接打断不听了。"
			    },
			    // 
			    // 展示被剪掉的树枝（Pruned Branches），直观理解为什么不需要计算那些节点。
			
			    {
			        id: "AB-02",
			        term: "Alpha 与 Beta 参数",
			        parent: "Alpha-Beta 剪枝 (Alpha-Beta Pruning)",
			        rarity: "R",
			        hint: "保底与封顶。",
			        def: "Alpha(α)：MAX目前的最好选择（下界/保底）；Beta(β)：MIN目前的最好选择（上界/封顶）。",
			        analogy: "α是我至少能赢多少，β是对手至多让我赢多少。"
			    },
			    {
			        id: "AB-03",
			        term: "剪枝效率",
			        parent: "Alpha-Beta 剪枝 (Alpha-Beta Pruning)",
			        rarity: "R",
			        hint: "算得同样深，但快一倍。",
			        def: "理想情况下复杂度从 O(b^m) 降到 O(b^(m/2))。同样的算力可以多算一倍步数。",
			        pitfall: "节点排序很重要：先检查好棋，剪枝最多。"
			    },
				// ==========================================
				    // 1. 知识表示核心基础
				    // ==========================================
				    {
				        id: "KR-01",
				        term: "知识表示 (KR)",
				        parent: "知识表示 (KR) 的核心基础",
				        rarity: "SR",
				        hint: "教计算机理解世界。",
				        def: "AI的一个领域，用计算机可利用的形式存储信息，使系统能通过推理解决复杂问题。",
				        analogy: "不仅是存像素数据，而是告诉它‘猫是四条腿爱吃鱼的动物’。教外星人理解概念，而不仅仅是看照片。"
				    },
				    {
				        id: "KR-02",
				        term: "知识 vs 数据 vs 信息",
				        parent: "知识表示 (KR) 的核心基础",
				        rarity: "R",
				        hint: "数字 -> 含义 -> 行动。",
				        def: "数据：原始数字(37)；信息：处理后的含义(体温37度)；知识：指导行动的整合信息(38度=发烧=吃药)。",
				        analogy: "数据是面粉，信息是面包，知识是‘饿了要吃面包’的智慧。"
				    },
				    {
				        id: "KR-03",
				        term: "知识库代理循环",
				        parent: "知识表示 (KR) 的核心基础",
				        rarity: "R",
				        hint: "看-学-想-做。",
				        def: "1. 感知(Perceive)；2. 学习(Update KB)；3. 推理(Reason)；4. 行动(Act)。",
				        analogy: "这是AI与世界互动的标准流程。"
				    },
				
				    // ==========================================
				    // 2. 知识的五大类型
				    // ==========================================
				    {
				        id: "Type-01",
				        term: "陈述性知识 (Declarative)",
				        parent: "知识的五大类型",
				        rarity: "R",
				        hint: "百科全书：是什么。",
				        def: "描述‘是什么’(What)的事实和概念。",
				        analogy: "只知道事实，不管怎么用。如‘北京是中国的首都’、‘天空是蓝的’。"
				    },
				    {
				        id: "Type-02",
				        term: "过程性知识 (Procedural)",
				        parent: "知识的五大类型",
				        rarity: "R",
				        hint: "烹饪指南：怎么做。",
				        def: "描述‘怎么做’(How)的规则、策略和步骤。",
				        analogy: "骑自行车的技巧：车往左倒就往左拐。不仅知道车是什么，还知道怎么骑。"
				    },
				    {
				        id: "Type-03",
				        term: "元知识 (Meta-knowledge)",
				        parent: "知识的五大类型",
				        rarity: "SR",
				        hint: "图书馆管理员。",
				        def: "关于知识的知识。",
				        analogy: "‘我不懂医学，但我知道医生懂’。知道知识在哪里，或者知道自己知道什么。"
				    },
				    {
				        id: "Type-04",
				        term: "启发式知识 (Heuristic)",
				        parent: "知识的五大类型",
				        rarity: "R",
				        hint: "老奶奶的智慧。",
				        def: "基于经验法则的知识，基于直觉或过往经验。",
				        analogy: "‘燕子低飞要下雨’。不一定科学，但管用，能快速决策。"
				    },
				    {
				        id: "Type-05",
				        term: "结构化知识 (Structural)",
				        parent: "知识的五大类型",
				        rarity: "R",
				        hint: "思维导图。",
				        def: "描述概念之间关系的知识，如‘部分与整体’、‘分类’。",
				        analogy: "知道‘轮子是汽车的一部分’，‘苹果是一种水果’。"
				    },
				
				    // ==========================================
				    // 3. 优秀KR系统的四大属性
				    // ==========================================
				    {
				        id: "Prop-01",
				        term: "表示充分性",
				        parent: "优秀KR系统的四大属性",
				        rarity: "R",
				        hint: "词汇量够不够。",
				        def: "是否有能力表示该领域所需的所有类型的知识。",
				        analogy: "如果语言里没有‘时间’这个词，就没法表达‘明天见’。"
				    },
				    {
				        id: "Prop-02",
				        term: "推理充分性",
				        parent: "优秀KR系统的四大属性",
				        rarity: "R",
				        hint: "脑子转不转。",
				        def: "是否有能力利用现有知识推导出新知识。",
				        analogy: "已知‘人都会死’+‘你是人’，能不能自动推出‘你会死’？"
				    },
				    {
				        id: "Prop-03",
				        term: "推理效率",
				        parent: "优秀KR系统的四大属性",
				        rarity: "R",
				        hint: "不要瞎想。",
				        def: "能否将推导能力引导到最有希望的方向（速度快）。",
				        analogy: "下棋时优先算能赢的步，而不是计算所有无意义的走法。"
				    },
				    {
				        id: "Prop-04",
				        term: "获取效率",
				        parent: "优秀KR系统的四大属性",
				        rarity: "R",
				        hint: "学习门槛。",
				        def: "获取和插入新信息是否容易。",
				        analogy: "教新知识是不是需要重写整个代码库？如果是，效率太低。"
				    },
				
				    // ==========================================
				    // 4. 逻辑表示法 (Logic)
				    // ==========================================
				    {
				        id: "Logic-01",
				        term: "命题逻辑 (Propositional Logic)",
				        parent: "核心技术一：逻辑表示法",
				        rarity: "R",
				        hint: "简单的开关电路。",
				        def: "最基础逻辑，处理简单真/假陈述。连接词：AND(∧), OR(∨), NOT(¬), If-Then(⇒)。",
				        analogy: "P=灯亮，Q=有电。只能表达‘灯亮且有电’，不能表达具体对象关系。",
				        pitfall: "局限性：无法表达具体的对象（如‘那朵云’）。"
				    },
				    {
				        id: "Logic-02",
				        term: "一阶逻辑 (FOL)",
				        parent: "核心技术一：逻辑表示法",
				        rarity: "SSR",
				        hint: "编程版逻辑。",
				        def: "引入对象、谓词和量词。核心：常量(John)、变量(x)、谓词(Brother(x,y))、量词(∀, ∃)。",
				        analogy: "命题逻辑是写死的值，FOL是可以传参数的函数。能表达‘所有猫都是哺乳动物’。",
				        pitfall: "∀搭配⇒，∃搭配∧。"
				    },
				    // 
				    // 展示全称量词和存在量词的符号及其逻辑含义的图解。
				
				    // ==========================================
				    // 5. 语义网络与框架
				    // ==========================================
				    {
				        id: "SemNet-01",
				        term: "语义网络 (Semantic Networks)",
				        parent: "核心技术二：语义网络",
				        rarity: "SR",
				        hint: "画图党。",
				        def: "基于图形的表示，节点代表概念，连线代表关系(Is-A, Has-A)。",
				        analogy: "白板上的概念图。[猫]--(Is-A)-->[动物]。通过继承关系节省存储。",
				        pitfall: "缺点：复杂量词处理困难，语义有时含糊。"
				    },
				    // 
				    // 展示节点（Nodes）和有向边（Arcs）构成的知识网络。
				
				    {
				        id: "Frame-01",
				        term: "框架 (Frames)",
				        parent: "核心技术三：框架",
				        rarity: "R",
				        hint: "填表党。",
				        def: "结构化表示，将对象的所有典型信息集合在一个单元中。结构：槽(Slots)+填充物(Fillers)。",
				        analogy: "个人简历表或编程中的Object。预定义好模板，遇到新对象填空即可。",
				        pitfall: "是语义网络的结构化升级版。"
				    },
				
				    // ==========================================
				    // 6. 规则与推理
				    // ==========================================
				    {
				        id: "Rule-01",
				        term: "产生式规则 (Production Rules)",
				        parent: "产生式规则",
				        rarity: "R",
				        hint: "条件反射。",
				        def: "IF-THEN结构。IF(条件) THEN(动作)。",
				        analogy: "交通规则：IF红灯 THEN刹车。专家系统常用。"
				    },
				    {
				        id: "Reason-01",
				        term: "正向推理 (Forward Chaining)",
				        parent: "推理机制",
				        rarity: "R",
				        hint: "福尔摩斯探案。",
				        def: "数据驱动。从已知事实出发，不断应用规则，直到得出结论。",
				        analogy: "看到脚印(事实) -> 推导有人来过 -> 推导是谁。"
				    },
				    {
				        id: "Reason-02",
				        term: "反向推理 (Backward Chaining)",
				        parent: "推理机制",
				        rarity: "R",
				        hint: "写论文。",
				        def: "目标驱动。从目标出发，反向寻找支持该目标的证据。",
				        analogy: "先定论点(目标)，再找论据来支持它。"
				    },
					// ==========================================
					    // 1. 机器学习概述
					    // ==========================================
					    {
					        id: "ML-Intro-01",
					        term: "机器学习 (Machine Learning)",
					        parent: "机器学习概述",
					        rarity: "SSR",
					        hint: "数据 + 答案 = 规则。",
					        def: "AI的一个子集，使计算机能够在没有明确编程的情况下学习和改进。核心逻辑是反推规则。",
					        analogy: "做菜。传统编程是给机器人食谱让它做菜；机器学习是给机器人尝一万道菜，让它自己反推总结出食谱。",
					        pitfall: "核心转变：从‘规则驱动’变成‘数据驱动’。"
					    },
					    // 
					    // 直观展示传统编程（输入+规则=输出）与机器学习（输入+输出=规则）的流程差异。
					
					    {
					        id: "ML-Intro-02",
					        term: "Tom Mitchell 定义 (T-E-P)",
					        parent: "机器学习概述",
					        rarity: "SR",
					        hint: "越练越强。",
					        def: "如果程序在任务 T 上的性能 P 随着经验 E 而提高，则称其进行了学习。",
					        analogy: "下棋程序。任务T=下棋，性能P=赢的概率，经验E=和自己下几万盘棋。下得越多赢面越大就是学习。"
					    },
					
					    // ==========================================
					    // 2. 机器学习的三大类型
					    // ==========================================
					    {
					        id: "Type-Super",
					        term: "监督学习 (Supervised Learning)",
					        parent: "机器学习的三大类型",
					        rarity: "R",
					        hint: "有老师辅导的刷题。",
					        def: "使用‘标记数据’训练，学习输入到输出的映射。包含分类（预测类别）和回归（预测数值）。",
					        analogy: "做练习题，书后附带‘标准答案’。做完了对答案，错了就改，直到学会。",
					        pitfall: "典型任务：是不是猫(分类)，房价多少(回归)。"
					    },
					    // 
			
					
					    // 展示分类（画线区分点）与回归（画线拟合趋势）的区别。
					
					    {
					        id: "Type-Unsuper",
					        term: "无监督学习 (Unsupervised Learning)",
					        parent: "机器学习的三大类型",
					        rarity: "R",
					        hint: "自学成才的分类。",
					        def: "使用‘未标记数据’训练，让模型自己发现隐藏结构。主要任务是聚类(Clustering)。",
					        analogy: "给你一堆混在一起的硬币，没人告诉你名字，但你能根据大小颜色把它们分成几堆。",
					        pitfall: "典型任务：客户分群。"
					    },
					    {
					        id: "Type-RL",
					        term: "强化学习 (Reinforcement Learning)",
					        parent: "机器学习的三大类型",
					        rarity: "SR",
					        hint: "训练狗狗。",
					        def: "智能体通过与环境互动，根据‘奖励’或‘惩罚’来学习最佳策略。",
					        analogy: "做对了给肉干（奖励），做错了批评（惩罚）。久而久之知道怎么做能得肉干。"
					    },
					    // 
					
			
					
					    // 展示Agent、Environment、Action、Reward的循环交互图。
					
					    // ==========================================
					    // 3. 深度学习与神经网络
					    // ==========================================
					    {
					        id: "DL-Intro",
					        term: "深度学习 (Deep Learning)",
					        parent: "深度学习与神经网络",
					        rarity: "SSR",
					        hint: "模拟大脑的复杂网络。",
					        def: "ML的子集，使用多层神经网络模拟人类学习。关键特征是能自动提取特征，无需人工干预。",
					        analogy: "如果ML是‘单层的小脑筋’，DL就是‘拥有无数层神经元的大脑’，能理解像‘猫耳朵’这种抽象概念。"
					    },
					    {
					        id: "ANN-Struct",
					        term: "人工神经网络 (ANN)",
					        parent: "深度学习与神经网络",
					        rarity: "SR",
					        hint: "信息的接力赛。",
					        def: "模仿生物神经元。组件：输入层(接棒) -> 隐藏层(多层加工) -> 输出层(冲线)。",
					        analogy: "信息像接力棒一样层层传递，每一层处理一点特征，最后得出结果。"
					    },
					    // 
			
					
					    // 展示输入层、多个隐藏层和输出层的节点连接结构。
					
					    // ==========================================
					    // 4. 深度学习的关键应用
					    // ==========================================
					    {
					        id: "App-CV",
					        term: "计算机视觉 (CV)",
					        parent: "深度学习的关键应用",
					        rarity: "R",
					        hint: "教会电脑“看”。",
					        def: "应用：人脸识别、自动驾驶、医学影像分析。",
					        analogy: "让电脑拥有眼睛。"
					    },
					    {
					        id: "App-NLP",
					        term: "自然语言处理 (NLP)",
					        parent: "深度学习的关键应用",
					        rarity: "R",
					        hint: "教会电脑“听说”。",
					        def: "应用：Siri/Alexa、自动翻译、聊天机器人。",
					        analogy: "让电脑听懂人话，也会说人话。"
					    },
					    {
					        id: "App-Robot",
					        term: "机器人技术 (Robotics)",
					        parent: "深度学习的关键应用",
					        rarity: "R",
					        hint: "教会电脑“动”。",
					        def: "应用：工业机器人、服务机器人。",
					        analogy: "让电脑拥有手脚。"
					    },
					
					    // ==========================================
					    // 5. 机器学习 vs 深度学习
					    // ==========================================
					    {
					        id: "Vs-Data",
					        term: "ML vs DL: 数据与硬件",
					        parent: "机器学习 vs 深度学习",
					        rarity: "R",
					        hint: "吃粗粮 vs 吃细糠。",
					        def: "ML：小数据+CPU即可；DL：海量数据+高端GPU（依赖矩阵运算）。",
					        analogy: "ML像开小灶，普通锅就行；DL像满汉全席，需要专业大厨房和顶级食材。"
					    },
					    {
					        id: "Vs-Feat",
					        term: "ML vs DL: 特征工程",
					        parent: "机器学习 vs 深度学习",
					        rarity: "SR",
					        hint: "手工 vs 自动。",
					        def: "ML：需要专家手工提取特征（耗时）；DL：算法自动提取特征（黑盒）。",
					        analogy: "ML：你要告诉电脑‘猫有尖耳朵’；DL：给电脑看一万张图，它自己总结出‘尖耳朵’是特征。"
					    },
					    // 
					
					
					
					    // 对比图：ML流程中有Manual Feature Extraction步骤，而DL是End-to-End自动学习。
					
					    {
					        id: "Vs-Time",
					        term: "ML vs DL: 执行时间",
					        parent: "机器学习 vs 深度学习",
					        rarity: "R",
					        hint: "快充 vs 慢充。",
					        def: "ML：训练快（分/小时）；DL：训练极慢（周）。",
					        analogy: "ML像做快餐，DL像煲老火汤。"
					    },
					
					    // ==========================================
					    // 6. 核心术语表
					    // ==========================================
					    {
					        id: "Term-Data",
					        term: "数据集 (Train/Test)",
					        parent: "核心术语表",
					        rarity: "R",
					        hint: "课本与考卷。",
					        def: "训练集：用来教模型的（平时上课）；测试集：用来考模型的（期末考试）。",
					        analogy: "不能拿期末考卷（测试集）来平时练习（训练），否则就是作弊（过拟合）。"
					    },
					    {
					        id: "Term-Feat",
					        term: "特征 (Features) & 标签 (Labels)",
					        parent: "核心术语表",
					        rarity: "R",
					        hint: "题目与答案。",
					        def: "特征：输入数据的属性（房子的面积）；标签：要预测的答案（房价）。",
					        analogy: "做题时，题干已知条件是特征，要填的空是标签。"
					    },
					    {
					        id: "Term-Model",
					        term: "模型 (Model)",
					        parent: "核心术语表",
					        rarity: "R",
					        hint: "学会的套路。",
					        def: "经过训练后，学习到的规则或数学公式。",
					        analogy: "学霸脑子里的解题公式。"
					    },
						
						// ==========================================
						    // 1. 神经网络基础 (Introduction to ANN)
						    // ==========================================
						    {
						        id: "ANN-01",
						        term: "人工神经网络 (ANN)",
						        parent: "神经网络基础 (Introduction to ANN)",
						        rarity: "SSR",
						        hint: "数字大脑。",
						        def: "受生物神经系统启发的信息处理范式，由大量高度互连的处理元件（神经元）协同工作以解决特定问题。",
						        analogy: "模仿人类大脑的‘虚拟大脑’。用代码构建无数个‘数字神经元’并把它们连起来。"
						    },
						    {
						        id: "ANN-02",
						        term: "核心特点",
						        parent: "神经网络基础 (Introduction to ANN)",
						        rarity: "R",
						        hint: "像人一样学习。",
						        def: "1. 通过‘例子’学习（而非传统编程规则）；2. 具有概括能力(Generalization)，能处理未见过的生数据。",
						        analogy: "不是死记硬背，而是学会了举一反三。"
						    },
						
						    // ==========================================
						    // 2. 生物神经元 vs 人工神经元
						    // ==========================================
						    {
						        id: "Bio-01",
						        term: "生物与人工的映射",
						        parent: "生物神经元 vs 人工神经元",
						        rarity: "SR",
						        hint: "接力赛的各个环节。",
						        def: "树突->输入；胞体->求和计算；轴突->输出；突触->权重。",
						        analogy: "树突是接棒手，胞体是运动员大脑，轴突是递棒手，突触是交接棒的默契程度。"
						    },
						    // 
						    // 直观展示生物神经元的树突、轴突、突触如何一一对应到人工神经元的输入、输出和权重。
						
						    {
						        id: "Bio-02",
						        term: "结构细节映射",
						        parent: "生物与人工的映射",
						        rarity: "R",
						        hint: "一一对应。",
						        def: "树突(Dendrites)=输入(Inputs)；胞体(Soma)=节点/求和(Summation)；轴突(Axon)=输出(Output)；突触(Synapse)=权重(Weights)。",
						        analogy: "突触决定信号传递强度，对应权重决定输入的重要性。"
						    },
						
						    // ==========================================
						    // 3. 人工神经元的数学模型
						    // ==========================================
						    {
						        id: "Math-01",
						        term: "核心公式",
						        parent: "人工神经元的数学模型",
						        rarity: "SSR",
						        hint: "y = f(wx + b)",
						        def: "输出 = 激活函数( (输入 × 权重)的总和 + 偏置 )。数学表达：y = f(∑(w_i * x_i) + b)。",
						        analogy: "加权求和后，加个基础分，再看能不能过及格线。"
						    },
						    // 
						    // 展示输入x、权重w、偏置b如何进入求和函数∑，最后通过激活函数f得到输出y。
						
						    {
						        id: "Math-02",
						        term: "权重 (Weights)",
						        parent: "人工神经元的数学模型",
						        rarity: "SR",
						        hint: "老师打分。",
						        def: "衡量每个输入重要性的参数。",
						        analogy: "就像期末考权重0.6，平时分0.4。权重越大，对结果影响越大。"
						    },
						    {
						        id: "Math-03",
						        term: "偏置 (Bias)",
						        parent: "人工神经元的数学模型",
						        rarity: "SR",
						        hint: "同情分。",
						        def: "允许移动激活函数的阈值。",
						        analogy: "即使你交白卷（输入为0），老师也可能给你几分基础分，让你更容易及格。"
						    },
						    {
						        id: "Math-04",
						        term: "激活函数 (Activation Function)",
						        parent: "人工神经元的数学模型",
						        rarity: "SSR",
						        hint: "门槛开关。",
						        def: "决定神经元是否‘被激活’（输出是否非零）。引入非线性能力。",
						        analogy: "如果总分超过60分（阈值）就给过（激活），否则挂科。没它就处理不了复杂问题。"
						    },
						
						    // ==========================================
						    // 4. 网络架构
						    // ==========================================
						    {
						        id: "Arch-01",
						        term: "基本层级 (Layers)",
						        parent: "网络架构 (Network Architecture)",
						        rarity: "SR",
						        hint: "输入-隐藏-输出。",
						        def: "输入层(接收不计算) -> 隐藏层(特征提取) -> 输出层(结果)。",
						        analogy: "输入层=眼睛耳朵；隐藏层=大脑皮层(思考过程看不见)；输出层=嘴巴说出答案。"
						    },
						    // 
						
						
						    // 展示典型的三层结构：Input Layer, Hidden Layer, Output Layer及其连接。
						
						    {
						        id: "Arch-02",
						        term: "全连接 (Fully Connected)",
						        parent: "网络架构 (Network Architecture)",
						        rarity: "R",
						        hint: "人人互联。",
						        def: "上一层的每个神经元都与下一层的每个神经元相连。",
						        analogy: "信息无死角传递。"
						    },
						
						    // ==========================================
						    // 5. 神经网络是如何学习的
						    // ==========================================
						    {
						        id: "Learn-01",
						        term: "学习本质",
						        parent: "神经网络是如何学习的",
						        rarity: "SSR",
						        hint: "调参。",
						        def: "学习本质上就是调整权重(Weights)和偏置(Bias)的过程。",
						        analogy: "不是存数据，而是不断微调参数来拟合数据规律。"
						    },
						    {
						        id: "Learn-02",
						        term: "前向传播 (Forward Propagation)",
						        parent: "神经网络是如何学习的",
						        rarity: "R",
						        hint: "做题。",
						        def: "数据从输入层流向输出层，得到一个预测值。",
						        analogy: "从读题到算出答案的过程。"
						    },
						    {
						        id: "Learn-03",
						        term: "反向传播 (Backpropagation)",
						        parent: "神经网络是如何学习的",
						        rarity: "UR",
						        hint: "错题订正。",
						        def: "计算误差后，将误差反向传回网络，告诉每个神经元该调大还是调小权重。",
						        analogy: "发现公式背错了（权重不对），回去修改记忆，下次争取算对。"
						    },
						    // 
						    // 对比图：前向传播是数据向右流动，反向传播是误差向左流动更新权重。
						
						    {
						        id: "Learn-04",
						        term: "迭代 (Iteration)",
						        parent: "神经网络是如何学习的",
						        rarity: "R",
						        hint: "刷题。",
						        def: "重复前向传播和反向传播，直到误差最小。",
						        analogy: "不断做题、对答案、订正，直到能考满分。"
						    },
						    {
						        id: "Learn-Pitfall",
						        term: "易错点：拟合 vs 存储",
						        parent: "神经网络是如何学习的",
						        rarity: "R",
						        hint: "找规律不是背答案。",
						        def: "神经网络不是‘存储’了数据，而是‘拟合’了数据的规律（通过权重矩阵）。",
						        analogy: "学会了怎么解方程，而不是背下了每一道题的答案。"
						    },
						
						    // ==========================================
						    // 6. 神经网络的应用
						    // ==========================================
						    {
						        id: "App-01",
						        term: "常见应用",
						        parent: "神经网络的应用",
						        rarity: "R",
						        hint: "找规律高手。",
						        def: "模式识别(人脸)、预测(股票)、分类(垃圾邮件)。",
						        analogy: "凡是需要从复杂数据中找规律的任务，它都是好手。"
						    },
							
							    // ==========================================
							    // 1. 深度学习概论
							    // ==========================================
							    {
							        id: "DL-Overview-01",
							        term: "深度学习 (Deep Learning)",
							        parent: "深度学习概论",
							        rarity: "SSR",
							        hint: "层层剥洋葱。",
							        def: "机器学习的一个子集，受人脑启发，利用多层（深度）神经网络学习极其复杂的特征表示。",
							        analogy: "辨认照片：第一层看像素点，第二层连成线，第三层组成形状，第四层拼出人脸。每一层都在提取更高级的特征。"
							    },
							    {
							        id: "DL-Overview-02",
							        term: "AI vs ML vs DL",
							        parent: "深度学习概论",
							        rarity: "R",
							        hint: "俄罗斯套娃。",
							        def: "AI（大雨伞，包含所有智能） > ML（从数据学习） > DL（用多层神经网络学习）。",
							        analogy: "AI是整个家族，ML是家族里的学霸，DL是学霸里专攻‘仿生大脑’的博士。"
							    },
							    // 
							    // 直观展示三者的包含关系：AI包含ML，ML包含DL。
							
							    // ==========================================
							    // 2. 神经网络的核心运作机制
							    // ==========================================
							    {
							        id: "Mech-Forward",
							        term: "前向传播 (Forward Propagation)",
							        parent: "神经网络的核心运作机制",
							        rarity: "R",
							        hint: "猜谜语。",
							        def: "输入数据通过网络层层传递，经过计算最终得出预测结果的过程。",
							        analogy: "看到谜面，脑子里过一遍，最后脱口而出一个答案（不管对不对）。"
							    },
							    {
							        id: "Mech-Loss",
							        term: "损失函数 (Loss Function)",
							        parent: "神经网络的核心运作机制",
							        rarity: "SR",
							        hint: "打分板。",
							        def: "衡量模型预测值与真实值之间差异的数学函数（如MSE、交叉熵）。",
							        analogy: "老师拿标准答案改卷，算出来的‘扣分’就是Loss。分数越低越好。"
							    },
							    {
							        id: "Mech-Backprop",
							        term: "反向传播 (Backpropagation)",
							        parent: "神经网络的核心运作机制",
							        rarity: "UR",
							        hint: "找背锅侠。",
							        def: "根据误差从输出层向输入层反向传播，计算梯度并调整权重。",
							        analogy: "项目搞砸了（误差大），老板倒查责任，发现是小李（某层神经元）没做好，扣他工资（调权重），让他长记性。"
							    },
							    // 
							    // 展示误差如何反向流动并更新权重的动态过程。
							
							    {
							        id: "Mech-Opt",
							        term: "优化器 (Optimizer)",
							        parent: "神经网络的核心运作机制",
							        rarity: "SR",
							        hint: "下山向导。",
							        def: "根据梯度更新权重的算法（如SGD, Adam），目的是最小化损失函数。",
							        analogy: "你被蒙眼放在山上，向导告诉你‘往左下方走一步’，带你一步步走到山谷最低点（Loss最小点）。"
							    },
							    // 
							    // 展示优化器如何在起伏的Loss地形中寻找最低点。
							
							    {
							        id: "Mech-Act",
							        term: "激活函数 (Sigmoid & ReLU)",
							        parent: "神经网络的核心运作机制",
							        rarity: "R",
							        hint: "概率与开关。",
							        def: "Sigmoid：压缩到0-1（像概率）；ReLU：负数归零，正数不变（高效开关）。",
							        analogy: "Sigmoid像打分（0-100%）；ReLU像门禁，有票就进（原样），没票滚蛋（归零）。"
							    },
							
							    // ==========================================
							    // 3. 常见的深度学习架构
							    // ==========================================
							    {
							        id: "Arch-CNN",
							        term: "卷积神经网络 (CNN)",
							        parent: "常见的深度学习架构",
							        rarity: "SSR",
							        hint: "拿着放大镜找花纹。",
							        def: "图像识别霸主。关键组件：卷积层（提取局部特征）+ 池化层（降维）。",
							        analogy: "卷积层是用放大镜一格格扫描找花纹；池化层是把图片打马赛克，虽模糊但轮廓还在，省眼力。",
							        pitfall: "不擅长处理序列数据（如文字），关注空间结构。"
							    },
							    // 
							    // 展示图片经过卷积和池化层后特征图（Feature Map）的变化。
							
							    {
							        id: "Arch-RNN",
							        term: "循环神经网络 (RNN)",
							        parent: "常见的深度学习架构",
							        rarity: "SR",
							        hint: "读书不过脑，读了下句忘上句？",
							        def: "处理序列数据（NLP、语音）。具有‘记忆’，前一步输出作为下一步输入。",
							        analogy: "一边读新字，一边带着对上文的记忆。理解‘他’是谁，取决于前面读到的‘小明’。",
							        pitfall: "容易‘健忘’（梯度消失），记不住太长的句子。"
							    },
							    {
							        id: "Arch-Trans",
							        term: "Transformer 架构",
							        parent: "常见的深度学习架构",
							        rarity: "UR",
							        hint: "一目十行。",
							        def: "NLP霸主。核心机制：自注意力(Self-Attention)。并行处理整个序列。",
							        analogy: "不像RNN逐字读，而是一眼看完整个句子，瞬间知道‘苹果’和‘好吃’关系紧密。"
							    },
							    // 
							    // 展示单词之间相互关注的连线强度，直观理解Attention机制。
							
							    // ==========================================
							    // 4. 生成式AI (Generative AI)
							    // ==========================================
							    {
							        id: "GenAI-01",
							        term: "生成式 AI (Generative AI)",
							        parent: "生成式AI",
							        rarity: "SSR",
							        hint: "画家 vs 鉴赏家。",
							        def: "专注于创造从未见过的新数据。学习分布规律，生成符合规律的新样本。",
							        analogy: "判别式AI是鉴赏家（分辨真假）；生成式AI是画家（模仿风格创作）。"
							    },
							    {
							        id: "GenAI-VAE",
							        term: "变分自编码器 (VAEs)",
							        parent: "生成式AI (主流模型)",
							        rarity: "R",
							        hint: "压缩再还原。",
							        def: "编码器压缩成概率分布 -> 解码器还原。生成的图像较模糊但连续。",
							        analogy: "把高清图记成抽象笔记，再根据笔记画回来的图。"
							    },
							    {
							        id: "GenAI-GAN",
							        term: "生成对抗网络 (GANs)",
							        parent: "生成式AI (主流模型)",
							        rarity: "SSR",
							        hint: "猫鼠游戏。",
							        def: "两个网络互搏：生成器造假，判别器抓假。在对抗中进化。",
							        analogy: "假钞团伙（技术越来越好） vs 警察（眼力越来越毒），最后逼真到分不清。"
							    },
							    // 
							    // 展示生成器和判别器的博弈循环结构。
							
							    {
							        id: "GenAI-LLM",
							        term: "大语言模型 (LLMs)",
							        parent: "生成式AI (主流模型)",
							        rarity: "UR",
							        hint: "超级文字接龙。",
							        def: "基于Transformer，通过海量文本训练，预测‘下一个字’的概率。",
							        analogy: "它读过人类所有的书，你说上半句，它根据概率接出最合理的下半句。"
							    },
							
							    // ==========================================
							    // 5. 挑战与伦理
							    // ==========================================
							    {
							        id: "Chal-Over",
							        term: "过拟合 (Overfitting)",
							        parent: "深度学习的挑战与伦理",
							        rarity: "R",
							        hint: "死记硬背的书呆子。",
							        def: "模型在训练集表现满分，在测试集一塌糊涂。",
							        analogy: "背下了练习册答案，考试稍微换个数字就不会做了。"
							    },
							    // 
							    // 通过曲线拟合图直观展示过拟合（过于扭曲）、欠拟合（太简单）和拟合良好。
							
							    {
							        id: "Chal-Under",
							        term: "欠拟合 (Underfitting)",
							        parent: "深度学习的挑战与伦理",
							        rarity: "R",
							        hint: "完全没学会。",
							        def: "模型太简单，连训练集都学不会。",
							        analogy: "小学生去考微积分，完全看不懂。"
							    },
							    {
							        id: "Chal-Ethic",
							        term: "伦理问题",
							        parent: "深度学习的挑战与伦理",
							        rarity: "R",
							        hint: "双刃剑。",
							        def: "偏见(Bias)、深度伪造(Deepfakes)、版权(Copyright)。",
							        analogy: "模型会学会人类的歧视；AI画的画版权归谁？"
							    }
];
